"""
================================================================================
Snapshot Ensemble è®­ç»ƒå™¨
================================================================================

Snapshot Ensemble å®ç° (Huang et al., 2017)

æ ¸å¿ƒæ€æƒ³: ä½¿ç”¨ä½™å¼¦é€€ç« + å‘¨æœŸæ€§çƒ­é‡å¯ï¼Œåœ¨æ¯ä¸ªå‘¨æœŸæœ«å°¾ä¿å­˜æ¨¡å‹å¿«ç…§ã€‚
- å•æ¬¡è®­ç»ƒè·å¾—å¤šä¸ªæ¨¡å‹
- åˆ©ç”¨å‘¨æœŸæ€§å­¦ä¹ ç‡è°ƒåº¦äº§ç”Ÿå¤šæ ·æ€§
- æ— é¢å¤–è®­ç»ƒæˆæœ¬

å‚è€ƒ: https://arxiv.org/abs/1704.00109
"""

import time
from pathlib import Path
from typing import Dict, List, Tuple

import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader
from tqdm import tqdm

from ..config import Config
from ..models import ModelFactory
from ..utils import ensure_dir, get_logger
from .base import BaseTrainer
from .scheduler import create_optimizer


class SnapshotEnsembleTrainer(BaseTrainer):
    """
    Snapshot Ensemble è®­ç»ƒå™¨

    ä½¿ç”¨ CosineAnnealingWarmRestarts è°ƒåº¦å™¨ï¼Œåœ¨æ¯ä¸ªå‘¨æœŸç»“æŸæ—¶ä¿å­˜å¿«ç…§ã€‚
    """

    def __init__(
        self,
        method_name: str,
        cfg: Config,
        num_cycles: int = 5,
    ):
        # è°ƒç”¨åŸºç±»åˆå§‹åŒ–
        super().__init__(method_name, cfg)

        self.num_cycles = num_cycles

        # è®¡ç®—æ¯ä¸ªå‘¨æœŸçš„ epoch æ•°
        self.epochs_per_cycle = cfg.total_epochs // num_cycles
        if self.epochs_per_cycle < 1:
            self.epochs_per_cycle = 1
            self.num_cycles = cfg.total_epochs

        # è®¾å¤‡
        self.device = torch.device(
            f"cuda:{cfg.gpu_ids[0]}" if cfg.gpu_ids else "cuda:0"
        )

        # æ€§èƒ½ä¼˜åŒ–
        if cfg.use_tf32:
            torch.backends.cuda.matmul.allow_tf32 = True
            torch.backends.cudnn.allow_tf32 = True
        torch.backends.cudnn.benchmark = True

        get_logger().info(f"\nğŸš€ Initializing {method_name} (Snapshot Ensemble)")
        get_logger().info(f"   Cycles: {self.num_cycles}")
        get_logger().info(f"   Epochs per cycle: {self.epochs_per_cycle}")
        get_logger().info(f"   Device: {self.device}")

        # åˆ›å»ºå•ä¸ªæ¨¡å‹
        self.model = ModelFactory.create_model(
            cfg.model_name,
            num_classes=cfg.num_classes,
            init_method=cfg.init_method,
        ).to(self.device)

        # å¯é€‰ç¼–è¯‘
        if cfg.compile_model and hasattr(torch, "compile"):
            self.model = torch.compile(self.model)

        # ä¼˜åŒ–å™¨ (ä½¿ç”¨å…¬å…±å·¥å‚å‡½æ•°)
        self.optimizer = create_optimizer(
            self.model, cfg.optimizer, cfg.lr, cfg.weight_decay
        )

        # ä½¿ç”¨ CosineAnnealingWarmRestarts è°ƒåº¦å™¨
        self.scheduler = optim.lr_scheduler.CosineAnnealingWarmRestarts(
            self.optimizer,
            T_0=self.epochs_per_cycle,
            T_mult=1,  # æ¯ä¸ªå‘¨æœŸé•¿åº¦ç›¸åŒ
        )

        # ä¿å­˜çš„å¿«ç…§
        self.snapshots: List[Dict] = []

        # æ‰©å±• history æ·»åŠ  cycle å­—æ®µ
        self.history["cycle"] = []

        # è®¾ç½®æ—¥å¿—
        self.setup_logging()

        # ä¿å­˜é…ç½®
        cfg.save()

    # æ³¨: _create_optimizer å·²ç§»é™¤ï¼Œä½¿ç”¨ scheduler.create_optimizer() æ›¿ä»£

    def _train_epoch(self, train_loader: DataLoader, epoch: int) -> float:
        """è®­ç»ƒä¸€ä¸ª epoch"""
        self.model.train()
        criterion = nn.CrossEntropyLoss(label_smoothing=self.cfg.label_smoothing)

        total_loss = 0.0
        iterator = tqdm(
            train_loader,
            desc=f"Epoch {epoch + 1}/{self.cfg.total_epochs}",
        )

        for inputs, targets in iterator:
            inputs = inputs.to(self.device, non_blocking=True)
            targets = targets.to(self.device, non_blocking=True)

            self.optimizer.zero_grad()
            logits = self.model(inputs)
            loss = criterion(logits, targets)
            loss.backward()

            if self.cfg.max_grad_norm > 0:
                torch.nn.utils.clip_grad_norm_(
                    self.model.parameters(), self.cfg.max_grad_norm
                )

            self.optimizer.step()
            total_loss += loss.item()
            iterator.set_postfix({"loss": loss.item()})

        return total_loss / len(train_loader)

    @torch.no_grad()
    def _validate(self, val_loader: DataLoader) -> Tuple[float, float]:
        """éªŒè¯ (ä½¿ç”¨å½“å‰æ¨¡å‹)"""
        self.model.eval()
        criterion = nn.CrossEntropyLoss()

        total_loss = 0.0
        correct = 0
        total = 0

        for inputs, targets in val_loader:
            inputs = inputs.to(self.device, non_blocking=True)
            targets = targets.to(self.device, non_blocking=True)

            logits = self.model(inputs)
            loss = criterion(logits, targets)
            total_loss += loss.item()

            preds = logits.argmax(dim=1)
            correct += (preds == targets).sum().item()
            total += targets.size(0)

        return total_loss / len(val_loader), 100.0 * correct / total

    @torch.no_grad()
    def _validate_ensemble(self, val_loader: DataLoader) -> Tuple[float, float]:
        """éªŒè¯ (ä½¿ç”¨æ‰€æœ‰å¿«ç…§é›†æˆ)"""
        if not self.snapshots:
            return self._validate(val_loader)

        criterion = nn.CrossEntropyLoss()
        total_loss = 0.0
        correct = 0
        total = 0

        for inputs, targets in val_loader:
            inputs = inputs.to(self.device, non_blocking=True)
            targets = targets.to(self.device, non_blocking=True)

            # æ”¶é›†æ‰€æœ‰å¿«ç…§çš„é¢„æµ‹
            all_logits = []
            for snapshot in self.snapshots:
                self.model.load_state_dict(snapshot)
                self.model.eval()
                logits = self.model(inputs)
                all_logits.append(logits)

            # é›†æˆé¢„æµ‹
            ensemble_logits = torch.stack(all_logits).mean(dim=0)
            loss = criterion(ensemble_logits, targets)
            total_loss += loss.item()

            preds = ensemble_logits.argmax(dim=1)
            correct += (preds == targets).sum().item()
            total += targets.size(0)

        return total_loss / len(val_loader), 100.0 * correct / total

    def _save_snapshot(self, cycle: int):
        """ä¿å­˜å½“å‰æ¨¡å‹å¿«ç…§"""
        snapshot = {k: v.clone() for k, v in self.model.state_dict().items()}
        self.snapshots.append(snapshot)
        self.logger.info(f"ğŸ“¸ Saved snapshot {cycle + 1}/{self.num_cycles}")

    def train(self, train_loader: DataLoader, val_loader: DataLoader):
        """æ‰§è¡Œå®Œæ•´è®­ç»ƒ"""
        self.logger.info("=" * 70)
        self.logger.info(f"ğŸ¯ Snapshot Ensemble Training: {self.name}")
        self.logger.info(
            f"   Cycles: {self.num_cycles}, Epochs/Cycle: {self.epochs_per_cycle}"
        )
        self.logger.info("=" * 70)

        training_start = time.time()
        current_cycle = 0

        try:
            for epoch in range(self.cfg.total_epochs):
                epoch_start = time.time()

                # åˆ¤æ–­å½“å‰å‘¨æœŸ
                cycle = epoch // self.epochs_per_cycle
                is_cycle_end = (epoch + 1) % self.epochs_per_cycle == 0

                # å‘¨æœŸå¼€å§‹æç¤º
                if cycle != current_cycle:
                    current_cycle = cycle
                    self.logger.info(
                        f"\nğŸ”„ Starting Cycle {cycle + 1}/{self.num_cycles}"
                    )

                # è®­ç»ƒ
                train_loss = self._train_epoch(train_loader, epoch)

                # æ›´æ–°å­¦ä¹ ç‡
                self.scheduler.step()

                # éªŒè¯
                val_loss, val_acc = self._validate(val_loader)

                epoch_time = time.time() - epoch_start
                current_lr = self.optimizer.param_groups[0]["lr"]

                # ä½¿ç”¨åŸºç±»æ–¹æ³•è®°å½• epoch (åŒæ—¶è®°å½• cycle)
                extra_info = f" [Cycle {cycle + 1}]"
                self._log_epoch(
                    epoch,
                    train_loss,
                    val_loss,
                    val_acc,
                    current_lr,
                    epoch_time,
                    extra_info,
                )
                self.history["cycle"].append(cycle + 1)

                # å‘¨æœŸç»“æŸæ—¶ä¿å­˜å¿«ç…§
                if is_cycle_end and cycle < self.num_cycles:
                    self._save_snapshot(cycle)
                    self._save_checkpoint(f"snapshot_{cycle + 1}")

                # ä½¿ç”¨åŸºç±»æ–¹æ³•æ£€æŸ¥æœ€ä½³
                self._check_best_and_save(val_loss, epoch)

            # æœ€ç»ˆè¯„ä¼°é›†æˆæ•ˆæœ
            ens_loss, ens_acc = self._validate_ensemble(val_loader)
            self.logger.info(f"\nğŸ“Š Ensemble ({len(self.snapshots)} snapshots):")
            self.logger.info(f"   Val Loss: {ens_loss:.4f}, Val Acc: {ens_acc:.2f}%")

            # ä½¿ç”¨åŸºç±»æ–¹æ³•å®Œæˆè®­ç»ƒ
            self._finalize_training(training_start)

        except KeyboardInterrupt:
            # ä½¿ç”¨åŸºç±»æ–¹æ³•å¤„ç†ä¸­æ–­
            self._handle_interrupt()
            raise

    def _save_checkpoint(self, tag: str):
        """ä¿å­˜ checkpoint"""
        ckpt_dir = Path(self.cfg.save_dir) / "checkpoints" / self.name / tag
        ensure_dir(ckpt_dir)

        # ä¿å­˜å½“å‰æ¨¡å‹
        torch.save(self.model.state_dict(), ckpt_dir / "model.pth")

        # ä¿å­˜æ‰€æœ‰å¿«ç…§
        for i, snap in enumerate(self.snapshots):
            torch.save(snap, ckpt_dir / f"snapshot_{i}.pth")

        # ä¿å­˜çŠ¶æ€
        state = {
            "num_snapshots": len(self.snapshots),
            "best_val_loss": self.best_val_loss,
            "history": self.history,
            "num_cycles": self.num_cycles,
            "total_training_time": self.total_training_time,
        }
        torch.save(state, ckpt_dir / "trainer_state.pth")
        self.logger.info(f"ğŸ’¾ Saved checkpoint: {tag}")

    def load_checkpoint(self, tag: str = "final") -> bool:
        """åŠ è½½ checkpoint"""
        ckpt_dir = Path(self.cfg.save_dir) / "checkpoints" / self.name / tag
        if not ckpt_dir.exists():
            self.logger.warning(f"âš ï¸ Checkpoint not found: {ckpt_dir}")
            return False

        # åŠ è½½çŠ¶æ€
        state_path = ckpt_dir / "trainer_state.pth"
        if state_path.exists():
            state = torch.load(state_path, weights_only=False)
            self.best_val_loss = state["best_val_loss"]
            self.history = state["history"]
            self.total_training_time = state.get("total_training_time", 0.0)

            # åŠ è½½å¿«ç…§
            self.snapshots = []
            for i in range(state["num_snapshots"]):
                snap_path = ckpt_dir / f"snapshot_{i}.pth"
                if snap_path.exists():
                    self.snapshots.append(torch.load(snap_path, weights_only=True))

            self.logger.info(f"âœ… Loaded {len(self.snapshots)} snapshots from: {tag}")
            return True
        return False

    def get_models(self) -> List[nn.Module]:
        """
        è·å–æ‰€æœ‰å¿«ç…§æ¨¡å‹ (ç”¨äºè¯„ä¼°)

        è¿”å›å¤šä¸ªç‹¬ç«‹æ¨¡å‹å®ä¾‹ï¼Œæ¯ä¸ªåŠ è½½ä¸åŒå¿«ç…§
        """
        models = []
        for snapshot in self.snapshots:
            model = ModelFactory.create_model(
                self.cfg.model_name,
                num_classes=self.cfg.num_classes,
            ).to(self.device)
            model.load_state_dict(snapshot)
            models.append(model)
        return models


def train_snapshot_ensemble(
    experiment_name: str,
    cfg: Config,
    train_loader: DataLoader,
    val_loader: DataLoader,
    num_cycles: int = 5,
) -> Tuple[SnapshotEnsembleTrainer, float]:
    """
    Snapshot Ensemble è®­ç»ƒå…¥å£å‡½æ•°

    Args:
        experiment_name: å®éªŒåç§°
        cfg: é…ç½®
        train_loader, val_loader: æ•°æ®åŠ è½½å™¨
        num_cycles: å‘¨æœŸæ•°

    Returns:
        (trainer, training_time)
    """
    trainer = SnapshotEnsembleTrainer(
        method_name=experiment_name,
        cfg=cfg,
        num_cycles=num_cycles,
    )

    trainer.train(train_loader, val_loader)
    training_time = trainer.total_training_time

    # åŠ è½½æœ€ç»ˆå¿«ç…§
    trainer.load_checkpoint("final")
    trainer.total_training_time = training_time

    get_logger().info(f"\nâœ… Snapshot Ensemble completed: {experiment_name}")

    return trainer, training_time
