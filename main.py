"""
================================================================================
ä¸»å…¥å£æ¨¡å— - CLIè§£æå’Œç¨‹åºå…¥å£
================================================================================
"""

# ========== Windows å…¼å®¹æ€§é…ç½® ==========
import io
import sys

if sys.platform == "win32":
    import torch

    # ç¦ç”¨ Dynamo ç¼–è¯‘ (Windows ä¸æ”¯æŒ Triton)
    torch._dynamo.config.disable = True
    torch._inductor.config.compile_threads = 1
    # å…³é—­ç›¸å…³ä¼˜åŒ–
    torch.backends.cudnn.benchmark = False
    torch.set_float32_matmul_precision("high")
    # ä¿®å¤ç»ˆç«¯è¾“å‡ºä¸­æ–‡/emoji ä¹±ç 
    sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding="utf-8")
    sys.stderr = io.TextIOWrapper(sys.stderr.buffer, encoding="utf-8")


sys.dont_write_bytecode = True  # ç¦ç”¨ __pycache__ ç”Ÿæˆ

import argparse
import datetime
from pathlib import Path

from .config import Config
from .datasets import configure_dataset_params, load_dataset
from .evaluation import ReportGenerator
from .training import train_experiment
from .utils import ensure_dir, get_logger, set_seed


def main():
    """NDE ç³»ç»Ÿä¸»å…¥å£: è§£æ -> åˆå§‹åŒ– -> åˆ†å‘"""
    args = _parse_args()
    cfg = _init_config(args)
    set_seed(cfg.seed)

    if args.eval:
        _run_evaluation(cfg, args)
    else:
        _run_training(cfg)


def _parse_args():
    p = argparse.ArgumentParser(description="NDE")
    p.add_argument("--eval", action="store_true")
    p.add_argument("--quick-test", action="store_true")
    return p.parse_args()


def _init_config(args):
    config_name = "config/default.yaml"
    path = Path(config_name)
    if not path.exists():
        path = Path(__file__).parent / config_name

    base_cfg, experiments, eval_ckpts = Config.load_yaml(str(path))

    # åº”ç”¨ quick_test æ¨¡å¼ (å¿…é¡»åœ¨ configure_dataset_params ä¹‹å‰)
    # å› ä¸º apply_quick_test() ä½¿ç”¨ replace() ä¼šåˆ›å»ºæ–°å¯¹è±¡ï¼Œä¸¢å¤± init=False å­—æ®µ
    if args.quick_test:
        base_cfg = base_cfg.apply_quick_test()

    # [New] æ‰‹åŠ¨è§¦å‘æ•°æ®é›†é…ç½® (è§£è€¦åˆ)
    configure_dataset_params(base_cfg)

    # å°†å®éªŒåˆ—è¡¨æŒ‚è½½åˆ°é…ç½®å¯¹è±¡ä¸Šä¾¿äºåç»­ä¼ é€’ (ä¸´æ—¶)
    base_cfg._experiments = experiments
    base_cfg._eval_ckpts = eval_ckpts
    return base_cfg


def _run_training(cfg):
    log = get_logger()
    log.info(
        f"ğŸš€ NDE | Training Mode | Models: {cfg.total_models} | Experiments: {len(cfg._experiments)}"
    )

    train_loader, val_loader = load_dataset(cfg, mode="train")

    # ç”Ÿæˆç»Ÿä¸€çš„è®­ç»ƒæ‰¹æ¬¡ç›®å½• (æ‰€æœ‰å®éªŒå…±äº«)
    batch_ts = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
    batch_dir = Path(cfg.save_root) / "training" / batch_ts
    ensure_dir(batch_dir)
    log.info(f"ğŸ“ Training batch dir: {batch_dir}")

    for exp in cfg._experiments:
        log.info(f"\nğŸ§ª Running: {exp.name}")

        # ğŸ”‘ å…³é”®ï¼šé‡ç½®éšæœºç§å­ï¼Œç¡®ä¿æ¯ä¸ªå®éªŒä»ç›¸åŒåˆå§‹çŠ¶æ€å¼€å§‹
        # è¿™ä¿è¯äº†ä¸åŒå®éªŒä¹‹é—´å”¯ä¸€çš„å·®å¼‚åªæœ‰é®æŒ¡å›¾æ¡ˆ
        set_seed(cfg.seed)

        c = cfg.copy(experiment_name=exp.name, **exp.get_config_overrides())

        # æ¯ä¸ªå®éªŒä½œä¸ºå­ç›®å½•
        c.training_base_dir = str(batch_dir)  # å…±äº«æ—¶é—´æˆ³ç›®å½• (æ—¥å¿—/å†å²)
        c.save_dir = str(batch_dir / exp.name)  # å®éªŒå­ç›®å½• (æ£€æŸ¥ç‚¹)
        ensure_dir(c.save_dir)

        train_experiment(cfg=c, train_loader=train_loader, val_loader=val_loader)


def _run_evaluation(cfg, args):
    log = get_logger()
    log.info(f"ğŸš€ NDE | Evaluation Mode | Checkpoints: {len(cfg._eval_ckpts)}")

    if not cfg._eval_ckpts:
        get_logger().error("âŒ No checkpoints for evaluation")
        return

    test_loader, c_ds, o_ds = load_dataset(cfg, mode="eval")
    ckpts = [c["path"] for c in cfg._eval_ckpts]

    ReportGenerator.evaluate_checkpoints(
        checkpoint_paths=ckpts,
        test_loader=test_loader,
        cfg=cfg,
        corruption_dataset=c_ds,
        ood_dataset=o_ds,
        run_gradcam=cfg.eval_run_gradcam,
        run_loss_landscape=cfg.eval_run_landscape,
    )


if __name__ == "__main__":
    main()
