"""
================================================================================
Domain Shift æ•°æ®é›†æ¨¡å—
================================================================================

åŒ…å«: DomainShiftDataset

"""

from pathlib import Path
from typing import TYPE_CHECKING, List

if TYPE_CHECKING:
    from ...config.core import Config

import numpy as np
import torch
from torch.utils.data import DataLoader, TensorDataset

from ...utils import get_logger
from ..preloaded import DATASET_REGISTRY

# â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
# â•‘ Domain Shift æ•°æ®é›†                                                          â•‘
# â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•


class DomainShiftDataset:
    """Domain Shift (åŸŸåç§») è¯„ä¼°æ•°æ®é›†

    ç”¨äºè¯„ä¼°æ¨¡å‹åœ¨ä¸åŒè§†è§‰åŸŸ/é£æ ¼ä¸Šçš„æ³›åŒ–èƒ½åŠ›ã€‚
    ä¸ OOD ä¸åŒçš„æ˜¯ï¼ŒDomain Shift æ•°æ®é›†æœ‰ç›¸åŒçš„ç±»åˆ«ï¼Œåªæ˜¯é£æ ¼ä¸åŒã€‚

    ä½¿ç”¨ç¤ºä¾‹:
        # ä»æ³¨å†Œè¡¨åŠ è½½
        >>> ds = DomainShiftDataset.from_name("cifar10_sketch", id_dataset="cifar10")

        # ä»æ–‡ä»¶å¤¹åŠ è½½
        >>> ds = DomainShiftDataset.from_folder("./data/sketches", id_dataset="cifar10")

    æ·»åŠ æ–°æ•°æ®é›†:
        >>> register_domain_dataset("my_domain", "My Domain", "./data/my_domain")
    """

    def __init__(
        self,
        name: str,
        images: torch.Tensor,
        labels: torch.Tensor,
        mean: List[float],
        std: List[float],
    ):
        """ç›´æ¥æ„é€ å‡½æ•°"""
        self.name = name
        self.images = images  # [N, C, H, W], uint8
        self.labels = labels  # [N], long
        self._mean = torch.tensor(mean).view(1, 3, 1, 1)
        self._std = torch.tensor(std).view(1, 3, 1, 1)

    @property
    def num_samples(self) -> int:
        return len(self.images)

    @classmethod
    def from_generated(
        cls,
        id_dataset: str,
        root: str = "./data",
        styles: List[str] = None,
    ) -> "DomainShiftDataset":
        """ä» generate.py ç”Ÿæˆçš„æ•°æ®åŠ è½½ Domain Shift æ•°æ®é›†

        Args:
            id_dataset: ID æ•°æ®é›†åç§° (ç”¨äºç¡®å®šè·¯å¾„å’Œæ ‡å‡†åŒ–å‚æ•°)
            root: æ•°æ®æ ¹ç›®å½•
            styles: è¦åŠ è½½çš„é£æ ¼åˆ—è¡¨ (é»˜è®¤åŠ è½½æ‰€æœ‰)

        Returns:
            DomainShiftDataset å®ä¾‹
        """
        from PIL import Image

        if id_dataset not in DATASET_REGISTRY:
            raise ValueError(
                f"æœªçŸ¥ ID æ•°æ®é›†: {id_dataset}. å¯ç”¨: {list(DATASET_REGISTRY.keys())}"
            )

        id_class = DATASET_REGISTRY[id_dataset]
        # matching generate.py output path
        folder_path = Path(root) / f"{id_class.NAME}-Domain"

        if not folder_path.exists():
            raise FileNotFoundError(
                f"æœªæ‰¾åˆ°ç”Ÿæˆçš„ Domain æ•°æ®: {folder_path}\n"
                f"è¯·å…ˆè¿è¡Œ: python -m ensemble.datasets.robustness.generate --type domain --dataset {id_dataset}"
            )

        # è·å–é£æ ¼å­ç›®å½•
        available_styles = [d.name for d in folder_path.iterdir() if d.is_dir()]
        target_styles = styles or available_styles

        if not target_styles:
            raise ValueError(f"åœ¨ {folder_path} ä¸­æœªæ‰¾åˆ°ä»»ä½•é£æ ¼ç›®å½•")

        get_logger().info(f"ğŸ“¥ åŠ è½½ Domain Shift æ•°æ®é›†: {folder_path.name}")
        get_logger().info(f"   é£æ ¼: {target_styles}")

        images_list = []
        labels_list = []
        target_size = id_class.IMAGE_SIZE

        # éå†é€‰å®šçš„é£æ ¼
        for style in target_styles:
            style_dir = folder_path / style
            if not style_dir.exists():
                get_logger().warning(f"è·³è¿‡ä¸å­˜åœ¨çš„é£æ ¼: {style}")
                continue

            # éå†ç±»åˆ« (class_0, class_1, ...)
            class_folders = sorted([d for d in style_dir.iterdir() if d.is_dir()])

            for class_idx, class_folder in enumerate(class_folders):
                # ç®€å•æ ¡éªŒæ–‡ä»¶å¤¹åæ˜¯å¦åŒ¹é… class_{idx} æ ¼å¼ï¼Œæˆ–è€…ç›´æ¥ä¿¡ä»»æ’åº
                # è¿™é‡Œçš„ class_idx æ˜¯ç›¸å¯¹äºæ–‡ä»¶å¤¹æ’åºçš„ï¼Œåº”ä¸ ID æ•°æ®é›†ä¸€è‡´

                image_files = list(class_folder.glob("*.[jJ][pP][gG]")) + list(
                    class_folder.glob("*.[pP][nN][gG]")
                )

                for img_path in image_files:
                    try:
                        img = Image.open(img_path).convert("RGB")

                        # ä¸¥æ ¼æ ¡éªŒå°ºå¯¸ï¼Œä¸å† Resize
                        if img.size != (target_size, target_size):
                            raise ValueError(
                                f"å°ºå¯¸ä¸åŒ¹é…: {img_path.name} is {img.size}, expected ({target_size}, {target_size})"
                            )

                        img_np = np.array(img)
                        images_list.append(img_np)
                        labels_list.append(class_idx)
                    except Exception as e:
                        get_logger().warning(f"è·³è¿‡æ— æ•ˆå›¾åƒ {img_path}: {e}")

        if not images_list:
            raise ValueError(f"æœªæ‰¾åˆ°æœ‰æ•ˆå›¾åƒ: {folder_path}")

        images = np.stack(images_list, axis=0)
        images_tensor = torch.from_numpy(images).permute(0, 3, 1, 2)
        labels_tensor = torch.tensor(labels_list, dtype=torch.long)

        get_logger().info(
            f"âœ… åŠ è½½äº† {len(images_tensor)} ä¸ªæ ·æœ¬, {len(target_styles)} ç§é£æ ¼"
        )

        return cls(
            name=f"{id_class.NAME}-Domain",
            images=images_tensor,
            labels=labels_tensor,
            mean=id_class.MEAN,
            std=id_class.STD,
        )

    def get_loader(
        self,
        config: "Config",
    ) -> DataLoader:
        """è·å–æ•°æ®åŠ è½½å™¨"""
        images_float = self.images.float() / 255.0
        images_normalized = (images_float - self._mean) / self._std

        dataset = TensorDataset(images_normalized, self.labels)
        return DataLoader(
            dataset,
            batch_size=config.batch_size,
            shuffle=False,
            num_workers=config.num_workers,
            pin_memory=config.pin_memory,
        )
