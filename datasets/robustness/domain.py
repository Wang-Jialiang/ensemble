"""
================================================================================
Domain Shift æ•°æ®é›†æ¨¡å—
================================================================================

åŒ…å«: DomainShiftDataset

"""

from pathlib import Path
from typing import TYPE_CHECKING

if TYPE_CHECKING:
    from ...config.core import Config

import numpy as np
import torch
from torch.utils.data import DataLoader, TensorDataset

from ...utils import get_logger
from ..preloaded import DATASET_REGISTRY

# â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
# â•‘ å¸¸é‡å®šä¹‰ (ä¸ generate.py ä¿æŒåŒæ­¥)                                           â•‘
# â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

DOMAIN_STYLES = ["sketch", "painting", "cartoon", "watercolor"]
DOMAIN_STRENGTHS = [0.3, 0.5, 0.7]  # è½»åº¦ã€ä¸­åº¦ã€é‡åº¦


# â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
# â•‘ Domain Shift æ•°æ®é›†                                                          â•‘
# â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•


class DomainShiftDataset:
    """Domain Shift (åŸŸåç§») è¯„ä¼°æ•°æ®é›†

    ç”¨äºè¯„ä¼°æ¨¡å‹åœ¨ä¸åŒè§†è§‰åŸŸ/é£æ ¼ä¸Šçš„æ³›åŒ–èƒ½åŠ›ã€‚
    ä¸ OOD ä¸åŒçš„æ˜¯ï¼ŒDomain Shift æ•°æ®é›†æœ‰ç›¸åŒçš„ç±»åˆ«ï¼Œåªæ˜¯é£æ ¼ä¸åŒã€‚

    ç›®å½•ç»“æ„: {Dataset}-Domain/{style}/{strength}/class_X/img_Y.png

    ä½¿ç”¨ç¤ºä¾‹:
        >>> ds = DomainShiftDataset("cifar10", "./data")
        >>> loader = ds.get_loader("sketch", 0.5, config)  # è·å–ç´ æé£æ ¼ã€ä¸­ç­‰å¼ºåº¦
    """

    # å¼•ç”¨æ¨¡å—çº§å¸¸é‡
    STYLES = DOMAIN_STYLES
    STRENGTHS = DOMAIN_STRENGTHS

    def __init__(self, id_dataset: str, root: str = "./data"):
        """Domain Shift æ•°æ®é›†æ„é€ å‡½æ•°"""
        if id_dataset not in DATASET_REGISTRY:
            raise ValueError(f"æœªçŸ¥ ID æ•°æ®é›†: {id_dataset}. å¯ç”¨: {list(DATASET_REGISTRY.keys())}")

        self.id_class = DATASET_REGISTRY[id_dataset]
        self.folder_path = Path(root) / f"{self.id_class.NAME}-Domain"

        self._verify_folder()
        self._init_statistics()
        get_logger().info(f"ğŸ“¥ åˆå§‹åŒ– Domain Shift: {self.folder_path.name}")

    def _verify_folder(self):
        """ç¡®ä¿æ•°æ®é›†æ–‡ä»¶å¤¹å­˜åœ¨"""
        if not self.folder_path.exists():
            raise FileNotFoundError(
                f"æœªæ‰¾åˆ°äº§ç”Ÿçš„ Domain æ•°æ®: {self.folder_path}\n"
                f"è¯·è¿è¡Œ: python -m ensemble.datasets.robustness.generate --type domain --dataset {self.id_class.NAME}"
            )

    def _init_statistics(self):
        """åˆå§‹åŒ– ID æ•°æ®é›†çš„ç»Ÿè®¡å‚æ•°"""
        self._mean = torch.tensor(self.id_class.MEAN).view(1, 3, 1, 1)
        self._std = torch.tensor(self.id_class.STD).view(1, 3, 1, 1)

    def get_loader(self, style: str, strength: float, config: "Config") -> DataLoader:
        """è·å–ç‰¹å®šé£æ ¼å’Œå¼ºåº¦çš„æ•°æ®åŠ è½½å™¨"""
        # 1. éªŒè¯å‚æ•°ä¸è·¯å¾„
        strength_dir = self._verify_params(style, strength)

        # 2. æ‰«æå¹¶åŠ è½½å›¾åƒæ•°æ®
        images_np, labels_np = self._scan_folder_for_samples(strength_dir)

        # 3. ç»„è£…å¹¶æ ‡å‡†åŒ–
        return self._create_dataloader(images_np, labels_np, config)

    def _verify_params(self, style: str, strength: float) -> Path:
        """æ ¡éªŒè¾“å…¥çš„é£æ ¼å’Œå¼ºåº¦å‚æ•°å¹¶å®šä½ç›®å½•"""
        if style not in self.STYLES:
            raise ValueError(f"æœªçŸ¥é£æ ¼: {style}")
        if strength not in self.STRENGTHS:
            raise ValueError(f"æœªçŸ¥å¼ºåº¦: {strength}")
            
        target_dir = self.folder_path / style / str(strength)
        if not target_dir.exists():
            raise FileNotFoundError(f"ç›®å½•ä¸å­˜åœ¨: {target_dir}")
        return target_dir

    def _scan_folder_for_samples(self, target_dir: Path):
        """é€’å½’æ‰«ææ–‡ä»¶å¤¹å¹¶è¯»å–å›¾åƒ"""
        from PIL import Image
        images, labels = [], []
        target_size = self.id_class.IMAGE_SIZE

        # éå†ç±»åˆ«å­ç›®å½•
        for class_dir in sorted([d for d in target_dir.iterdir() if d.is_dir()]):
            class_idx = self._parse_class_idx(class_dir.name)
            if class_idx is None: continue

            # è¯»å–è¯¥ç±»åˆ«ä¸‹æ‰€æœ‰å›¾åƒ
            for img_path in class_dir.glob("*.png"):
                img_data = self._read_single_image(img_path, target_size)
                if img_data is not None:
                    images.append(img_data)
                    labels.append(class_idx)

        if not images:
            raise ValueError(f"æœªåœ¨ {target_dir} å‘ç°æœ‰æ•ˆå›¾åƒ")
            
        return np.stack(images), np.array(labels)

    def _parse_class_idx(self, dir_name: str):
        """ä»æ–‡ä»¶å¤¹åè§£æç±»åˆ«ç´¢å¼• (class_0005 -> 5)"""
        try:
            return int(dir_name.split("_")[1])
        except (IndexError, ValueError):
            return None

    def _read_single_image(self, path: Path, size: int):
        """è¯»å–å•å¼ å›¾åƒå¹¶æ ¡éªŒå°ºå¯¸"""
        from PIL import Image
        try:
            img = Image.open(path)
            if img.size != (size, size): return None
            return np.array(img)
        except Exception:
            return None

    def _create_dataloader(self, images_np, labels_np, config) -> DataLoader:
        """æ‰§è¡Œå¼ é‡åŒ–ã€å½’ä¸€åŒ–å¹¶åˆ›å»º Loader"""
        imgs = torch.from_numpy(images_np).permute(0, 3, 1, 2).float() / 255.0
        imgs_norm = (imgs - self._mean) / self._std
        lbls = torch.from_numpy(labels_np).long()

        return DataLoader(
            TensorDataset(imgs_norm, lbls),
            batch_size=config.batch_size,
            shuffle=False,
            num_workers=config.num_workers,
            pin_memory=config.pin_memory,
        )
