"""
================================================================================
Corruption æ•°æ®é›†æ¨¡å—
================================================================================

åŒ…å«: CorruptionDataset, CORRUPTIONS å¸¸é‡
"""

from pathlib import Path
from typing import TYPE_CHECKING

if TYPE_CHECKING:
    from ...config.core import Config

import numpy as np
import torch
from torch.utils.data import DataLoader, TensorDataset

from ...utils import get_logger
from ..preloaded import DATASET_REGISTRY

# â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
# â•‘ å…¨å±€å¸¸é‡å®šä¹‰                                                                 â•‘
# â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

# â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
# â•‘ å…¨å±€å¸¸é‡å®šä¹‰                                                                 â•‘
# â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

# å®Œæ•´ 19 ç§ Corruptionï¼Œåˆ†ä¸º 4 å¤§ç±»
# å‚è€ƒ: Benchmarking Neural Network Robustness to Common Corruptions and Perturbations
CORRUPTION_CATEGORIES = {
    "noise": [
        "gaussian_noise",
        "shot_noise",
        "impulse_noise",
        "speckle_noise",  # Extra
    ],
    "blur": [
        "defocus_blur",
        "glass_blur",
        "motion_blur",
        "zoom_blur",
        "gaussian_blur",  # Extra
    ],
    "weather": [
        "snow",
        "frost",
        "fog",
        "brightness",
        "spatter",  # Extra
    ],
    "digital": [
        "contrast",
        "elastic_transform",
        "pixelate",
        "jpeg_compression",
        "saturate",  # Extra
    ],
}

# æ‰å¹³åŒ–åˆ—è¡¨ï¼Œæ–¹ä¾¿éå†
CORRUPTIONS = [c for cat in CORRUPTION_CATEGORIES.values() for c in cat]

# 3ç§ä¸¥é‡ç¨‹åº¦ (æˆ–è€…å®Œæ•´ 1-5ï¼Œè¿™é‡Œä¿æŒ 1, 3, 5 ä»¥èŠ‚çœç©ºé—´ï¼Œæˆ–è€…æ”¹ä¸º range(1, 6))
# æ—¢ç„¶ç”¨æˆ·æƒ³è¦æ›´æ ‡å‡†çš„è¯„ä¼°ï¼Œè¿™é‡Œæ‰©å±•ä¸ºå®Œæ•´çš„ 1-5
SEVERITIES = [1, 3, 5]


# â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
# â•‘ Corruptionæ•°æ®é›†                                                              â•‘
# â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•


class CorruptionDataset:
    """Corruption è¯„ä¼°æ•°æ®é›† (Full Coverage æ¨¡å¼)

    ä»é¢„ç”Ÿæˆçš„ .npy æ–‡ä»¶åŠ è½½ corruption æ•°æ®ã€‚
    ä½¿ç”¨ `python -m ensemble.datasets.robustness.generate` é¢„ç”Ÿæˆæ•°æ®ã€‚

    æœ¬ç±»ä¾èµ–äº `metadata.json` æ–‡ä»¶ï¼Œè¯¥æ–‡ä»¶ç”±ç”Ÿæˆè„šæœ¬è‡ªåŠ¨åˆ›å»ºã€‚
    """

    # å¼•ç”¨æ¨¡å—çº§å¸¸é‡ (ä¿ç•™å…¼å®¹æ€§)
    CORRUPTIONS = CORRUPTIONS
    CATEGORIES = CORRUPTION_CATEGORIES
    SEVERITIES = SEVERITIES

    def __init__(self, dataset_name: str, root: str = "./data"):
        """Corruption æ•°æ®é›†æ„é€ å‡½æ•°"""
        if dataset_name not in DATASET_REGISTRY:
            raise ValueError(
                f"æœªçŸ¥æ•°æ®é›†: {dataset_name}. å¯ç”¨: {list(DATASET_REGISTRY.keys())}"
            )

        self.name = dataset_name
        DatasetClass = DATASET_REGISTRY[dataset_name]
        self.data_dir = Path(root) / f"{DatasetClass.NAME}-C"

        # 1. åŸºç¡€åˆå§‹åŒ–
        get_logger().info(f"ğŸ“¥ å‡†å¤‡åŠ è½½ Corruption æ•°æ®: {self.data_dir}...")
        self._verify_installation()
        self._init_statistics(DatasetClass)
        self._load_labels()

        get_logger().info("âœ… Corruption æ•°æ®é›†å‡†å¤‡å°±ç»ª (Full Coverage)")

    def _verify_installation(self):
        """ç¡®ä¿é¢„ç”Ÿæˆæ•°æ®åŒ…å·²å®‰è£…"""
        labels_path = self.data_dir / "labels.npy"
        if not labels_path.exists():
            raise FileNotFoundError(f"æœªæ‰¾åˆ°é¢„ç”Ÿæˆæ•°æ®: {labels_path}")

    def _init_statistics(self, DatasetClass):
        """åˆå§‹åŒ–æ•°æ®é›†ç»Ÿè®¡ä¿¡æ¯"""
        self.mean = torch.tensor(DatasetClass.MEAN).view(1, 3, 1, 1)
        self.std = torch.tensor(DatasetClass.STD).view(1, 3, 1, 1)

    def _load_labels(self):
        """åŠ è½½æ ‡ç­¾æ–‡ä»¶"""
        labels_path = self.data_dir / "labels.npy"
        if not labels_path.exists():
            raise FileNotFoundError(f"Missing labels file: {labels_path}")
        self.labels = torch.from_numpy(np.load(str(labels_path))).long()

    def get_loader(
        self, corruption_type: str, severity: int, config: "Config"
    ) -> DataLoader:
        """è·å–ç‰¹å®šæŸåç±»å‹å’Œä¸¥é‡ç¨‹åº¦çš„æ•°æ®åŠ è½½å™¨"""

        # 1. è§£æç›®æ ‡ç±»å‹
        target_types = self._resolve_types(corruption_type)

        # 2. æ”¶é›†æ•°æ®æ‰¹æ¬¡
        all_data, all_labels = [], []

        # å…¨é‡æ¨¡å¼ä¸‹ï¼Œæ¯ä¸ª corruption å¯¹åº”çš„éƒ½æ˜¯å®Œæ•´çš„ labels
        current_labels = self.labels

        for c_type in target_types:
            # åŠ è½½å›¾åƒæ•°æ®
            data = self._load_corruption(c_type, severity)

            # æ ¡éªŒæ•°æ®é•¿åº¦
            if len(data) != len(current_labels):
                raise ValueError(
                    f"Data length mismatch for {c_type}: data={len(data)}, labels={len(current_labels)}"
                )

            all_data.append(data)
            all_labels.append(current_labels)

        # 3. ç»„è£… DataLoader
        return self._prepare_dataloader(
            torch.cat(all_data, dim=0), torch.cat(all_labels, dim=0), config
        )

    def _resolve_types(self, corruption_type: str) -> list:
        """è§£æè¾“å…¥çš„ç±»å‹åç§°(å•ç±»æˆ–å…·ä½“ç±»å‹)"""
        if corruption_type in self.CATEGORIES:
            return self.CATEGORIES[corruption_type]
        if corruption_type in self.CORRUPTIONS:
            return [corruption_type]
        raise ValueError(f"æœªçŸ¥ Corruption ç±»å‹: {corruption_type}")

    def _prepare_dataloader(self, data, labels, config) -> DataLoader:
        """æ•´ç†å¹¶åˆ›å»º DataLoader"""
        dataset = TensorDataset(data, labels)
        return DataLoader(
            dataset,
            batch_size=config.batch_size,
            shuffle=False,
            num_workers=config.num_workers,
            pin_memory=config.pin_memory,
        )

    def _load_corruption(self, corruption_type: str, severity: int) -> torch.Tensor:
        """ä»é¢„ç”Ÿæˆæ–‡ä»¶åŠ è½½å•ä¸ª corruption ç±»å‹çš„æ•°æ®"""
        # 1. æ„é€ æ–‡ä»¶å
        filename = f"{corruption_type}.npy"

        # 2. è¯»å–å¯¹åº”ä¸¥é‡ç¨‹åº¦çš„æ•°æ®åˆ‡ç‰‡
        images_np = self._read_npy_slice(filename, severity)

        # 3. è½¬æ¢ä¸ºæ ‡å‡†åŒ–çš„ Tensor
        return self._postprocess_tensor(images_np)

    def _read_npy_slice(self, filename: str, severity: int) -> np.ndarray:
        """æ‰§è¡Œå…·ä½“çš„äºŒè¿›åˆ¶æ–‡ä»¶è¯»å–å’Œåˆ‡ç‰‡è®¡ç®—"""
        if severity not in self.SEVERITIES:
            raise ValueError(f"Severity å¿…é¡»åœ¨ {self.SEVERITIES} ä¸­, å¾—åˆ° {severity}")

        file_path = self.data_dir / filename
        if not file_path.exists():
            raise FileNotFoundError(f"æœªæ‰¾åˆ°æ•°æ®æ–‡ä»¶: {file_path}")

        # ä½¿ç”¨ mmap æ¨¡å¼è¯»å–ï¼Œé¿å…ä¸€æ¬¡æ€§åŠ è½½è¿‡å¤§æ–‡ä»¶ (è§†æƒ…å†µè€Œå®šï¼Œè¿™é‡Œå…ˆ load è¿›æ¥)
        # æ³¨æ„: å¦‚æœæ–‡ä»¶å·¨å¤§ï¼Œå»ºè®®æ”¹ç”¨ mmap_mode='r' å¹¶å°å¿ƒå¤„ç†
        data = np.load(str(file_path))

        # è®¡ç®—åˆ‡ç‰‡ç´¢å¼• (å‡è®¾æ•°æ®æŒ‰ severity æ’åºå †å )
        total_records = data.shape[0]
        n_sev = len(self.SEVERITIES)
        n_samples = total_records // n_sev

        if total_records % n_sev != 0:
            raise ValueError(f"æ•°æ®æ ¼å¼é”™è¯¯: {total_records} æ— æ³•è¢« {n_sev} æ•´é™¤")

        # å®šä½å¹¶åˆ‡ç‰‡
        sev_idx = self.SEVERITIES.index(severity)
        return data[sev_idx * n_samples : (sev_idx + 1) * n_samples]

    def _postprocess_tensor(self, images_np: np.ndarray) -> torch.Tensor:
        """å°† numpy å›¾åƒé˜µåˆ—è½¬æ¢ä¸ºæ ‡å‡†åŒ– PyTorch å¼ é‡"""
        # [N, H, W, 3] -> [N, 3, H, W]
        images_tensor = torch.from_numpy(images_np).permute(0, 3, 1, 2).float() / 255.0
        return (images_tensor - self.mean) / self.std
