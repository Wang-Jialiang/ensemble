"""
================================================================================
ç»Ÿä¸€æ•°æ®ç”Ÿæˆè„šæœ¬
================================================================================

æ”¯æŒä¸‰ç§æ•°æ®ç±»å‹çš„ç”Ÿæˆ:
- Corruption: ä½¿ç”¨ imagecorruptions åº“ç”ŸæˆæŸåæ•°æ®
- Domain Shift: ä½¿ç”¨ Stable Diffusion Img2Img ç”Ÿæˆé£æ ¼è¿ç§»æ•°æ®
- OOD: ä½¿ç”¨ Stable Diffusion Text2Img ç”Ÿæˆåˆ†å¸ƒå¤–æ•°æ®

ä½¿ç”¨ç¤ºä¾‹:
    # Corruption
    python -m ensemble.datasets.robustness.generate --type corruption --dataset eurosat

    # Domain Shift
    python -m ensemble.datasets.robustness.generate --type domain --dataset eurosat --styles sketch

    # OOD
    python -m ensemble.datasets.robustness.generate --type ood --dataset eurosat --num_samples 100
"""

import argparse
from pathlib import Path
from typing import Optional

import numpy as np
from PIL import Image
from tqdm import tqdm

from ...utils import ensure_dir, get_logger
from ..preloaded import DATASET_REGISTRY
from .corruption import CORRUPTIONS, SEVERITIES

# =============================================================================
# Corruption ç”Ÿæˆå™¨
# =============================================================================


class CorruptionGenerator:
    """Corruption ç”Ÿæˆå™¨ - åŸºäº imagecorruptions åº“

    ä½¿ç”¨ imagecorruptions åº“å®ç°ä¸ ImageNet-C ç›¸åŒçš„ corruption ç±»å‹ã€‚
    ä¾èµ–: pip install imagecorruptions
    """

    CORRUPTIONS = CORRUPTIONS
    SEVERITIES = SEVERITIES

    @staticmethod
    def apply(img: np.ndarray, corruption_type: str, severity: int = 5) -> np.ndarray:
        """å¯¹å•å¼ å›¾åƒåº”ç”¨ corruption"""
        try:
            from imagecorruptions import corrupt
        except ImportError:
            raise ImportError("éœ€è¦å®‰è£… imagecorruptions: pip install imagecorruptions")

        if corruption_type not in CorruptionGenerator.CORRUPTIONS:
            raise ValueError(f"Unknown corruption: {corruption_type}")

        if severity not in CorruptionGenerator.SEVERITIES:
            if not 1 <= severity <= 5:
                raise ValueError(f"Severity must be 1-5, got {severity}")

        img_uint8 = np.clip(img, 0, 255).astype(np.uint8)
        corrupted = corrupt(
            img_uint8, corruption_name=corruption_type, severity=severity
        )
        return corrupted.astype(np.float32)

    @staticmethod
    def apply_batch(
        images: np.ndarray,
        corruption_type: str,
        severity: int = 5,
        seed: Optional[int] = None,
    ) -> np.ndarray:
        """æ‰¹é‡åº”ç”¨ corruption"""
        if seed is not None:
            np.random.seed(seed)

        corrupted = []
        for img in images:
            c_img = CorruptionGenerator.apply(img, corruption_type, severity)
            corrupted.append(c_img)

        return np.stack(corrupted)


# =============================================================================
# Domain Shift ç”Ÿæˆå™¨
# =============================================================================


class DomainGenerator:
    """Domain Shift ç”Ÿæˆå™¨ - åŸºäº Stable Diffusion Img2Img

    ä½¿ç”¨ Stable Diffusion å°†åŸå§‹å›¾åƒè½¬æ¢ä¸ºä¸åŒé£æ ¼ã€‚
    ä¾èµ–: pip install diffusers transformers accelerate
    """

    # 4 ç§é£æ ¼ (prompt ç”¨äºå¼•å¯¼ Stable Diffusion)
    STYLES = {
        "sketch": "pencil sketch drawing",
        "painting": "oil painting artwork",
        "cartoon": "cartoon illustration style",
        "watercolor": "watercolor painting art",
    }

    # 3 ç§å¼ºåº¦ç­‰çº§ (ç±»ä¼¼ Corruption çš„ severity)
    STRENGTHS = [0.3, 0.5, 0.7]  # è½»åº¦ã€ä¸­åº¦ã€é‡åº¦

    def __init__(self, device: str = "cuda"):
        self.device = device
        self._pipe = None

    def _get_pipe(self):
        """å»¶è¿ŸåŠ è½½ pipeline"""
        if self._pipe is None:
            try:
                import torch
                from diffusers import StableDiffusionImg2ImgPipeline
            except ImportError:
                raise ImportError(
                    "éœ€è¦å®‰è£… diffusers: pip install diffusers transformers accelerate"
                )

            get_logger().info(
                f"ğŸ“¥ åŠ è½½ Stable Diffusion Img2Img æ¨¡å‹ (è®¾å¤‡: {self.device})..."
            )
            self._pipe = StableDiffusionImg2ImgPipeline.from_pretrained(
                "stabilityai/stable-diffusion-2-1",
                torch_dtype=torch.float16 if "cuda" in self.device else torch.float32,
            ).to(self.device)
            self._pipe.set_progress_bar_config(disable=True)

            # å°è¯•å¯ç”¨ xformers
            try:
                self._pipe.enable_xformers_memory_efficient_attention()
            except Exception:
                pass
        return self._pipe

    def apply_batch(
        self, images: np.ndarray, style: str, strength: float, batch_size: int = 16
    ) -> np.ndarray:
        """æ‰¹é‡é£æ ¼è½¬æ¢"""
        if style not in self.STYLES:
            raise ValueError(f"Unknown style: {style}")

        prompt = self.STYLES[style]
        pipe = self._get_pipe()
        all_results = []

        # è·å– GPU ID ä»¥ä¾¿è¿›åº¦æ¡ä¸é‡å 
        gpu_id = 0
        if "cuda:" in self.device:
            gpu_id = int(self.device.split(":")[-1])

        pbar = tqdm(
            range(0, len(images), batch_size),
            desc=f"      [{self.device}] {style}/{strength}",
            position=gpu_id,
            leave=False,
            mininterval=1.0,  # é¿å…é¢‘ç¹åˆ·æ–°
        )

        for i in pbar:
            batch = images[i : i + batch_size]
            original_size = (batch.shape[2], batch.shape[1])  # (W, H)

            # è½¬æ¢ä¸º PIL å¹¶è°ƒæ•´å¤§å°ä¸º 512
            pils = [
                Image.fromarray(img.astype(np.uint8)).resize(
                    (512, 512), Image.Resampling.LANCZOS
                )
                for img in batch
            ]

            # æ‰¹é‡ç”Ÿæˆ
            outputs = pipe(
                prompt=[prompt] * len(pils),
                image=pils,
                strength=strength,
                guidance_scale=7.5,
                num_inference_steps=30,
            ).images

            # æ¢å¤å°ºå¯¸å¹¶è½¬å› numpy
            transformed = [
                np.array(img.resize(original_size, Image.Resampling.LANCZOS))
                for img in outputs
            ]
            all_results.extend(transformed)

        return np.stack(all_results)

    def apply(self, img: np.ndarray, style: str, strength: float) -> np.ndarray:
        """å¯¹å•å¼ å›¾åƒåº”ç”¨é£æ ¼è¿ç§» (å°è£… apply_batch)"""
        return self.apply_batch(np.expand_dims(img, 0), style, strength, batch_size=1)[
            0
        ]


# =============================================================================
# OOD ç”Ÿæˆå™¨
# =============================================================================


class OODGenerator:
    """OOD ç”Ÿæˆå™¨ - åŸºäº Stable Diffusion Text2Img

    ä½¿ç”¨ Stable Diffusion ç”Ÿæˆä¸åŸæ•°æ®é›†æ— å…³çš„å›¾åƒã€‚
    ä¾èµ–: pip install diffusers transformers accelerate
    """

    # é¢„è®¾ OOD prompts (ä¸ä»»ä½•å¸¸è§å›¾åƒåˆ†ç±»æ•°æ®é›†æ— å…³)
    OOD_PROMPTS = [
        "abstract colorful geometric patterns",
        "underwater coral reef with tropical fish",
        "close-up of delicious food dishes",
        "city street at night with neon lights",
        "cartoon character illustration",
        "ancient stone ruins in jungle",
        "microscopic view of cells",
        "aurora borealis in night sky",
        "vintage book pages with text",
        "crystal formations in cave",
    ]

    def __init__(self, device: str = "cuda"):
        self.device = device
        self._pipe = None

    def _get_pipe(self):
        """å»¶è¿ŸåŠ è½½ pipeline"""
        if self._pipe is None:
            try:
                import torch
                from diffusers import StableDiffusionPipeline
            except ImportError:
                raise ImportError(
                    "éœ€è¦å®‰è£… diffusers: pip install diffusers transformers accelerate"
                )

            get_logger().info(
                f"ğŸ“¥ åŠ è½½ Stable Diffusion Text2Img æ¨¡å‹ (è®¾å¤‡: {self.device})..."
            )
            self._pipe = StableDiffusionPipeline.from_pretrained(
                "stabilityai/stable-diffusion-2-1",
                torch_dtype=torch.float16 if "cuda" in self.device else torch.float32,
            ).to(self.device)
            self._pipe.set_progress_bar_config(disable=True)

            # å°è¯•å¯ç”¨ xformers
            try:
                self._pipe.enable_xformers_memory_efficient_attention()
            except Exception:
                pass
        return self._pipe

    def generate_batch(
        self,
        num_samples: int,
        target_size: int = 64,
        batch_size: int = 16,
        seed: Optional[int] = None,
    ) -> np.ndarray:
        """æ‰¹é‡ç”Ÿæˆ OOD å›¾åƒ"""
        import random

        if seed is not None:
            random.seed(seed)

        pipe = self._get_pipe()
        all_results = []

        # è·å– GPU ID ä»¥ä¾¿è¿›åº¦æ¡ä¸é‡å 
        gpu_id = 0
        if "cuda:" in self.device:
            gpu_id = int(self.device.split(":")[-1])

        pbar = tqdm(
            range(0, num_samples, batch_size),
            desc=f"      [{self.device}] OOD ç”Ÿæˆ",
            position=gpu_id,
            leave=False,
            mininterval=1.0,
        )

        for i in pbar:
            current_bs = min(batch_size, num_samples - i)
            prompts = [random.choice(self.OOD_PROMPTS) for _ in range(current_bs)]

            # æ‰¹é‡ç”Ÿæˆ
            outputs = pipe(
                prompt=prompts,
                height=512,
                width=512,
                guidance_scale=7.5,
                num_inference_steps=30,
            ).images

            # è°ƒæ•´å°ºå¯¸å¹¶è½¬å› numpy
            transformed = [
                np.array(
                    img.resize((target_size, target_size), Image.Resampling.LANCZOS)
                )
                for img in outputs
            ]
            all_results.extend(transformed)

        return np.stack(all_results)

    def generate(self, target_size: int = 64, seed: Optional[int] = None) -> np.ndarray:
        """ç”Ÿæˆå•å¼  OOD å›¾åƒ (å°è£… generate_batch)"""
        return self.generate_batch(1, target_size, batch_size=1, seed=seed)[0]


# =============================================================================
# å¹¶è¡Œå¤„ç†åŠ©æ‰‹
# =============================================================================


def _process_single_corruption(args):
    """å•ç§ corruption å¤„ç†å‡½æ•° (ç”¨äº multiprocessing)"""
    corruption, images_np, severities, output_dir, seed = args
    all_severities = []
    for severity in severities:
        corrupted = CorruptionGenerator.apply_batch(
            images_np, corruption, severity, seed=seed
        )
        all_severities.append(corrupted.astype(np.uint8))

    stacked = np.concatenate(all_severities, axis=0)
    np.save(str(output_dir / f"{corruption}.npy"), stacked)
    return corruption


def _worker_domain(
    device,
    styles,
    strengths,
    images_np,
    labels_np,
    output_dir,
    dataset_name,
    batch_size,
):
    """Domain å·¥ä½œè€…çº¿ç¨‹ (ç”¨äº GPU å¹¶è¡Œ)"""
    generator = DomainGenerator(device=device)
    DatasetClass = DATASET_REGISTRY[dataset_name]

    for style in styles:
        for strength in strengths:
            get_logger().info(f"   [{device}] ç”Ÿæˆ: {style} (strength={strength})...")
            strength_dir = output_dir / style / str(strength)

            for class_idx in range(DatasetClass.NUM_CLASSES):
                ensure_dir(strength_dir / f"class_{class_idx:04d}")

            # ä½¿ç”¨åŒ…è£…å¥½çš„ apply_batch
            styled_images = generator.apply_batch(
                images_np, style, strength, batch_size=batch_size
            )

            # ä¿å­˜
            for i, (img, label) in enumerate(zip(styled_images, labels_np)):
                img_path = strength_dir / f"class_{label:04d}" / f"img_{i}.png"
                Image.fromarray(img).save(str(img_path))


def _worker_ood_gpu(gpu_id, n, target_size, bs, s, q):
    """OOD å·¥ä½œè€…çº¿ç¨‹ (ç”¨äº GPU å¹¶è¡Œ)"""
    generator = OODGenerator(device=f"cuda:{gpu_id}")
    imgs = generator.generate_batch(
        num_samples=n, target_size=target_size, batch_size=bs, seed=s + gpu_id
    )
    q.put(imgs)


# =============================================================================
# ç”Ÿæˆå‡½æ•°
# =============================================================================


def generate_corruption_dataset(
    dataset_name: str,
    root: str = "./data",
    seed: int = 42,
    force: bool = False,
) -> Path:
    """é¢„ç”Ÿæˆ corruption æ•°æ®é›†ï¼ˆä½¿ç”¨ CPU å¤šè¿›ç¨‹åŠ é€Ÿï¼‰"""
    import multiprocessing
    import os

    if dataset_name not in DATASET_REGISTRY:
        raise ValueError(
            f"æœªçŸ¥æ•°æ®é›†: {dataset_name}. å¯ç”¨: {list(DATASET_REGISTRY.keys())}"
        )

    DatasetClass = DATASET_REGISTRY[dataset_name]
    output_dir = Path(root) / f"{DatasetClass.NAME}-C"
    ensure_dir(output_dir)

    labels_path = output_dir / "labels.npy"
    if labels_path.exists() and not force:
        get_logger().info(
            f"âœ… {output_dir} å·²å­˜åœ¨ï¼Œè·³è¿‡ç”Ÿæˆ (ä½¿ç”¨ --force å¼ºåˆ¶é‡æ–°ç”Ÿæˆ)"
        )
        return output_dir

    get_logger().info(f"ğŸ”§ å¼€å§‹ç”Ÿæˆ {DatasetClass.NAME}-C (EPYC å¹¶è¡Œæ¨¡å¼)...")

    # åŠ è½½æµ‹è¯•é›†
    extra_kwargs = {}
    if not getattr(DatasetClass, "HAS_OFFICIAL_SPLIT", True):
        extra_kwargs["seed"] = seed
    test_dataset = DatasetClass(root=root, train=False, **extra_kwargs)

    # è½¬æ¢ä¸º numpy (H, W, C) æ ¼å¼
    images_np = test_dataset.images.permute(0, 2, 3, 1).numpy()
    labels_np = test_dataset.targets.numpy()
    total_samples = len(labels_np)

    # å‡†å¤‡å¹¶è¡Œå‚æ•°
    tasks = []
    for corruption in CORRUPTIONS:
        tasks.append((corruption, images_np, SEVERITIES, output_dir, seed))

    # ä½¿ç”¨æ‰€æœ‰å¯ç”¨çš„ CPU æ ¸å¿ƒ
    num_cpus = os.cpu_count()
    get_logger().info(f"   ä½¿ç”¨ {num_cpus} ä¸ªè¿›ç¨‹å¹¶è¡Œç”Ÿæˆ...")

    with multiprocessing.Pool(processes=min(len(CORRUPTIONS), num_cpus)) as pool:
        for _ in tqdm(
            pool.imap_unordered(_process_single_corruption, tasks),
            total=len(tasks),
            desc="   Corruption æ€»è¿›åº¦",
        ):
            pass

    # ä¿å­˜æ ‡ç­¾
    np.save(str(labels_path), labels_np)

    # ç»Ÿè®¡ä¿¡æ¯
    msg = f"âœ… {DatasetClass.NAME}-C ç”Ÿæˆå®Œæˆ: {len(CORRUPTIONS)} corruptions Ã— {total_samples} samples Ã— {len(SEVERITIES)} severities"
    get_logger().info(msg)
    return output_dir


def generate_domain_dataset(
    dataset_name: str,
    root: str = "./data",
    samples_per_group: Optional[int] = 1000,
    seed: int = 42,
    force: bool = False,
    batch_size: int = 16,
) -> Path:
    """é¢„ç”Ÿæˆ domain shift æ•°æ®é›†ï¼ˆåŒ GPU + æ‰¹é‡æ¨ç†åŠ é€Ÿï¼‰"""
    import multiprocessing

    import torch

    if dataset_name not in DATASET_REGISTRY:
        raise ValueError(f"æœªçŸ¥æ•°æ®é›†: {dataset_name}")

    styles = list(DomainGenerator.STYLES.keys())
    strengths = DomainGenerator.STRENGTHS
    DatasetClass = DATASET_REGISTRY[dataset_name]
    output_dir = Path(root) / f"{DatasetClass.NAME}-Domain"

    if output_dir.exists() and not force:
        get_logger().info(f"âœ… {output_dir} å·²å­˜åœ¨ï¼Œè·³è¿‡ç”Ÿæˆ")
        return output_dir

    get_logger().info(
        f"ğŸ”§ å¼€å§‹ç”Ÿæˆ {DatasetClass.NAME}-Domain (GPU å¹¶è¡Œ + Batch Size {batch_size})..."
    )

    # åŠ è½½å¹¶æŠ½æ ·
    extra_kwargs = {}
    if not getattr(DatasetClass, "HAS_OFFICIAL_SPLIT", True):
        extra_kwargs["seed"] = seed
    test_dataset = DatasetClass(root=root, train=False, **extra_kwargs)

    images_np = test_dataset.images.permute(0, 2, 3, 1).numpy()
    labels_np = test_dataset.targets.numpy()
    total_available = len(labels_np)
    target_n = min(samples_per_group or total_available, total_available)

    np.random.seed(seed)
    indices = np.random.permutation(total_available)[:target_n]
    images_np = images_np[indices]
    labels_np = labels_np[indices]

    # æ£€æµ‹ GPU å¹¶åˆ†å‘ä»»åŠ¡
    num_gpus = torch.cuda.device_count()
    if num_gpus == 0:
        get_logger().warning("æœªæ£€æµ‹åˆ° GPUï¼Œå°†å›é€€åˆ° CPU (å•è¿›ç¨‹)ï¼Œé€Ÿåº¦å¯èƒ½ä¼šéå¸¸æ…¢ã€‚")
        generator = DomainGenerator(device="cpu")
        for style in styles:
            for strength in strengths:
                get_logger().info(f"   ç”Ÿæˆ: {style} (strength={strength})...")
                strength_dir = output_dir / style / str(strength)
                for class_idx in range(DatasetClass.NUM_CLASSES):
                    ensure_dir(strength_dir / f"class_{class_idx:04d}")

                styled_images = generator.apply_batch(
                    images_np, style, strength, batch_size=batch_size
                )
                for i, (img, label) in enumerate(zip(styled_images, labels_np)):
                    img_path = strength_dir / f"class_{label:04d}" / f"img_{i}.png"
                    Image.fromarray(img).save(str(img_path))
        get_logger().info(f"âœ… {DatasetClass.NAME}-Domain ç”Ÿæˆå®Œæˆ!")
        return output_dir

    get_logger().info(f"   æ£€æµ‹åˆ° {num_gpus} ä¸ª GPU, å¼€å§‹åˆ†å‘ä»»åŠ¡...")

    processes = []
    # å°† styles å¹³åˆ†
    for i in range(num_gpus):
        gpu_styles = styles[i::num_gpus]
        if not gpu_styles:
            continue
        p = multiprocessing.Process(
            target=_worker_domain,
            args=(
                f"cuda:{i}",
                gpu_styles,
                strengths,
                images_np,
                labels_np,
                output_dir,
                dataset_name,
                batch_size,
            ),
        )
        p.start()
        processes.append(p)

    for p in processes:
        p.join()

    get_logger().info(f"âœ… {DatasetClass.NAME}-Domain ç”Ÿæˆå®Œæˆ!")
    return output_dir


def generate_ood_dataset(
    dataset_name: str,
    root: str = "./data",
    num_samples: int = 1000,
    seed: int = 42,
    force: bool = False,
    batch_size: int = 16,
) -> Path:
    """é¢„ç”Ÿæˆ OOD æ•°æ®é›†ï¼ˆåŒ GPU + æ‰¹é‡ç”ŸæˆåŠ é€Ÿï¼‰"""
    import multiprocessing

    import torch

    if dataset_name not in DATASET_REGISTRY:
        raise ValueError(
            f"æœªçŸ¥æ•°æ®é›†: {dataset_name}. å¯ç”¨: {list(DATASET_REGISTRY.keys())}"
        )

    DatasetClass = DATASET_REGISTRY[dataset_name]
    output_dir = Path(root) / f"{DatasetClass.NAME}-OOD"
    ensure_dir(output_dir)

    images_path = output_dir / "images.npy"
    if images_path.exists() and not force:
        get_logger().info(
            f"âœ… {output_dir} å·²å­˜åœ¨ï¼Œè·³è¿‡ç”Ÿæˆ (ä½¿ç”¨ --force å¼ºåˆ¶é‡æ–°ç”Ÿæˆ)"
        )
        return output_dir

    get_logger().info(
        f"ğŸ”§ å¼€å§‹ç”Ÿæˆ {DatasetClass.NAME}-OOD ({num_samples} å¼ , GPU å¹¶è¡Œæ¨¡å¼)..."
    )

    num_gpus = torch.cuda.device_count()
    if num_gpus == 0:
        get_logger().warning("æœªæ£€æµ‹åˆ° GPUï¼Œå°†ä½¿ç”¨ CPU è¿›è¡Œ OOD ç”Ÿæˆï¼Œé€Ÿåº¦ä¼šéå¸¸æ…¢ã€‚")
        # Fallback to CPU if no GPU is found
        generator = OODGenerator(device="cpu")
        images_array = generator.generate_batch(
            num_samples=num_samples,
            target_size=DatasetClass.IMAGE_SIZE,
            batch_size=batch_size,
            seed=seed,
        )
        np.save(str(images_path), images_array)
    elif num_gpus == 1:
        # å• GPU æ¨¡å¼
        get_logger().info("   æ£€æµ‹åˆ° 1 ä¸ª GPU (cuda:0)ï¼Œä½¿ç”¨å• GPU æ¨¡å¼ç”Ÿæˆ...")
        generator = OODGenerator(device="cuda:0")
        images_array = generator.generate_batch(
            num_samples=num_samples,
            target_size=DatasetClass.IMAGE_SIZE,
            batch_size=batch_size,
            seed=seed,
        )
        np.save(str(images_path), images_array)
    else:
        # å¤š GPU å¹¶è¡Œ
        get_logger().info(f"   æ£€æµ‹åˆ° {num_gpus} ä¸ª GPUï¼Œä½¿ç”¨å¤š GPU å¹¶è¡Œæ¨¡å¼ç”Ÿæˆ...")
        samples_per_gpu = num_samples // num_gpus
        results_queue = multiprocessing.Queue()

        processes = []
        for i in range(num_gpus):
            # åˆ†é…æ ·æœ¬ï¼Œç¡®ä¿æ€»æ•°æ­£ç¡®
            n = samples_per_gpu + (num_samples % num_gpus if i == num_gpus - 1 else 0)
            p = multiprocessing.Process(
                target=_worker_ood_gpu,
                args=(i, n, DatasetClass.IMAGE_SIZE, batch_size, seed, results_queue),
            )
            p.start()
            processes.append(p)

        all_imgs = []
        for _ in range(num_gpus):
            all_imgs.append(results_queue.get())
        for p in processes:
            p.join()

        final_array = np.concatenate(all_imgs, axis=0)
        np.save(str(images_path), final_array)

    get_logger().info(f"âœ… {DatasetClass.NAME}-OOD ç”Ÿæˆå®Œæˆ: {num_samples} å¼ ")
    return output_dir


# =============================================================================
# CLI å…¥å£
# =============================================================================


def main():
    parser = argparse.ArgumentParser(
        description="ç»Ÿä¸€æ•°æ®ç”Ÿæˆè„šæœ¬ (Corruption / Domain Shift / OOD)"
    )
    parser.add_argument(
        "--type",
        type=str,
        required=True,
        choices=["corruption", "domain", "ood"],
        help="ç”Ÿæˆç±»å‹: corruption, domain, ood",
    )
    parser.add_argument(
        "--dataset",
        type=str,
        required=True,
        choices=list(DATASET_REGISTRY.keys()),
        help="æ•°æ®é›†åç§°",
    )
    parser.add_argument(
        "--root",
        type=str,
        default="./data",
        help="æ•°æ®æ ¹ç›®å½•",
    )
    parser.add_argument(
        "--seed",
        type=int,
        default=42,
        help="éšæœºç§å­",
    )
    parser.add_argument(
        "--force",
        action="store_true",
        help="å¼ºåˆ¶é‡æ–°ç”Ÿæˆ",
    )
    parser.add_argument(
        "--samples_per_group",
        type=int,
        default=1000,
        help="æ¯ç»„æ ·æœ¬æ•°ï¼ˆä»… Domain/OODï¼‰ã€‚Domain: æ¯é£æ ¼Ã—å¼ºåº¦; OOD: æ€»æ•°ã€‚Corruption å§‹ç»ˆä½¿ç”¨å…¨é‡æµ‹è¯•é›†",
    )
    parser.add_argument(
        "--batch_size",
        type=int,
        default=16,
        help="æ¸²æŸ“ç”Ÿæˆæ—¶çš„ Batch Size (Stable Diffusion ä¼˜åŒ–)",
    )
    args = parser.parse_args()

    if args.type == "corruption":
        # Corruption ä½¿ç”¨å…¨é‡æµ‹è¯•é›†ï¼ˆCPU æ“ä½œï¼Œé€Ÿåº¦å¿«ï¼‰
        generate_corruption_dataset(
            dataset_name=args.dataset,
            root=args.root,
            seed=args.seed,
            force=args.force,
        )
    elif args.type == "domain":
        generate_domain_dataset(
            dataset_name=args.dataset,
            root=args.root,
            samples_per_group=args.samples_per_group,
            seed=args.seed,
            force=args.force,
            batch_size=args.batch_size,
        )
    elif args.type == "ood":
        # OOD ç”¨ samples_per_group Ã— 2 (è¡¥å¿ Text2Img æ›´æ…¢)
        ood_samples = args.samples_per_group * 2
        generate_ood_dataset(
            dataset_name=args.dataset,
            root=args.root,
            num_samples=ood_samples,
            seed=args.seed,
            force=args.force,
            batch_size=args.batch_size,
        )


if __name__ == "__main__":
    main()
