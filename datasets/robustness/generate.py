"""
================================================================================
ç»Ÿä¸€æ•°æ®ç”Ÿæˆè„šæœ¬ (SDXL Lightning ç‰ˆ)
================================================================================

æ”¯æŒæ•°æ®ç±»å‹çš„ç”Ÿæˆ:
- Corruption: ä½¿ç”¨ imagecorruptions åº“ç”ŸæˆæŸåæ•°æ®
- OOD: ä½¿ç”¨ SDXL Lightning Text2Img ç”Ÿæˆåˆ†å¸ƒå¤–æ•°æ®

ä½¿ç”¨ç¤ºä¾‹:
    python -m ensemble.datasets.robustness.generate --type corruption --dataset cifar10
    python -m ensemble.datasets.robustness.generate --type ood --dataset cifar10
"""

import argparse
import multiprocessing
import os
import warnings
from pathlib import Path
from typing import Optional

# å¼ºåˆ¶ä½¿ç”¨ spawn å¯åŠ¨æ–¹æ³•ï¼Œè§£å†³ CUDA åœ¨ fork å­è¿›ç¨‹ä¸­æ— æ³•é‡æ–°åˆå§‹åŒ–çš„é—®é¢˜
# å¿…é¡»åœ¨ä»»ä½• CUDA è°ƒç”¨ä¹‹å‰è®¾ç½®
try:
    multiprocessing.set_start_method("spawn", force=True)
except RuntimeError:
    pass  # å·²ç»è®¾ç½®è¿‡äº†

import numpy as np
from PIL import Image

from ...utils import console


def patch_dependencies():
    """Monkey-patch dependencies for imagecorruptions compatibility."""
    try:
        import skimage.filters

        original_gaussian = skimage.filters.gaussian

        def patched_gaussian(*args, **kwargs):
            if "multichannel" in kwargs:
                multichannel = kwargs.pop("multichannel")
                if multichannel and "channel_axis" not in kwargs:
                    kwargs["channel_axis"] = -1
            return original_gaussian(*args, **kwargs)

        skimage.filters.gaussian = patched_gaussian
    except (ImportError, AttributeError):
        pass
    try:
        import numpy as np

        if not hasattr(np, "float_"):
            np.float_ = np.float64
    except (ImportError, AttributeError):
        pass


patch_dependencies()

import torch
from safetensors.torch import load_file

warnings.filterwarnings("ignore", category=UserWarning, module="pkg_resources")
warnings.filterwarnings("ignore", category=UserWarning, module="imagecorruptions")
warnings.filterwarnings("ignore", category=RuntimeWarning, module="imagecorruptions")
warnings.filterwarnings("ignore", "invalid value encountered in divide")
warnings.filterwarnings("ignore", "invalid value encountered in cast")
warnings.filterwarnings("ignore", category=FutureWarning, module="diffusers")

try:
    from diffusers import (
        EulerDiscreteScheduler,
        StableDiffusionXLImg2ImgPipeline,
        StableDiffusionXLPipeline,
        UNet2DConditionModel,
    )
except ImportError:
    pass

from ...config import Config
from ...utils import ensure_dir, get_logger
from ..preloaded import DATASET_REGISTRY
from .corruption import CORRUPTIONS, SEVERITIES

# =============================================================================
# å¯è§†åŒ–å·¥å…·
# =============================================================================


def save_visual_comparison(
    original_imgs: np.ndarray,
    processed_imgs: np.ndarray,
    output_path: Path,
    title: str,
    num_samples: int = 8,
):
    """ä¿å­˜åŸå§‹å›¾åƒä¸å¤„ç†åå›¾åƒçš„å¯¹æ¯”ç½‘æ ¼"""
    n = min(len(original_imgs), num_samples)
    if n == 0:
        return

    indices = np.linspace(0, len(original_imgs) - 1, n, dtype=int)
    orig = original_imgs[indices]
    proc = processed_imgs[indices]

    h, w = orig.shape[1:3]
    grid = Image.new("RGB", (w * n, h * 2))

    for i, (o, p) in enumerate(zip(orig, proc)):
        grid.paste(Image.fromarray(o.astype(np.uint8)), (i * w, 0))
        grid.paste(Image.fromarray(p.astype(np.uint8)), (i * w, h))

    ensure_dir(output_path.parent)
    grid.save(str(output_path))
    get_logger().info(f"ğŸ“Š å¯è§†åŒ–ä¿å­˜: {output_path}")


# =============================================================================
# å›¾åƒå¤„ç†å·¥å…·
# =============================================================================


def _prepare_pil_batch(images_np: np.ndarray, target_size: int = 512):
    """å°† numpy æ‰¹é‡å›¾åƒè½¬æ¢ä¸º PIL æ ¼å¼å¹¶ç»Ÿä¸€ç¼©æ”¾ï¼ˆ512 å¯¹ CIFAR-10 è¶³å¤Ÿï¼‰"""
    return [
        Image.fromarray(img.astype(np.uint8)).resize(
            (target_size, target_size), Image.LANCZOS
        )
        for img in images_np
    ]


def _convert_to_numpy_batch(images_pil: list, target_size: tuple):
    """å°† PIL æ‰¹é‡å›¾åƒæ¢å¤åˆ°ç›®æ ‡å°ºå¯¸å¹¶è½¬å› numpy æ ¼å¼"""
    return [np.array(img.resize(target_size, Image.LANCZOS)) for img in images_pil]


def _get_gpu_id(device: str):
    """ä»è®¾å¤‡å­—ç¬¦ä¸²ä¸­æå– GPU ID"""
    try:
        return int(device.split(":")[-1])
    except (ValueError, IndexError):
        return 0


def _check_existing_dataset(output_dir: Path, force: bool):
    """æ£€æŸ¥æ•°æ®é›†æ˜¯å¦å·²å­˜åœ¨"""
    if output_dir.exists() and not force:
        get_logger().info(f"â­ï¸ æ•°æ®é›†å·²å­˜åœ¨: {output_dir}ï¼Œè·³è¿‡ç”Ÿæˆ")
        return True
    ensure_dir(output_dir)
    return False


def _load_test_set_numpy(DatasetClass, root, seed=42):
    """åŠ è½½æµ‹è¯•é›†å¹¶è½¬æ¢ä¸º numpy æ ¼å¼"""
    extra_kwargs = {}
    if not getattr(DatasetClass, "HAS_OFFICIAL_SPLIT", True):
        extra_kwargs["seed"] = seed
    dataset = DatasetClass(root=root, train=False, **extra_kwargs)
    images_np = dataset.images.permute(0, 2, 3, 1).numpy()
    labels_np = dataset.targets.numpy()
    return images_np, labels_np


def _sample_dataset(images_np, labels_np, n, seed=42):
    """å¯¹æ•°æ®é›†è¿›è¡ŒéšæœºæŠ½æ ·"""
    if n is None or n >= len(images_np):
        return images_np, labels_np
    np.random.seed(seed)
    indices = np.random.choice(len(images_np), size=n, replace=False)
    return images_np[indices], labels_np[indices]


# =============================================================================
# Corruption ç”Ÿæˆå™¨
# =============================================================================


class CorruptionGenerator:
    """Corruption ç”Ÿæˆå™¨ - åŸºäº imagecorruptions åº“"""

    CORRUPTIONS = CORRUPTIONS
    SEVERITIES = SEVERITIES

    @staticmethod
    def apply(img: np.ndarray, corruption_type: str, severity: int = 5) -> np.ndarray:
        """å¯¹å•å¼ å›¾åƒåº”ç”¨ corruption"""
        try:
            from imagecorruptions import corrupt
        except ImportError:
            raise ImportError("éœ€è¦å®‰è£… imagecorruptions: pip install imagecorruptions")

        if corruption_type not in CorruptionGenerator.CORRUPTIONS:
            raise ValueError(f"Unknown corruption: {corruption_type}")

        img_uint8 = np.clip(img, 0, 255).astype(np.uint8)
        corrupted = corrupt(
            img_uint8, corruption_name=corruption_type, severity=severity
        )
        return corrupted.astype(np.float32)

    @staticmethod
    def apply_batch(
        images: np.ndarray,
        corruption_type: str,
        severity: int = 5,
        seed: Optional[int] = None,
    ) -> np.ndarray:
        """æ‰¹é‡åº”ç”¨ corruption"""
        if seed is not None:
            np.random.seed(seed)
        return np.stack(
            [
                CorruptionGenerator.apply(img, corruption_type, severity)
                for img in images
            ]
        )


# =============================================================================
# SDXL Lightning Pipeline åŠ è½½å™¨
# =============================================================================


class LightningPipelineLoader:
    """SDXL Lightning Pipeline åŠ è½½å™¨ (å•ä¾‹æ¨¡å¼)"""

    _text2img_cache = {}
    _img2img_cache = {}

    @classmethod
    def get_text2img(
        cls, device: str, base_model: str, repo: str, ckpt: str
    ) -> "StableDiffusionXLPipeline":
        """è·å– Text2Img Pipeline (å¼ºåˆ¶æœ¬åœ°å•æ–‡ä»¶åŠ è½½)"""
        return cls._get_pipeline(
            device,
            base_model,
            repo,
            ckpt,
            StableDiffusionXLPipeline,
            cls._text2img_cache,
            "Text2Img",
        )

    @classmethod
    def get_img2img(
        cls, device: str, base_model: str, repo: str, ckpt: str
    ) -> "StableDiffusionXLImg2ImgPipeline":
        """è·å– Img2Img Pipeline (å¼ºåˆ¶æœ¬åœ°å•æ–‡ä»¶åŠ è½½)"""
        return cls._get_pipeline(
            device,
            base_model,
            repo,
            ckpt,
            StableDiffusionXLImg2ImgPipeline,
            cls._img2img_cache,
            "Img2Img",
        )

    @classmethod
    def _get_pipeline(
        cls,
        device: str,
        base_model: str,
        repo: str,
        ckpt: str,
        pipe_cls,
        cache,
        name: str,
    ):
        """é€šç”¨ Pipeline åŠ è½½é€»è¾‘ (æ”¯æŒå…¨ç¦»çº¿ YAML é…ç½®)"""
        if device not in cache:
            get_logger().info(
                f"ğŸ“¥ [{device}] æ­£åœ¨ä»æœ¬åœ°æ–‡ä»¶åŠ è½½ SDXL Lightning {name}..."
            )

            if not os.path.isfile(base_model):
                raise FileNotFoundError(f"åŸºç¡€æƒé‡æ–‡ä»¶æœªæ‰¾åˆ°: {base_model}")

            # å¯»æ‰¾é…å¥—çš„ç¦»çº¿é…ç½®æ–‡ä»¶ (.yaml)
            config_path = base_model.rsplit(".", 1)[0] + ".yaml"
            original_config = None
            if os.path.exists(config_path):
                get_logger().info(f"ğŸ“œ å‘ç°é…å¥—ç¦»çº¿é…ç½®: {config_path}")
                original_config = config_path
            else:
                # å°è¯•åœ¨è¯¥ç›®å½•ä¸‹å¯»æ‰¾ä»»ä½•ä¸€ä¸ª .yaml æ–‡ä»¶ä½œä¸ºå¤‡é€‰
                yaml_files = list(Path(base_model).parent.glob("*.yaml"))
                if yaml_files:
                    original_config = str(yaml_files[0])
                    get_logger().info(f"ğŸ“œ è‡ªåŠ¨åŒ¹é…ç›®å½•ä¸‹çš„é…ç½®: {original_config}")

            # å¯»æ‰¾é…å¥—çš„ CLIP å­—å…¸é…ç½®ç›®å½• (ç”¨äºç¦»çº¿ Tokenizer/TextEncoder)
            # ä¼˜å…ˆå¯»æ‰¾ä¸æ¨¡å‹åŒç›®å½•ä¸‹çš„ 'config' æ–‡ä»¶å¤¹
            config_dir = os.path.join(os.path.dirname(base_model), "config")
            local_config = None
            if os.path.isdir(config_dir):
                get_logger().info(f"ğŸ“š å‘ç°æœ¬åœ°ç»„ä»¶é…ç½®ç›®å½•: {config_dir}")
                local_config = config_dir

            # å¼ºåˆ¶æœ¬åœ°å•æ–‡ä»¶åŠ è½½ (å¦‚æœæä¾›äº† original_config å’Œ local_configï¼Œåˆ™å¯å…¨ç¦»çº¿è¿è¡Œ)
            pipe = pipe_cls.from_single_file(
                base_model,
                original_config=original_config,
                config=local_config,
                torch_dtype=torch.float16,
                local_files_only=True,
            ).to(device)

            # æ³¨å…¥ Lightning æƒé‡
            cls._apply_lightning_to_pipe(pipe, device, repo, ckpt)

            pipe.scheduler = EulerDiscreteScheduler.from_config(
                pipe.scheduler.config, timestep_spacing="trailing"
            )
            pipe.set_progress_bar_config(disable=True)
            cls._try_enable_optimizations(pipe)
            cache[device] = pipe
        return cache[device]

    @classmethod
    def _apply_lightning_to_pipe(cls, pipe, device: str, repo: str, ckpt: str):
        """å°† Lightning æƒé‡æ³¨å…¥åˆ°ç°æœ‰ Pipeline çš„ UNet ä¸­"""
        local_path = Path(repo) / ckpt
        if not local_path.exists():
            raise FileNotFoundError(f"Lightning æƒé‡æ–‡ä»¶æœªæ‰¾åˆ°: {local_path}")

        get_logger().info(f"ğŸš€ åŠ è½½æœ¬åœ° Lightning æƒé‡: {local_path}")
        state_dict = load_file(str(local_path), device=device)
        pipe.unet.load_state_dict(state_dict)

    @staticmethod
    def _try_enable_optimizations(pipe):
        """å°è¯•å¯ç”¨æ˜¾å­˜ä¼˜åŒ–å’ŒåŠ é€Ÿ"""
        # VAE slicing: é™ä½ VAE ç¼–è§£ç çš„å³°å€¼æ˜¾å­˜
        try:
            pipe.enable_vae_slicing()
        except Exception:
            pass

        # VAE tiling: æ”¯æŒä»»æ„å¤§å°è¾“å…¥
        try:
            pipe.enable_vae_tiling()
        except Exception:
            pass

        # xformers: é«˜æ•ˆæ³¨æ„åŠ›æœºåˆ¶ (éœ€è¦å®‰è£… xformers)
        try:
            pipe.enable_xformers_memory_efficient_attention()
            get_logger().info("   âš¡ å·²å¯ç”¨ xformers åŠ é€Ÿ")
        except Exception:
            pass

        # torch.compile: å·²ç¦ç”¨
        # åŸå› : SDXL UNet é¦–æ¬¡ç¼–è¯‘éœ€è¦ 10-30 åˆ†é’Ÿï¼Œå¯¹äº Lightning 4-step æ¨ç†æ”¶ç›Šå¾ˆå°
        # å¦‚æœéœ€è¦å¤§é‡ç”Ÿæˆï¼Œå¯ä»¥è€ƒè™‘å¯ç”¨ï¼Œä½†éœ€è¦ç­‰å¾…é¦–æ¬¡ç¼–è¯‘å®Œæˆ
        # try:
        #     import torch
        #     if hasattr(torch, "compile") and torch.cuda.is_available():
        #         pipe.unet = torch.compile(pipe.unet, mode="max-autotune", fullgraph=True)
        #         get_logger().info("   âš¡ å·²å¯ç”¨ torch.compile åŠ é€Ÿ")
        # except Exception:
        #     pass


# =============================================================================
# OOD ç”Ÿæˆå™¨ (SDXL Lightning)
# =============================================================================


class OODGenerator:
    """OOD ç”Ÿæˆå™¨ - åŸºäº SDXL Lightning Text2Img"""

    def __init__(
        self,
        device: str = "cuda",
        base_model: str = "stabilityai/stable-diffusion-xl-base-1.0",
        lightning_repo: str = "ByteDance/SDXL-Lightning",
        lightning_ckpt: str = "sdxl_lightning_4step_unet.safetensors",
        prompts: Optional[list] = None,
        num_steps: int = 4,
        sdxl_height: int = 1024,
        sdxl_width: int = 1024,
        guidance_scale: float = 0.0,
    ):
        self.device = device
        self.base_model = base_model
        self.lightning_repo = lightning_repo
        self.lightning_ckpt = lightning_ckpt
        if prompts is None:
            from ...config import Config

            prompts = Config().generation.ood_prompts
        self.prompts = prompts
        self.num_steps = num_steps
        self.sdxl_height = sdxl_height
        self.sdxl_width = sdxl_width
        self.guidance_scale = guidance_scale
        self._pipe = None

    def _get_pipe(self):
        """è·å– Text2Img Pipeline"""
        if self._pipe is None:
            self._pipe = LightningPipelineLoader.get_text2img(
                self.device, self.base_model, self.lightning_repo, self.lightning_ckpt
            )
        return self._pipe

    def generate_batch(
        self,
        num_samples: int,
        target_size: int = 64,
        batch_size: int = 24,
        seed: Optional[int] = None,
    ) -> np.ndarray:
        """æ‰¹é‡ç”Ÿæˆ OOD å›¾åƒ (resize åçš„å°å°ºå¯¸)"""
        import random

        if seed is not None:
            random.seed(seed)

        pipe = self._get_pipe()
        results = []

        from rich.progress import (
            BarColumn,
            Progress,
            TaskProgressColumn,
            TextColumn,
            TimeRemainingColumn,
        )

        with Progress(
            TextColumn("[progress.description]{task.description}"),
            BarColumn(),
            TaskProgressColumn(),
            TimeRemainingColumn(),
            console=console,
            transient=True,
        ) as progress:
            task_id = progress.add_task(
                f"      [{self.device}] OOD ç”Ÿæˆ", total=num_samples
            )

            for i in range(0, num_samples, batch_size):
                current_bs = min(batch_size, num_samples - i)
                prompts = [random.choice(self.prompts) for _ in range(current_bs)]

                outputs = pipe(
                    prompt=prompts,
                    height=self.sdxl_height,
                    width=self.sdxl_width,
                    guidance_scale=self.guidance_scale,
                    num_inference_steps=self.num_steps,
                ).images

                results.extend(
                    _convert_to_numpy_batch(outputs, (target_size, target_size))
                )
                progress.update(task_id, advance=current_bs)

        return np.stack(results)

    def generate_hires_samples(
        self,
        num_samples: int,
        seed: Optional[int] = None,
    ) -> np.ndarray:
        """ç”Ÿæˆå°‘é‡é«˜åˆ†è¾¨ç‡åŸå›¾ (ä»…ç”¨äºå¯è§†åŒ–)"""
        import random

        if seed is not None:
            random.seed(seed)

        pipe = self._get_pipe()
        results = []

        for _ in range(num_samples):
            prompt = random.choice(self.prompts)
            output = pipe(
                prompt=prompt,
                height=self.sdxl_height,
                width=self.sdxl_width,
                guidance_scale=self.guidance_scale,
                num_inference_steps=self.num_steps,
            ).images[0]
            results.append(np.array(output))

        return np.stack(results)


# =============================================================================
# å¹¶è¡Œå¤„ç†åŠ©æ‰‹
# =============================================================================


def _process_single_corruption(args):
    """å•ç§ corruption å¤„ç†å‡½æ•° (ç”¨äº multiprocessing)"""
    corruption, images_np, severities, output_dir, seed, slice_obj = args

    # åˆ‡ç‰‡å¤„ç†: åªå¤„ç†åˆ†é…ç»™è¯¥ corruption çš„éƒ¨åˆ†æ•°æ®
    if slice_obj is not None:
        images_to_process = images_np[slice_obj]
    else:
        images_to_process = images_np

    all_severities = []
    for severity in severities:
        corrupted = CorruptionGenerator.apply_batch(
            images_to_process, corruption, severity, seed=seed
        )
        all_severities.append(corrupted.astype(np.uint8))

    stacked = np.concatenate(all_severities, axis=0)
    np.save(str(output_dir / f"{corruption}.npy"), stacked)
    return corruption


def _worker_ood_gpu(
    gpu_id,
    n,
    target_size,
    bs,
    seed,
    q,
    base_model,
    lightning_repo,
    lightning_ckpt,
    prompts,
    num_steps,
):
    """OOD å·¥ä½œè€…çº¿ç¨‹ (ç”¨äº GPU å¹¶è¡Œ)"""
    generator = OODGenerator(
        device=f"cuda:{gpu_id}",
        base_model=base_model,
        lightning_repo=lightning_repo,
        lightning_ckpt=lightning_ckpt,
        prompts=prompts,
        num_steps=num_steps,
    )
    imgs_resized = generator.generate_batch(
        num_samples=n, target_size=target_size, batch_size=bs, seed=seed + gpu_id
    )
    q.put(imgs_resized)


# =============================================================================
# ç”Ÿæˆå‡½æ•°
# =============================================================================


def generate_corruption_dataset(
    dataset_name: str,
    root: str = "./data",
    seed: int = 42,
    force: bool = False,
) -> Path:
    """é¢„ç”Ÿæˆ corruption æ•°æ®é›† (ä½¿ç”¨ CPU å¤šè¿›ç¨‹åŠ é€Ÿ) - é»˜è®¤é‡‡ç”¨ç±»åˆ«å‡è¡¡å‡è¡¡åˆ‡åˆ†"""
    import math
    import multiprocessing
    import os

    if dataset_name not in DATASET_REGISTRY:
        raise ValueError(f"æœªçŸ¥æ•°æ®é›†: {dataset_name}")

    DatasetClass = DATASET_REGISTRY[dataset_name]
    output_dir = Path(root) / f"{DatasetClass.NAME}-C"

    if _check_existing_dataset(output_dir, force):
        return output_dir

    get_logger().info(
        f"ğŸ”§ ç”Ÿæˆ Corruption: {DatasetClass.NAME}-C (Balanced Strategy)..."
    )

    images_np, labels_np = _load_test_set_numpy(DatasetClass, root, seed)
    total_samples = len(labels_np)

    # === æ„å»ºç”Ÿæˆä»»åŠ¡ (Category-Balanced Slicing) ===
    tasks = []

    # æŒ‰ç…§ç±»åˆ«åˆ†ç»„åˆ†é…æ•°æ®ç‰‡æ®µ
    from .corruption import CORRUPTION_CATEGORIES

    for category, corruption_list in CORRUPTION_CATEGORIES.items():
        num_types = len(corruption_list)
        chunk_size = math.ceil(total_samples / num_types)

        for i, corruption in enumerate(corruption_list):
            start_idx = i * chunk_size
            end_idx = min((i + 1) * chunk_size, total_samples)

            # å¦‚æœèµ·å§‹ç´¢å¼•è¶…å‡ºèŒƒå›´ (ä¾‹å¦‚å‘ä¸Šå–æ•´å¯¼è‡´æº¢å‡º)ï¼Œä¿®æ­£ä¸ºæœ€åä¸€æ®µæˆ–ç©º
            if start_idx >= total_samples:
                # ç†è®ºä¸Š ceil ä¸ä¼šå‘ç”Ÿè¿™ç§æƒ…å†µï¼Œé™¤é num_types > total_samplesï¼Œè¿™é‡Œåšä¸ªå…œåº•
                start_idx = total_samples
                end_idx = total_samples

            slice_obj = slice(start_idx, end_idx)
            tasks.append(
                (corruption, images_np, SEVERITIES, output_dir, seed, slice_obj)
            )

    # ===============================================

    num_cpus = os.cpu_count()

    from rich.progress import (
        BarColumn,
        Progress,
        TaskProgressColumn,
        TextColumn,
        TimeRemainingColumn,
    )

    with Progress(
        TextColumn("[progress.description]{task.description}"),
        BarColumn(),
        TaskProgressColumn(),
        TimeRemainingColumn(),
        console=console,
    ) as progress:
        task_id = progress.add_task("   Corruption æ€»è¿›åº¦", total=len(tasks))

        with multiprocessing.Pool(processes=min(len(tasks), num_cpus)) as pool:
            for _ in pool.imap_unordered(_process_single_corruption, tasks):
                progress.update(task_id, advance=1)

    np.save(str(output_dir / "labels.npy"), labels_np)

    get_logger().info(
        f"âœ… {DatasetClass.NAME}-C ç”Ÿæˆå®Œæˆ: {len(tasks)} corruptions (Category-Balanced)"
    )
    return output_dir


def generate_ood_dataset(
    dataset_name: str,
    root: str = "./data",
    num_samples: int = 1000,
    seed: int = 42,
    force: bool = False,
    batch_size: int = 24,
    base_model: str = "stabilityai/stable-diffusion-xl-base-1.0",
    lightning_repo: str = "ByteDance/SDXL-Lightning",
    lightning_ckpt: str = "sdxl_lightning_4step_unet.safetensors",
    prompts: Optional[list] = None,
    num_steps: int = 4,
) -> Path:
    """é¢„ç”Ÿæˆ OOD æ•°æ®é›† (ä»…ä¿å­˜ resize åçš„å°å›¾)"""
    import time

    if dataset_name not in DATASET_REGISTRY:
        raise ValueError(f"æœªçŸ¥æ•°æ®é›†: {dataset_name}")

    DatasetClass = DATASET_REGISTRY[dataset_name]
    output_dir = Path(root) / f"{DatasetClass.NAME}-OOD"

    if _check_existing_dataset(output_dir, force):
        return output_dir

    get_logger().info(
        f"ğŸ”§ ç”Ÿæˆ OOD: {DatasetClass.NAME} ({num_samples} å¼ , SDXL Lightning 4-step)"
    )

    start_time = time.time()
    num_gpus = torch.cuda.device_count()
    if num_gpus <= 1:
        device = "cuda:0" if num_gpus == 1 else "cpu"
        generator = OODGenerator(
            device=device,
            base_model=base_model,
            lightning_repo=lightning_repo,
            lightning_ckpt=lightning_ckpt,
            prompts=prompts,
            num_steps=num_steps,
        )
        imgs = generator.generate_batch(
            num_samples=num_samples,
            target_size=DatasetClass.IMAGE_SIZE,
            batch_size=batch_size,
            seed=seed,
        )
        np.save(str(output_dir / "images.npy"), imgs)
    else:
        import multiprocessing

        samples_per_gpu = num_samples // num_gpus
        q = multiprocessing.Queue()
        processes = []

        for i in range(num_gpus):
            gpu_n = samples_per_gpu + (
                num_samples % num_gpus if i == num_gpus - 1 else 0
            )
            p = multiprocessing.Process(
                target=_worker_ood_gpu,
                args=(
                    i,
                    gpu_n,
                    DatasetClass.IMAGE_SIZE,
                    batch_size,
                    seed,
                    q,
                    base_model,
                    lightning_repo,
                    lightning_ckpt,
                    prompts,
                    num_steps,
                ),
            )
            p.start()
            processes.append(p)

        all_imgs = [q.get() for _ in range(num_gpus)]
        for p in processes:
            p.join()
        np.save(str(output_dir / "images.npy"), np.concatenate(all_imgs, axis=0))

    elapsed = time.time() - start_time
    get_logger().info(
        f"âœ… {DatasetClass.NAME}-OOD ç”Ÿæˆå®Œæˆ! {num_samples} å¼  â±ï¸ è€—æ—¶: {elapsed:.1f}s ({elapsed / 60:.1f}åˆ†é’Ÿ)"
    )
    return output_dir


def visualize_corruption(
    dataset_name: str,
    root: str = "./data",
    num_vis: int = 8,
    gen_cfg=None,
    seed: int = 42,
):
    """ä¸º Corruption ç”Ÿæˆå¯è§†åŒ–å¯¹æ¯”å›¾"""
    DatasetClass = DATASET_REGISTRY[dataset_name]
    output_dir = Path(root) / f"{DatasetClass.NAME}-C"
    vis_dir = output_dir / "visuals"
    ensure_dir(vis_dir)

    extra_kwargs = {}
    if not getattr(DatasetClass, "HAS_OFFICIAL_SPLIT", True):
        extra_kwargs["seed"] = seed
    test_dataset = DatasetClass(root=root, train=False, **extra_kwargs)
    images_np = test_dataset.images.permute(0, 2, 3, 1).numpy()

    get_logger().info("ğŸ¨ æ­£åœ¨ç”Ÿæˆ Corruption å¯è§†åŒ–å¯¹æ¯”å›¾...")

    vis_corruptions = (
        gen_cfg.vis_corruptions if gen_cfg else ["gaussian_noise", "fog", "glass_blur"]
    )

    for c in vis_corruptions:
        for s in SEVERITIES:
            corrupted = CorruptionGenerator.apply_batch(
                images_np[:num_vis], c, s, seed=seed
            )
            save_visual_comparison(
                images_np[:num_vis],
                corrupted,
                vis_dir / f"{c}_s{s}.png",
                f"{c} (severity={s})",
                num_samples=num_vis,
            )


# =============================================================================
# CLI å…¥å£
# =============================================================================


def main():
    """CLI å…¥å£"""
    args = _parse_args()
    config = _load_config()
    _execute_generation(args, config)

    if config.generation.visualize:
        _execute_visualization(args, config)


def _parse_args():
    parser = argparse.ArgumentParser(
        description="é¡¹ç›®é²æ£’æ€§æ•°æ®ç”Ÿæˆå™¨ (SDXL Lightning)"
    )
    parser.add_argument(
        "--type", type=str, required=True, choices=["corruption", "ood"]
    )
    parser.add_argument(
        "--dataset", type=str, required=True, choices=list(DATASET_REGISTRY.keys())
    )
    parser.add_argument("--force", action="store_true", help="å¿½ç•¥ç¼“å­˜å¼ºåˆ¶ç”Ÿæˆ")
    return parser.parse_args()


def _load_config():
    cfg_path = Path(__file__).parents[2] / "config" / "default.yaml"
    config, _, _ = Config.load_yaml(str(cfg_path))
    return config


def _execute_generation(args, config):
    gen_cfg = config.generation
    if args.type == "corruption":
        generate_corruption_dataset(
            args.dataset, config.data_root, config.seed, args.force
        )
    elif args.type == "ood":
        generate_ood_dataset(
            args.dataset,
            config.data_root,
            gen_cfg.samples_per_group * 2,
            config.seed,
            args.force,
            gen_cfg.batch_size,
            gen_cfg.base_model,
            gen_cfg.lightning_repo,
            gen_cfg.lightning_ckpt,
            gen_cfg.ood_prompts,
            gen_cfg.num_steps,
        )


def _execute_visualization(args, config):
    if args.type == "corruption":
        visualize_corruption(
            args.dataset,
            config.data_root,
            config.generation.num_vis,
            config.generation,
            config.seed,
        )
    elif args.type == "ood":
        visualize_ood(
            args.dataset,
            config.data_root,
            config.generation.num_vis,
            config.generation,
        )


def save_visual_grid(
    images: np.ndarray,
    output_path: Path,
    title: str,
    num_samples: int = 8,
    nrow: int = 4,
):
    """ä¿å­˜å•ç»„å›¾åƒçš„ç½‘æ ¼"""
    n = min(len(images), num_samples)
    if n == 0:
        return

    # Randomly select n images if we have more than n
    if len(images) > n:
        indices = np.linspace(0, len(images) - 1, n, dtype=int)
        imgs = images[indices]
    else:
        imgs = images

    h, w = imgs.shape[1:3]
    # åŠ¨æ€è°ƒæ•´åˆ—æ•°ï¼šå®é™…åˆ—æ•°ä¸è¶…è¿‡æ ·æœ¬æ•°
    actual_cols = min(nrow, n)
    actual_rows = (n + actual_cols - 1) // actual_cols

    grid = Image.new("RGB", (w * actual_cols, h * actual_rows))

    for i, img in enumerate(imgs):
        r = i // actual_cols
        c = i % actual_cols
        grid.paste(Image.fromarray(img.astype(np.uint8)), (c * w, r * h))

    ensure_dir(output_path.parent)
    grid.save(str(output_path))
    get_logger().info(f"ğŸ“Š å¯è§†åŒ–ä¿å­˜: {output_path}")


def visualize_ood(
    dataset_name: str,
    root: str = "./data",
    num_vis: int = 8,
    gen_cfg=None,
):
    """ä¸º OOD ç”Ÿæˆå¯è§†åŒ–ç½‘æ ¼

    1. å±•ç¤º resize åçš„å°å›¾ (ä» images.npy)
    2. å®æ—¶ç”Ÿæˆ num_vis ä¸ªé«˜åˆ†è¾¨ç‡åŸå›¾å¹¶å±•ç¤º
    """
    DatasetClass = DATASET_REGISTRY[dataset_name]
    output_dir = Path(root) / f"{DatasetClass.NAME}-OOD"
    vis_dir = output_dir / "visuals"
    ensure_dir(vis_dir)

    images_path = output_dir / "images.npy"

    if not images_path.exists():
        get_logger().warning(f"âš ï¸ OOD æ•°æ®æœªæ‰¾åˆ°: {images_path}")
        return

    get_logger().info("ğŸ¨ æ­£åœ¨ç”Ÿæˆ OOD å¯è§†åŒ–...")

    # 1. åŠ è½½å¹¶å±•ç¤º resize åçš„å°å›¾
    images = np.load(str(images_path), mmap_mode="r")
    total_images = len(images)
    indices = np.linspace(0, total_images - 1, min(total_images, num_vis), dtype=int)
    vis_images = images[indices]

    save_visual_grid(
        vis_images,
        vis_dir / "ood_samples_resized.png",
        "OOD Samples (Resized)",
        num_samples=num_vis,
        nrow=4,
    )

    # 2. å®æ—¶ç”Ÿæˆ num_vis ä¸ªé«˜åˆ†è¾¨ç‡åŸå›¾
    if gen_cfg is not None:
        get_logger().info(f"   ğŸ“· ç”Ÿæˆ {num_vis} å¼ é«˜åˆ†è¾¨ç‡åŸå›¾ç”¨äºå¯è§†åŒ–...")
        generator = OODGenerator(
            device="cuda" if torch.cuda.is_available() else "cpu",
            base_model=gen_cfg.base_model,
            lightning_repo=gen_cfg.lightning_repo,
            lightning_ckpt=gen_cfg.lightning_ckpt,
            prompts=gen_cfg.ood_prompts,
            num_steps=gen_cfg.num_steps,
        )
        hires_samples = generator.generate_hires_samples(num_vis, seed=42)

        save_visual_grid(
            hires_samples,
            vis_dir / "ood_samples_hires.png",
            "OOD Samples (High-Resolution 1024x1024)",
            num_samples=num_vis,
            nrow=4,
        )
        get_logger().info(f"   âœ… é«˜åˆ†è¾¨ç‡åŸå›¾: {vis_dir / 'ood_samples_hires.png'}")


if __name__ == "__main__":
    main()
