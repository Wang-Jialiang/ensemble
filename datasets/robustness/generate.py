"""
================================================================================
ç»Ÿä¸€æ•°æ®ç”Ÿæˆè„šæœ¬ (SDXL Lightning ç‰ˆ)
================================================================================

æ”¯æŒæ•°æ®ç±»å‹çš„ç”Ÿæˆ:
- Corruption: ä½¿ç”¨ imagecorruptions åº“ç”ŸæˆæŸåæ•°æ®
- OOD: ä½¿ç”¨ SDXL Lightning Text2Img ç”Ÿæˆåˆ†å¸ƒå¤–æ•°æ®

ä½¿ç”¨ç¤ºä¾‹:
    python -m ensemble.datasets.robustness.generate --type corruption --dataset cifar10
    python -m ensemble.datasets.robustness.generate --type ood --dataset cifar10
"""

import argparse
import multiprocessing
import os
import warnings
from pathlib import Path
from typing import Optional

import numpy as np
import skimage.filters
import torch
from diffusers import (
    EulerDiscreteScheduler,
    StableDiffusionXLPipeline,
)
from PIL import Image
from safetensors.torch import load_file

from ...config import Config
from ...utils import console, ensure_dir, get_logger
from ..preloaded import DATASET_REGISTRY
from .corruption import CORRUPTIONS, SEVERITIES

# æ³¨æ„: ä¸ºè§£å†³ CUDA åœ¨ fork å­è¿›ç¨‹ä¸­æ— æ³•é‡æ–°åˆå§‹åŒ–çš„é—®é¢˜ï¼Œ
# ä½¿ç”¨ multiprocessing.get_context("spawn") åˆ›å»ºå±€éƒ¨ä¸Šä¸‹æ–‡
# è€Œéå…¨å±€ set_start_methodï¼Œé¿å…å½±å“å…¶ä»–æ¨¡å—


# =============================================================================
# Monkey-patch dependencies for imagecorruptions compatibility
# =============================================================================

original_gaussian = skimage.filters.gaussian


def patched_gaussian(*args, **kwargs):
    if "multichannel" in kwargs:
        multichannel = kwargs.pop("multichannel")
        if multichannel and "channel_axis" not in kwargs:
            kwargs["channel_axis"] = -1
    return original_gaussian(*args, **kwargs)


skimage.filters.gaussian = patched_gaussian

if not hasattr(np, "float_"):
    np.float_ = np.float64


def _suppress_known_warnings():
    """é›†ä¸­ç®¡ç†å·²çŸ¥çš„æ— å®³è­¦å‘Š"""
    # ä¾èµ–åº“å…¼å®¹æ€§è­¦å‘Š
    warnings.filterwarnings("ignore", category=UserWarning, module="pkg_resources")
    warnings.filterwarnings("ignore", category=UserWarning, module="imagecorruptions")
    warnings.filterwarnings(
        "ignore", category=RuntimeWarning, module="imagecorruptions"
    )
    # æ•°å€¼è®¡ç®—è­¦å‘Š (Corruption ç”Ÿæˆä¸­çš„è¾¹ç•Œæƒ…å†µ)
    warnings.filterwarnings("ignore", "invalid value encountered in divide")
    warnings.filterwarnings("ignore", "invalid value encountered in cast")
    # Diffusers ç‰ˆæœ¬è­¦å‘Š
    warnings.filterwarnings("ignore", category=FutureWarning, module="diffusers")


_suppress_known_warnings()


# =============================================================================
# å¯è§†åŒ–å·¥å…·
# =============================================================================


def save_visual_comparison(
    original_imgs: np.ndarray,
    processed_imgs: np.ndarray,
    output_path: Path,
    title: str,
    num_samples: int = 8,
):
    """ä¿å­˜åŸå§‹å›¾åƒä¸å¤„ç†åå›¾åƒçš„å¯¹æ¯”ç½‘æ ¼"""
    n = min(len(original_imgs), num_samples)
    if n == 0:
        return

    indices = np.linspace(0, len(original_imgs) - 1, n, dtype=int)
    orig = original_imgs[indices]
    proc = processed_imgs[indices]

    h, w = orig.shape[1:3]
    grid = Image.new("RGB", (w * n, h * 2))

    for i, (o, p) in enumerate(zip(orig, proc)):
        grid.paste(Image.fromarray(o.astype(np.uint8)), (i * w, 0))
        grid.paste(Image.fromarray(p.astype(np.uint8)), (i * w, h))

    ensure_dir(output_path.parent)
    grid.save(str(output_path))
    get_logger().info(f"ğŸ“Š å¯è§†åŒ–ä¿å­˜: {output_path}")


# =============================================================================
# å›¾åƒå¤„ç†å·¥å…·
# =============================================================================


def _convert_to_numpy_batch(images_pil: list, target_size: tuple):
    """å°† PIL æ‰¹é‡å›¾åƒæ¢å¤åˆ°ç›®æ ‡å°ºå¯¸å¹¶è½¬å› numpy æ ¼å¼"""
    return [np.array(img.resize(target_size, Image.LANCZOS)) for img in images_pil]


def _get_gpu_id(device: str):
    """ä»è®¾å¤‡å­—ç¬¦ä¸²ä¸­æå– GPU ID"""
    try:
        return int(device.split(":")[-1])
    except (ValueError, IndexError):
        return 0


def _check_existing_dataset(output_dir: Path, force: bool):
    """æ£€æŸ¥æ•°æ®é›†æ˜¯å¦å·²å­˜åœ¨"""
    if output_dir.exists() and not force:
        get_logger().info(f"â­ï¸ æ•°æ®é›†å·²å­˜åœ¨: {output_dir}ï¼Œè·³è¿‡ç”Ÿæˆ")
        return True
    ensure_dir(output_dir)
    return False


def _load_test_set_numpy(DatasetClass, root, seed=42):
    """åŠ è½½æµ‹è¯•é›†å¹¶è½¬æ¢ä¸º numpy æ ¼å¼"""
    extra_kwargs = {}
    if not getattr(DatasetClass, "HAS_OFFICIAL_SPLIT", True):
        extra_kwargs["seed"] = seed
    dataset = DatasetClass(root=root, train=False, **extra_kwargs)
    images_np = dataset.images.permute(0, 2, 3, 1).numpy()
    labels_np = dataset.targets.numpy()
    return images_np, labels_np


# =============================================================================
# Corruption ç”Ÿæˆå™¨
# =============================================================================


class CorruptionGenerator:
    """Corruption ç”Ÿæˆå™¨ - åŸºäº imagecorruptions åº“"""

    CORRUPTIONS = CORRUPTIONS
    SEVERITIES = SEVERITIES

    @staticmethod
    def apply(img: np.ndarray, corruption_type: str, severity: int = 5) -> np.ndarray:
        """å¯¹å•å¼ å›¾åƒåº”ç”¨ corruption"""
        try:
            from imagecorruptions import corrupt
        except ImportError:
            raise ImportError("éœ€è¦å®‰è£… imagecorruptions: pip install imagecorruptions")

        if corruption_type not in CorruptionGenerator.CORRUPTIONS:
            raise ValueError(f"Unknown corruption: {corruption_type}")

        img_uint8 = np.clip(img, 0, 255).astype(np.uint8)
        corrupted = corrupt(
            img_uint8, corruption_name=corruption_type, severity=severity
        )
        return corrupted.astype(np.float32)

    @staticmethod
    def apply_batch(
        images: np.ndarray,
        corruption_type: str,
        severity: int = 5,
        seed: Optional[int] = None,
    ) -> np.ndarray:
        """æ‰¹é‡åº”ç”¨ corruption"""
        if seed is not None:
            np.random.seed(seed)
        return np.stack(
            [
                CorruptionGenerator.apply(img, corruption_type, severity)
                for img in images
            ]
        )


# =============================================================================
# SDXL Lightning Pipeline åŠ è½½å™¨
# =============================================================================


class LightningPipelineLoader:
    """SDXL Lightning Pipeline åŠ è½½å™¨ (å•ä¾‹æ¨¡å¼)"""

    _text2img_cache = {}

    @classmethod
    def get_text2img(
        cls, device: str, base_model: str, repo: str, ckpt: str
    ) -> "StableDiffusionXLPipeline":
        """è·å– Text2Img Pipeline (å¼ºåˆ¶æœ¬åœ°å•æ–‡ä»¶åŠ è½½)"""
        return cls._get_pipeline(
            device,
            base_model,
            repo,
            ckpt,
            StableDiffusionXLPipeline,
            cls._text2img_cache,
            "Text2Img",
        )

    @classmethod
    def _get_pipeline(
        cls,
        device: str,
        base_model: str,
        repo: str,
        ckpt: str,
        pipe_cls,
        cache,
        name: str,
    ):
        """é€šç”¨ Pipeline åŠ è½½é€»è¾‘ (æ”¯æŒå…¨ç¦»çº¿ YAML é…ç½®)"""
        if device not in cache:
            get_logger().info(
                f"ğŸ“¥ [{device}] æ­£åœ¨ä»æœ¬åœ°æ–‡ä»¶åŠ è½½ SDXL Lightning {name}..."
            )

            if not os.path.isfile(base_model):
                raise FileNotFoundError(f"åŸºç¡€æƒé‡æ–‡ä»¶æœªæ‰¾åˆ°: {base_model}")

            # å¯»æ‰¾é…å¥—çš„ CLIP å­—å…¸é…ç½®ç›®å½• (ç”¨äºç¦»çº¿ Tokenizer/TextEncoder)
            # ä¼˜å…ˆå¯»æ‰¾ä¸æ¨¡å‹åŒç›®å½•ä¸‹çš„ 'config' æ–‡ä»¶å¤¹
            config_dir = os.path.join(os.path.dirname(base_model), "config")
            local_config = None
            if os.path.isdir(config_dir):
                get_logger().info(f"ğŸ“š å‘ç°æœ¬åœ°ç»„ä»¶é…ç½®ç›®å½•: {config_dir}")
                local_config = config_dir

            # å¼ºåˆ¶æœ¬åœ°å•æ–‡ä»¶åŠ è½½ (å¦‚æœæä¾›äº† original_config å’Œ local_configï¼Œåˆ™å¯å…¨ç¦»çº¿è¿è¡Œ)
            pipe = pipe_cls.from_single_file(
                base_model,
                config=local_config,
                torch_dtype=torch.float16,
                local_files_only=True,
            ).to(device)

            # æ³¨å…¥ Lightning æƒé‡
            cls._apply_lightning_to_pipe(pipe, device, repo, ckpt)

            pipe.scheduler = EulerDiscreteScheduler.from_config(
                pipe.scheduler.config, timestep_spacing="trailing"
            )
            pipe.set_progress_bar_config(disable=True)
            cls._try_enable_optimizations(pipe)
            cache[device] = pipe
        return cache[device]

    @classmethod
    def _apply_lightning_to_pipe(cls, pipe, device: str, repo: str, ckpt: str):
        """å°† Lightning æƒé‡æ³¨å…¥åˆ°ç°æœ‰ Pipeline çš„ UNet ä¸­"""
        local_path = Path(repo) / ckpt
        if not local_path.exists():
            raise FileNotFoundError(f"Lightning æƒé‡æ–‡ä»¶æœªæ‰¾åˆ°: {local_path}")

        get_logger().info(f"ğŸš€ åŠ è½½æœ¬åœ° Lightning æƒé‡: {local_path}")
        state_dict = load_file(str(local_path), device=device)
        pipe.unet.load_state_dict(state_dict)

    @staticmethod
    def _try_enable_optimizations(pipe):
        """å°è¯•å¯ç”¨æ˜¾å­˜ä¼˜åŒ–å’ŒåŠ é€Ÿ"""

        pipe.enable_vae_slicing()
        pipe.enable_vae_tiling()
        pipe.enable_xformers_memory_efficient_attention()
        get_logger().info("   âš¡ å·²å¯ç”¨ xformers åŠ é€Ÿ")


# torch.compile: å·²ç¦ç”¨
# åŸå› : SDXL UNet é¦–æ¬¡ç¼–è¯‘éœ€è¦ 10-30 åˆ†é’Ÿï¼Œå¯¹äº Lightning 4-step æ¨ç†æ”¶ç›Šå¾ˆå°
# å¦‚æœéœ€è¦å¤§é‡ç”Ÿæˆï¼Œå¯ä»¥è€ƒè™‘å¯ç”¨ï¼Œä½†éœ€è¦ç­‰å¾…é¦–æ¬¡ç¼–è¯‘å®Œæˆ
# try:
#     import torch
#     if hasattr(torch, "compile") and torch.cuda.is_available():
#         pipe.unet = torch.compile(pipe.unet, mode="max-autotune", fullgraph=True)
#         get_logger().info("   âš¡ å·²å¯ç”¨ torch.compile åŠ é€Ÿ")
# except Exception:
#     pass


# =============================================================================
# OOD ç”Ÿæˆå™¨ (SDXL Lightning)
# =============================================================================


class OODGenerator:
    """OOD ç”Ÿæˆå™¨ - åŸºäº SDXL Lightning Text2Img"""

    def __init__(
        self,
        device: str = "cuda",
        base_model: str = "stabilityai/stable-diffusion-xl-base-1.0",
        lightning_repo: str = "ByteDance/SDXL-Lightning",
        lightning_ckpt: str = "sdxl_lightning_4step_unet.safetensors",
        prompts: Optional[list] = None,
        num_steps: int = 4,
        sdxl_height: int = 1024,
        sdxl_width: int = 1024,
        guidance_scale: float = 0.0,
    ):
        self.device = device
        self.base_model = base_model
        self.lightning_repo = lightning_repo
        self.lightning_ckpt = lightning_ckpt
        if prompts is None:
            raise ValueError(
                "âŒ å¿…é¡»æä¾› prompts å‚æ•° (ä» yaml æŒ‰æ•°æ®é›†è·å–å¯¹åº”çš„ ood_prompts)"
            )
        self.prompts = prompts
        self.num_steps = num_steps
        self.sdxl_height = sdxl_height
        self.sdxl_width = sdxl_width
        self.guidance_scale = guidance_scale
        self._pipe = None

    def _get_pipe(self):
        """è·å– Text2Img Pipeline"""
        if self._pipe is None:
            self._pipe = LightningPipelineLoader.get_text2img(
                self.device, self.base_model, self.lightning_repo, self.lightning_ckpt
            )
        return self._pipe

    def generate_batch(
        self,
        num_samples: int,
        target_size: int = 64,
        batch_size: int = 24,
        seed: Optional[int] = None,
    ) -> np.ndarray:
        """æ‰¹é‡ç”Ÿæˆ OOD å›¾åƒ (resize åçš„å°å°ºå¯¸)"""
        import random

        if seed is not None:
            random.seed(seed)

        pipe = self._get_pipe()
        results = []

        from rich.progress import (
            BarColumn,
            Progress,
            TaskProgressColumn,
            TextColumn,
            TimeRemainingColumn,
        )

        with Progress(
            TextColumn("[progress.description]{task.description}"),
            BarColumn(),
            TaskProgressColumn(),
            TimeRemainingColumn(),
            console=console,
            transient=True,
        ) as progress:
            task_id = progress.add_task(
                f"      [{self.device}] OOD ç”Ÿæˆ", total=num_samples
            )

            for i in range(0, num_samples, batch_size):
                current_bs = min(batch_size, num_samples - i)
                prompts = [random.choice(self.prompts) for _ in range(current_bs)]

                outputs = pipe(
                    prompt=prompts,
                    height=self.sdxl_height,
                    width=self.sdxl_width,
                    guidance_scale=self.guidance_scale,
                    num_inference_steps=self.num_steps,
                ).images

                results.extend(
                    _convert_to_numpy_batch(outputs, (target_size, target_size))
                )
                progress.update(task_id, advance=current_bs)

        return np.stack(results)

    def generate_hires_samples(
        self,
        num_samples: int,
        seed: Optional[int] = None,
    ) -> np.ndarray:
        """ç”Ÿæˆå°‘é‡é«˜åˆ†è¾¨ç‡åŸå›¾ (ä»…ç”¨äºå¯è§†åŒ–)"""
        import random

        if seed is not None:
            random.seed(seed)

        pipe = self._get_pipe()
        results = []

        for _ in range(num_samples):
            prompt = random.choice(self.prompts)
            output = pipe(
                prompt=prompt,
                height=self.sdxl_height,
                width=self.sdxl_width,
                guidance_scale=self.guidance_scale,
                num_inference_steps=self.num_steps,
            ).images[0]
            results.append(np.array(output))

        return np.stack(results)


# =============================================================================
# å¹¶è¡Œå¤„ç†åŠ©æ‰‹
# =============================================================================


def _process_single_corruption(args):
    """å•ç§ corruption å¤„ç†å‡½æ•° (ç”¨äº multiprocessing)"""
    corruption, images_np, severities, output_dir, seed = args

    # å…¨é‡å¤„ç†: ä¸å†æ”¯æŒåˆ‡ç‰‡
    images_to_process = images_np

    all_severities = []
    for severity in severities:
        corrupted = CorruptionGenerator.apply_batch(
            images_to_process, corruption, severity, seed=seed
        )
        all_severities.append(corrupted.astype(np.uint8))

    stacked = np.concatenate(all_severities, axis=0)
    np.save(str(output_dir / f"{corruption}.npy"), stacked)
    return corruption


def _worker_ood_gpu(
    gpu_id,
    n,
    target_size,
    bs,
    seed,
    q,
    base_model,
    lightning_repo,
    lightning_ckpt,
    prompts,
    num_steps,
):
    """OOD å·¥ä½œè€…çº¿ç¨‹ (ç”¨äº GPU å¹¶è¡Œ)"""
    generator = OODGenerator(
        device=f"cuda:{gpu_id}",
        base_model=base_model,
        lightning_repo=lightning_repo,
        lightning_ckpt=lightning_ckpt,
        prompts=prompts,
        num_steps=num_steps,
    )
    imgs_resized = generator.generate_batch(
        num_samples=n, target_size=target_size, batch_size=bs, seed=seed + gpu_id
    )
    q.put(imgs_resized)


# =============================================================================
# ç”Ÿæˆå‡½æ•°
# =============================================================================


def generate_corruption_dataset(
    dataset_name: str,
    root: str = "./data",
    seed: int = 42,
    force: bool = False,
) -> Path:
    """é¢„ç”Ÿæˆ corruption æ•°æ®é›† (ä½¿ç”¨ CPU å¤šè¿›ç¨‹åŠ é€Ÿ) - æ— è®ºå¦‚ä½•éƒ½ç”Ÿæˆå…¨é‡æ•°æ® (Full Coverage)"""
    import multiprocessing
    import os

    if dataset_name not in DATASET_REGISTRY:
        raise ValueError(f"æœªçŸ¥æ•°æ®é›†: {dataset_name}")

    DatasetClass = DATASET_REGISTRY[dataset_name]
    output_dir = Path(root) / f"{DatasetClass.NAME}-C"

    if _check_existing_dataset(output_dir, force):
        return output_dir

    get_logger().info(
        f"ğŸ”§ ç”Ÿæˆ Corruption: {DatasetClass.NAME}-C (Full Coverage Strategy)..."
    )

    images_np, labels_np = _load_test_set_numpy(DatasetClass, root, seed)

    # å…¨é‡æ¨¡å¼: ä»…ä»…ä¼ å…¥ full data
    # ä¸å†ç”±äºç±»åˆ«å‡è¡¡åˆ‡åˆ†ã€‚
    # æ‰€æœ‰çš„ Corruptions éƒ½åº”ç”¨åœ¨æ‰€æœ‰ Images ä¸Š

    tasks = []

    for corruption in CORRUPTIONS:
        # Full Mode: ä¼ é€’ None ä½œä¸º slice_objï¼Œè¡¨ç¤ºå¤„ç†å…¨é‡
        tasks.append((corruption, images_np, SEVERITIES, output_dir, seed))

    # ===============================================

    num_cpus = os.cpu_count()

    from rich.progress import (
        BarColumn,
        Progress,
        TaskProgressColumn,
        TextColumn,
        TimeRemainingColumn,
    )

    with Progress(
        TextColumn("[progress.description]{task.description}"),
        BarColumn(),
        TaskProgressColumn(),
        TimeRemainingColumn(),
        console=console,
    ) as progress:
        task_id = progress.add_task("   Corruption æ€»è¿›åº¦", total=len(tasks))

        # ä½¿ç”¨ spawn ä¸Šä¸‹æ–‡åˆ›å»ºè¿›ç¨‹æ±  (ä¸æ±¡æŸ“å…¨å±€è®¾ç½®)
        ctx = multiprocessing.get_context("spawn")
        with ctx.Pool(processes=min(len(tasks), num_cpus)) as pool:
            for _ in pool.imap_unordered(_process_single_corruption, tasks):
                progress.update(task_id, advance=1)

    np.save(str(output_dir / "labels.npy"), labels_np)

    get_logger().info(
        f"âœ… {DatasetClass.NAME}-C ç”Ÿæˆå®Œæˆ: {len(tasks)} corruptions (Full Coverage)"
    )
    return output_dir


def generate_ood_dataset(
    dataset_name: str,
    root: str = "./data",
    num_samples: int = 1000,
    seed: int = 42,
    force: bool = False,
    batch_size: int = 24,
    base_model: str = "stabilityai/stable-diffusion-xl-base-1.0",
    lightning_repo: str = "ByteDance/SDXL-Lightning",
    lightning_ckpt: str = "sdxl_lightning_4step_unet.safetensors",
    prompts: Optional[list] = None,
    num_steps: int = 4,
    ood_type: str = "near",  # "near" æˆ– "far"
) -> Path:
    """é¢„ç”Ÿæˆ OOD æ•°æ®é›† (ä»…ä¿å­˜ resize åçš„å°å›¾)

    Args:
        ood_type: "near" = Near-OOD, "far" = Far-OOD
    """
    import time

    if dataset_name not in DATASET_REGISTRY:
        raise ValueError(f"æœªçŸ¥æ•°æ®é›†: {dataset_name}")

    DatasetClass = DATASET_REGISTRY[dataset_name]
    # æ ¹æ® ood_type åŒºåˆ†è¾“å‡ºç›®å½•
    ood_suffix = "Near-OOD" if ood_type == "near" else "Far-OOD"
    output_dir = Path(root) / f"{DatasetClass.NAME}-{ood_suffix}"

    if _check_existing_dataset(output_dir, force):
        return output_dir

    get_logger().info(
        f"ğŸ”§ ç”Ÿæˆ {ood_suffix}: {DatasetClass.NAME} ({num_samples} å¼ , SDXL Lightning 4-step)"
    )

    start_time = time.time()
    num_gpus = torch.cuda.device_count()

    # ä½¿ç”¨ spawn ä¸Šä¸‹æ–‡ (CUDA è¦æ±‚)
    ctx = multiprocessing.get_context("spawn")

    samples_per_gpu = num_samples // num_gpus
    q = ctx.Queue()
    processes = []

    for i in range(num_gpus):
        gpu_n = samples_per_gpu + (num_samples % num_gpus if i == num_gpus - 1 else 0)
        p = ctx.Process(
            target=_worker_ood_gpu,
            args=(
                i,
                gpu_n,
                DatasetClass.IMAGE_SIZE,
                batch_size,
                seed,
                q,
                base_model,
                lightning_repo,
                lightning_ckpt,
                prompts,
                num_steps,
            ),
        )
        p.start()
        processes.append(p)

    all_imgs = [q.get() for _ in range(num_gpus)]
    for p in processes:
        p.join()
    np.save(str(output_dir / "images.npy"), np.concatenate(all_imgs, axis=0))

    elapsed = time.time() - start_time
    get_logger().info(
        f"âœ… {DatasetClass.NAME}-{ood_suffix} ç”Ÿæˆå®Œæˆ! {num_samples} å¼  â±ï¸ è€—æ—¶: {elapsed:.1f}s ({elapsed / 60:.1f}åˆ†é’Ÿ)"
    )
    return output_dir


def visualize_corruption(
    dataset_name: str,
    root: str = "./data",
    num_vis: int = 8,
    gen_cfg=None,
    seed: int = 42,
):
    """ä¸º Corruption ç”Ÿæˆå¯è§†åŒ–å¯¹æ¯”å›¾"""
    DatasetClass = DATASET_REGISTRY[dataset_name]
    output_dir = Path(root) / f"{DatasetClass.NAME}-C"
    vis_dir = output_dir / "visuals"
    ensure_dir(vis_dir)

    extra_kwargs = {}
    if not getattr(DatasetClass, "HAS_OFFICIAL_SPLIT", True):
        extra_kwargs["seed"] = seed
    test_dataset = DatasetClass(root=root, train=False, **extra_kwargs)
    images_np = test_dataset.images.permute(0, 2, 3, 1).numpy()

    get_logger().info("ğŸ¨ æ­£åœ¨ç”Ÿæˆ Corruption å¯è§†åŒ–å¯¹æ¯”å›¾...")

    vis_corruptions = (
        gen_cfg.vis_corruptions if gen_cfg else ["gaussian_noise", "fog", "glass_blur"]
    )

    for c in vis_corruptions:
        for s in SEVERITIES:
            corrupted = CorruptionGenerator.apply_batch(
                images_np[:num_vis], c, s, seed=seed
            )
            save_visual_comparison(
                images_np[:num_vis],
                corrupted,
                vis_dir / f"{c}_s{s}.png",
                f"{c} (severity={s})",
                num_samples=num_vis,
            )


# =============================================================================
# CLI å…¥å£
# =============================================================================


def main():
    """CLI å…¥å£"""
    args = _parse_args()
    config = _load_config()
    _execute_generation(args, config)

    if config.generation.visualize:
        _execute_visualization(args, config)


def _parse_args():
    parser = argparse.ArgumentParser(
        description="é¡¹ç›®é²æ£’æ€§æ•°æ®ç”Ÿæˆå™¨ (SDXL Lightning)"
    )
    parser.add_argument(
        "--type", type=str, required=True, choices=["corruption", "ood"]
    )
    parser.add_argument(
        "--dataset", type=str, required=True, choices=list(DATASET_REGISTRY.keys())
    )
    parser.add_argument(
        "--ood-type",
        type=str,
        default="both",
        choices=["near", "far", "both"],
        help="OOD ç±»å‹: near=Near-OOD, far=Far-OOD, both=ä¸¤è€…éƒ½ç”Ÿæˆ (é»˜è®¤)",
    )
    parser.add_argument("--force", action="store_true", help="å¿½ç•¥ç¼“å­˜å¼ºåˆ¶ç”Ÿæˆ")
    return parser.parse_args()


def _load_config():
    cfg_path = Path(__file__).parents[2] / "config" / "default.yaml"
    config, _, _ = Config.load_yaml(str(cfg_path))
    return config


def _execute_generation(args, config):
    gen_cfg = config.generation
    if args.type == "corruption":
        generate_corruption_dataset(
            args.dataset, config.data_root, config.seed, args.force
        )
    elif args.type == "ood":
        ood_types = ["near", "far"] if args.ood_type == "both" else [args.ood_type]

        for ood_type in ood_types:
            # æ ¹æ® OOD ç±»å‹é€‰æ‹©å¯¹åº”çš„ prompts
            prompts_dict = (
                gen_cfg.near_ood_prompts
                if ood_type == "near"
                else gen_cfg.far_ood_prompts
            )
            ood_prompts = prompts_dict.get(args.dataset) if prompts_dict else None

            if ood_prompts is None:
                raise ValueError(
                    f"âŒ æœªæ‰¾åˆ°æ•°æ®é›† '{args.dataset}' çš„ {ood_type}_ood_promptsï¼Œè¯·åœ¨ default.yaml ä¸­é…ç½®"
                )

            generate_ood_dataset(
                args.dataset,
                config.data_root,
                gen_cfg.samples_per_group,
                config.seed,
                args.force,
                gen_cfg.batch_size,
                gen_cfg.base_model,
                gen_cfg.lightning_repo,
                gen_cfg.lightning_ckpt,
                ood_prompts,
                gen_cfg.num_steps,
                ood_type=ood_type,  # ä¼ é€’ OOD ç±»å‹
            )


def _execute_visualization(args, config):
    if args.type == "corruption":
        visualize_corruption(
            args.dataset,
            config.data_root,
            config.generation.num_vis,
            config.generation,
            config.seed,
        )
    elif args.type == "ood":
        ood_types = ["near", "far"] if args.ood_type == "both" else [args.ood_type]
        for ood_type in ood_types:
            visualize_ood(
                args.dataset,
                config.data_root,
                config.generation.num_vis,
                config.generation,
                ood_type=ood_type,
            )


def save_visual_grid(
    images: np.ndarray,
    output_path: Path,
    title: str,
    num_samples: int = 8,
    nrow: int = 4,
):
    """ä¿å­˜å•ç»„å›¾åƒçš„ç½‘æ ¼"""
    n = min(len(images), num_samples)
    if n == 0:
        return

    # Randomly select n images if we have more than n
    if len(images) > n:
        indices = np.linspace(0, len(images) - 1, n, dtype=int)
        imgs = images[indices]
    else:
        imgs = images

    h, w = imgs.shape[1:3]
    # åŠ¨æ€è°ƒæ•´åˆ—æ•°ï¼šå®é™…åˆ—æ•°ä¸è¶…è¿‡æ ·æœ¬æ•°
    actual_cols = min(nrow, n)
    actual_rows = (n + actual_cols - 1) // actual_cols

    grid = Image.new("RGB", (w * actual_cols, h * actual_rows))

    for i, img in enumerate(imgs):
        r = i // actual_cols
        c = i % actual_cols
        grid.paste(Image.fromarray(img.astype(np.uint8)), (c * w, r * h))

    ensure_dir(output_path.parent)
    grid.save(str(output_path))
    get_logger().info(f"ğŸ“Š å¯è§†åŒ–ä¿å­˜: {output_path}")


def visualize_ood(
    dataset_name: str,
    root: str = "./data",
    num_vis: int = 8,
    gen_cfg=None,
    ood_type: str = "near",  # "near" æˆ– "far"
):
    """ä¸º OOD ç”Ÿæˆå¯è§†åŒ–ç½‘æ ¼

    Args:
        ood_type: "near" = Near-OOD, "far" = Far-OOD

    1. å±•ç¤º resize åçš„å°å›¾ (ä» images.npy)
    2. å®æ—¶ç”Ÿæˆ num_vis ä¸ªé«˜åˆ†è¾¨ç‡åŸå›¾å¹¶å±•ç¤º
    """
    DatasetClass = DATASET_REGISTRY[dataset_name]
    ood_suffix = "Near-OOD" if ood_type == "near" else "Far-OOD"
    output_dir = Path(root) / f"{DatasetClass.NAME}-{ood_suffix}"
    vis_dir = output_dir / "visuals"
    ensure_dir(vis_dir)

    images_path = output_dir / "images.npy"

    if not images_path.exists():
        get_logger().warning(f"âš ï¸ {ood_suffix} æ•°æ®æœªæ‰¾åˆ°: {images_path}")
        return

    get_logger().info(f"ğŸ¨ æ­£åœ¨ç”Ÿæˆ {ood_suffix} å¯è§†åŒ–...")

    # 1. åŠ è½½å¹¶å±•ç¤º resize åçš„å°å›¾
    images = np.load(str(images_path), mmap_mode="r")
    total_images = len(images)
    indices = np.linspace(0, total_images - 1, min(total_images, num_vis), dtype=int)
    vis_images = images[indices]

    save_visual_grid(
        vis_images,
        vis_dir / f"{ood_type}_ood_samples_resized.png",
        f"{ood_suffix} Samples (Resized)",
        num_samples=num_vis,
        nrow=4,
    )

    # 2. å®æ—¶ç”Ÿæˆ num_vis ä¸ªé«˜åˆ†è¾¨ç‡åŸå›¾
    if gen_cfg is not None:
        # æ ¹æ® ood_type é€‰æ‹©å¯¹åº”çš„ prompts
        prompts_dict = (
            gen_cfg.near_ood_prompts if ood_type == "near" else gen_cfg.far_ood_prompts
        )
        ood_prompts = prompts_dict.get(dataset_name) if prompts_dict else None

        if ood_prompts is None:
            get_logger().warning(
                f"âš ï¸ æœªæ‰¾åˆ°æ•°æ®é›† '{dataset_name}' çš„ {ood_type}_ood_promptsï¼Œè·³è¿‡é«˜åˆ†è¾¨ç‡å¯è§†åŒ–"
            )
            return
        get_logger().info(f"   ğŸ“· ç”Ÿæˆ {num_vis} å¼ é«˜åˆ†è¾¨ç‡åŸå›¾ç”¨äºå¯è§†åŒ–...")
        generator = OODGenerator(
            device="cuda" if torch.cuda.is_available() else "cpu",
            base_model=gen_cfg.base_model,
            lightning_repo=gen_cfg.lightning_repo,
            lightning_ckpt=gen_cfg.lightning_ckpt,
            prompts=ood_prompts,
            num_steps=gen_cfg.num_steps,
        )
        hires_samples = generator.generate_hires_samples(num_vis, seed=42)

        save_visual_grid(
            hires_samples,
            vis_dir / f"{ood_type}_ood_samples_hires.png",
            f"{ood_suffix} Samples (High-Resolution 1024x1024)",
            num_samples=num_vis,
            nrow=4,
        )
        get_logger().info(
            f"   âœ… é«˜åˆ†è¾¨ç‡åŸå›¾: {vis_dir / f'{ood_type}_ood_samples_hires.png'}"
        )


if __name__ == "__main__":
    main()
