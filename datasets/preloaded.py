"""
================================================================================
é¢„åŠ è½½æ•°æ®é›†æ¨¡å—
================================================================================

åŒ…å«: PreloadedCIFAR10, PreloadedEuroSAT, DATASET_REGISTRY
"""

import time
from pathlib import Path
from typing import Dict, Type

import numpy as np
import torch
import torchvision
from tenacity import retry, stop_after_attempt, wait_fixed

from ..utils import get_logger
from .base import BasePreloadedDataset

# â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
# â•‘ æ•°æ®é›†æ³¨å†Œè¡¨                                                                 â•‘
# â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

DATASET_REGISTRY: Dict[str, Type[BasePreloadedDataset]] = {}


def register_dataset(name: str):
    """è£…é¥°å™¨ï¼šæ³¨å†Œæ•°æ®é›†åˆ°å…¨å±€æ³¨å†Œè¡¨

    ä½¿ç”¨æ–¹å¼:
        @register_dataset("my_dataset")
        class MyDataset(BasePreloadedDataset):
            ...
    """

    def decorator(cls: Type[BasePreloadedDataset]) -> Type[BasePreloadedDataset]:
        DATASET_REGISTRY[name] = cls
        return cls

    return decorator


# â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
# â•‘ å…·ä½“æ•°æ®é›†å®žçŽ°                                                               â•‘
# â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•


@register_dataset("cifar10")
class PreloadedCIFAR10(BasePreloadedDataset):
    """å†…å­˜é¢„åŠ è½½çš„CIFAR-10æ•°æ®é›†"""

    MEAN = [0.4914, 0.4822, 0.4465]
    STD = [0.2023, 0.1994, 0.2010]
    IMAGE_SIZE = 32
    NUM_CLASSES = 10
    NAME = "CIFAR-10"

    @retry(stop=stop_after_attempt(3), wait=wait_fixed(5), reraise=True)
    def _load_data(self):
        """ä¸»åŠ è½½æµç¨‹ (å¸¦é‡è¯•ä¿æŠ¤)"""
        # 1. å‡†å¤‡åŽŸå§‹æ•°æ®é›†
        source_ds = self._fetch_builtin_dataset()
        
        # 2. ä»Žæºæ•°æ®æ‘„å–åˆ°å†…å­˜
        start_time = time.time()
        self._ingest_source_data(source_ds)
        
        # 3. ç»Ÿè®¡å¹¶å®Œæˆ
        self._log_loaded(time.time() - start_time)

    def _fetch_builtin_dataset(self):
        """æ£€æŸ¥å¹¶ä¸‹è½½ torchvision CIFAR10"""
        cifar_dir = Path(self.root) / "cifar-10-batches-py"
        skip_download = cifar_dir.exists()
        
        log_msg = "âœ… æ•°æ®é›†å·²å­˜åœ¨ï¼Œè·³è¿‡ä¸‹è½½" if skip_download else "ðŸ“¥ æ•°æ®é›†ä¸å­˜åœ¨ï¼Œå¼€å§‹ä¸‹è½½..."
        get_logger().info(log_msg)
        
        return torchvision.datasets.CIFAR10(root=self.root, train=self.train, download=not skip_download)

    def _ingest_source_data(self, source_ds):
        """å°†æºæ•°æ®é›†çš„ image/targets è½¬ç§»åˆ° Tensor å½¢å¼"""
        get_logger().info(f"ðŸ“¦ Preloading {self.NAME} {'train' if self.train else 'test'} to RAM...")
        # (N, H, W, 3) -> (N, 3, H, W)
        self.images = torch.from_numpy(source_ds.data).permute(0, 3, 1, 2)
        self.targets = torch.tensor(source_ds.targets, dtype=torch.long)


@register_dataset("eurosat")
class PreloadedEuroSAT(BasePreloadedDataset):
    """å†…å­˜é¢„åŠ è½½çš„EuroSATé¥æ„Ÿæ•°æ®é›†"""

    MEAN = [0.485, 0.456, 0.406]  # ImageNetæ ‡å‡†åŒ–
    STD = [0.229, 0.224, 0.225]
    IMAGE_SIZE = 64
    NUM_CLASSES = 10
    NAME = "EuroSAT"
    HAS_OFFICIAL_SPLIT = False  # æ²¡æœ‰å®˜æ–¹åˆ’åˆ†ï¼Œéœ€è¦æ‰‹åŠ¨åˆ’åˆ†

    def __init__(
        self,
        root: str,
        train: bool,
        test_split: float = 0.2,
        seed: int = 42,
    ):
        """
        åˆå§‹åŒ–EuroSATæ•°æ®é›†

        å‚æ•°:
            root: æ•°æ®é›†æ ¹ç›®å½•
            train: æ˜¯å¦ä¸ºè®­ç»ƒé›†
            test_split: è®­ç»ƒ/æµ‹è¯•åˆ’åˆ†æ¯”ä¾‹ (EuroSATæ²¡æœ‰å®˜æ–¹åˆ’åˆ†)
            seed: éšæœºç§å­
        """
        self.test_split = test_split
        self.seed = seed
        super().__init__(root, train)

    @retry(stop=stop_after_attempt(3), wait=wait_fixed(5), reraise=True)
    def _load_data(self):
        """ä¸»åŠ è½½æµç¨‹ (ç”±äºŽ EuroSAT æ— åˆ’åˆ†ï¼ŒåŒ…å«æœ¬åœ°é‡‡æ ·é€»è¾‘)"""
        # 1. å‡†å¤‡æºæ•°æ®
        source_ds = self._fetch_builtin_dataset()
        
        # 2. è§£æž PIL æ•°æ®
        start_time = time.time()
        full_imgs, full_lbls = self._extract_samples(source_ds)

        # 3. åˆ’åˆ†æ•°æ®é›†
        self._apply_train_test_split(full_imgs, full_lbls)
        
        # 4. ç»Ÿè®¡
        self._log_loaded(time.time() - start_time)

    def _fetch_builtin_dataset(self):
        """æ£€æŸ¥å¹¶ä¸‹è½½ torchvision EuroSAT"""
        eurosat_dir = Path(self.root) / "eurosat" / "2750"
        skip_download = eurosat_dir.exists()
        
        log_msg = "âœ… EuroSATå·²å­˜åœ¨" if skip_download else "ðŸ“¥ å¼€å§‹ä¸‹è½½ EuroSAT..."
        get_logger().info(log_msg)
        return torchvision.datasets.EuroSAT(root=self.root, download=not skip_download)

    def _extract_samples(self, source_ds):
        """è§£æž PIL Image åºåˆ—ä¸º NumPy é˜µåˆ—"""
        get_logger().info(f"ðŸ“¡ Parsing {self.NAME} samples...")
        imgs, lbls = [], []
        for img, target in source_ds:
            imgs.append(np.array(img))
            lbls.append(target)
        return np.stack(imgs, axis=0), np.array(lbls)

    def _apply_train_test_split(self, all_images, all_targets):
        """å¯¹å…¨é‡æ•°æ®è¿›è¡Œç¡®å®šæ€§éšæœºåˆ’åˆ†"""
        total = len(all_images)
        rng = np.random.default_rng(self.seed)
        shuffled_indices = rng.permutation(total)

        test_n = int(total * self.test_split)
        train_n = total - test_n

        indices = shuffled_indices[:train_n] if self.train else shuffled_indices[train_n:]
        
        # è½¬ä¸º Tensor å¹¶äº¤æ¢é€šé“ (H,W,C) -> (C,H,W)
        self.images = torch.from_numpy(all_images[indices]).permute(0, 3, 1, 2)
        self.targets = torch.tensor(all_targets[indices], dtype=torch.long)
