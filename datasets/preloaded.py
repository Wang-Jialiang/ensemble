"""
================================================================================
é¢„åŠ è½½æ•°æ®é›†æ¨¡å—
================================================================================

åŒ…å«: PreloadedCIFAR10, PreloadedEuroSAT, DATASET_REGISTRY
"""

import time
from pathlib import Path
from typing import Dict, Type

import numpy as np
import torch
import torchvision
from tenacity import retry, stop_after_attempt, wait_fixed

from ..utils import get_logger
from .base import BasePreloadedDataset

# â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
# â•‘ æ•°æ®é›†æ³¨å†Œè¡¨                                                                 â•‘
# â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

DATASET_REGISTRY: Dict[str, Type[BasePreloadedDataset]] = {}


def register_dataset(name: str):
    """è£…é¥°å™¨ï¼šæ³¨å†Œæ•°æ®é›†åˆ°å…¨å±€æ³¨å†Œè¡¨

    ä½¿ç”¨æ–¹å¼:
        @register_dataset("my_dataset")
        class MyDataset(BasePreloadedDataset):
            ...
    """

    def decorator(cls: Type[BasePreloadedDataset]) -> Type[BasePreloadedDataset]:
        DATASET_REGISTRY[name] = cls
        return cls

    return decorator


# â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
# â•‘ å…·ä½“æ•°æ®é›†å®ç°                                                               â•‘
# â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•


@register_dataset("cifar10")
class PreloadedCIFAR10(BasePreloadedDataset):
    """å†…å­˜é¢„åŠ è½½çš„CIFAR-10æ•°æ®é›†"""

    MEAN = [0.4914, 0.4822, 0.4465]
    STD = [0.2023, 0.1994, 0.2010]
    IMAGE_SIZE = 32
    NUM_CLASSES = 10
    NAME = "CIFAR-10"

    @retry(stop=stop_after_attempt(3), wait=wait_fixed(5), reraise=True)
    def _load_data(self):
        """åŠ è½½æ•°æ® (å¸¦é‡è¯•)"""
        try:
            # æ£€æŸ¥æ•°æ®é›†æ˜¯å¦å·²å­˜åœ¨ï¼Œé¿å…é‡å¤ä¸‹è½½
            cifar_dir = Path(self.root) / "cifar-10-batches-py"
            should_download = not cifar_dir.exists()
            if should_download:
                get_logger().info("ğŸ“¥ CIFAR-10æ•°æ®é›†ä¸å­˜åœ¨ï¼Œå¼€å§‹ä¸‹è½½...")
            else:
                get_logger().info("âœ… CIFAR-10æ•°æ®é›†å·²å­˜åœ¨ï¼Œè·³è¿‡ä¸‹è½½")

            base_dataset = torchvision.datasets.CIFAR10(
                root=self.root, train=self.train, download=should_download
            )
        except Exception as e:
            get_logger().error(f"âŒ CIFAR-10åŠ è½½å¤±è´¥: {e}")
            raise

        get_logger().info(
            f"ğŸ“¦ Preloading {'train' if self.train else 'test'} data to RAM..."
        )
        start = time.time()

        self.images = torch.from_numpy(base_dataset.data)
        self.images = self.images.permute(0, 3, 1, 2)
        self.targets = torch.tensor(base_dataset.targets, dtype=torch.long)

        self._log_loaded(time.time() - start)


@register_dataset("eurosat")
class PreloadedEuroSAT(BasePreloadedDataset):
    """å†…å­˜é¢„åŠ è½½çš„EuroSATé¥æ„Ÿæ•°æ®é›†"""

    MEAN = [0.485, 0.456, 0.406]  # ImageNetæ ‡å‡†åŒ–
    STD = [0.229, 0.224, 0.225]
    IMAGE_SIZE = 64
    NUM_CLASSES = 10
    NAME = "EuroSAT"
    HAS_OFFICIAL_SPLIT = False  # æ²¡æœ‰å®˜æ–¹åˆ’åˆ†ï¼Œéœ€è¦æ‰‹åŠ¨åˆ’åˆ†

    def __init__(
        self,
        root: str,
        train: bool,
        test_split: float = 0.2,
        seed: int = 42,
    ):
        """
        åˆå§‹åŒ–EuroSATæ•°æ®é›†

        å‚æ•°:
            root: æ•°æ®é›†æ ¹ç›®å½•
            train: æ˜¯å¦ä¸ºè®­ç»ƒé›†
            test_split: è®­ç»ƒ/æµ‹è¯•åˆ’åˆ†æ¯”ä¾‹ (EuroSATæ²¡æœ‰å®˜æ–¹åˆ’åˆ†)
            seed: éšæœºç§å­
        """
        self.test_split = test_split
        self.seed = seed
        super().__init__(root, train)

    @retry(stop=stop_after_attempt(3), wait=wait_fixed(5), reraise=True)
    def _load_data(self):
        """åŠ è½½æ•°æ® (å¸¦é‡è¯•)"""
        try:
            # æ£€æŸ¥æ•°æ®é›†æ˜¯å¦å·²å­˜åœ¨ï¼Œé¿å…é‡å¤ä¸‹è½½
            eurosat_dir = Path(self.root) / "eurosat" / "2750"
            should_download = not eurosat_dir.exists()
            if should_download:
                get_logger().info("ğŸ“¥ EuroSATæ•°æ®é›†ä¸å­˜åœ¨ï¼Œå¼€å§‹ä¸‹è½½...")
            else:
                get_logger().info("âœ… EuroSATæ•°æ®é›†å·²å­˜åœ¨ï¼Œè·³è¿‡ä¸‹è½½")

            full_dataset = torchvision.datasets.EuroSAT(
                root=self.root, download=should_download
            )
        except Exception as e:
            get_logger().error(f"âŒ EuroSATåŠ è½½å¤±è´¥: {e}")
            raise

        get_logger().info(
            f"ğŸ“¡ Preloading {'train' if self.train else 'test'} data to RAM..."
        )
        start = time.time()

        # è·å–æ‰€æœ‰æ•°æ®
        all_images = []
        all_targets = []
        for img, target in full_dataset:
            # EuroSATå›¾åƒæ˜¯PIL Imageï¼Œè½¬æ¢ä¸ºnumpyå†è½¬tensor
            img_np = np.array(img)
            all_images.append(img_np)
            all_targets.append(target)

        all_images = np.stack(all_images, axis=0)  # (N, 64, 64, 3)
        all_targets = np.array(all_targets)

        # åˆ’åˆ†è®­ç»ƒ/æµ‹è¯•é›†: ä½¿ç”¨éš”ç¦»çš„ RNG ä¿è¯å¯é‡å¤æ€§ä¸”ä¸å½±å“å…¨å±€çŠ¶æ€
        total_samples = len(all_images)
        rng = np.random.default_rng(self.seed)
        indices = rng.permutation(total_samples)

        test_size = int(total_samples * self.test_split)
        train_size = total_samples - test_size

        if self.train:
            selected_indices = indices[:train_size]
        else:
            selected_indices = indices[train_size:]

        # è½¬æ¢ä¸ºtensor
        self.images = torch.from_numpy(all_images[selected_indices])
        self.images = self.images.permute(0, 3, 1, 2)  # (N, 3, 64, 64)
        self.targets = torch.tensor(all_targets[selected_indices], dtype=torch.long)

        self._log_loaded(time.time() - start)
