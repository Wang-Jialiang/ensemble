"""
================================================================================
é¢„åŠ è½½æ•°æ®é›†æ¨¡å—
================================================================================

åŒ…å«: PreloadedCIFAR10, PreloadedEuroSAT, DATASET_REGISTRY
"""

from pathlib import Path
from typing import Dict, Type

import numpy as np
import torch
import torchvision
from torchvision import transforms
from tqdm import tqdm

from ..utils import get_logger
from .base import BasePreloadedDataset

# â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
# â•‘ æ•°æ®é›†æ³¨å†Œè¡¨                                                                 â•‘
# â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

DATASET_REGISTRY: Dict[str, Type[BasePreloadedDataset]] = {}


def register_dataset(name: str):
    """è£…é¥°å™¨ï¼šæ³¨å†Œæ•°æ®é›†åˆ°å…¨å±€æ³¨å†Œè¡¨

    ä½¿ç”¨æ–¹å¼:
        @register_dataset("my_dataset")
        class MyDataset(BasePreloadedDataset):
            ...
    """

    def decorator(cls: Type[BasePreloadedDataset]) -> Type[BasePreloadedDataset]:
        DATASET_REGISTRY[name] = cls
        return cls

    return decorator


# â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
# â•‘ å…·ä½“æ•°æ®é›†å®žçŽ°                                                               â•‘
# â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•


@register_dataset("cifar10")
class PreloadedCIFAR10(BasePreloadedDataset):
    """å†…å­˜é¢„åŠ è½½çš„CIFAR-10æ•°æ®é›†"""

    MEAN = [0.4914, 0.4822, 0.4465]
    STD = [0.2023, 0.1994, 0.2010]
    IMAGE_SIZE = 32
    NUM_CLASSES = 10
    NUM_CHANNELS = 3
    NAME = "CIFAR-10"

    def _init_transforms(self):
        """CIFAR-10 æ•°æ®å¢žå¼º: ä¿å®ˆç­–ç•¥"""
        if self.train:
            self.transform = transforms.Compose(
                [
                    transforms.RandomCrop(self.IMAGE_SIZE, padding=4),
                    transforms.RandomHorizontalFlip(p=0.5),
                    transforms.RandomRotation(degrees=15),
                ]
            )
        else:
            self.transform = None

    def _load_data(self):
        """ä¸»åŠ è½½æµç¨‹"""
        source_ds = self._fetch_builtin_dataset()
        self._ingest_source_data(source_ds)
        self._log_loaded()

    def _fetch_builtin_dataset(self):
        """åŠ è½½ torchvision CIFAR10 (å‡è®¾å·²ä¸‹è½½)"""
        return torchvision.datasets.CIFAR10(
            root=self.root, train=self.train, download=False
        )

    def _ingest_source_data(self, source_ds):
        """å°†æºæ•°æ®é›†çš„ image/targets è½¬ç§»åˆ° Tensor å½¢å¼"""
        # (N, H, W, 3) -> (N, 3, H, W)
        self.images = torch.from_numpy(source_ds.data).permute(0, 3, 1, 2)
        self.targets = torch.tensor(source_ds.targets, dtype=torch.long)


@register_dataset("eurosat")
class PreloadedEuroSAT(BasePreloadedDataset):
    """å†…å­˜é¢„åŠ è½½çš„EuroSATé¥æ„Ÿæ•°æ®é›†"""

    MEAN = [0.3444, 0.3803, 0.4078]  # EuroSAT specific statistics
    STD = [0.2037, 0.1366, 0.1148]
    IMAGE_SIZE = 64
    NUM_CLASSES = 10
    NUM_CHANNELS = 3
    NAME = "EuroSAT"
    HAS_OFFICIAL_SPLIT = False  # æ²¡æœ‰å®˜æ–¹åˆ’åˆ†ï¼Œéœ€è¦æ‰‹åŠ¨åˆ’åˆ†

    def __init__(
        self,
        root: str,
        train: bool,
        test_split: float = 0.2,
        seed: int = 42,
    ):
        """
        åˆå§‹åŒ–EuroSATæ•°æ®é›†

        å‚æ•°:
            root: æ•°æ®é›†æ ¹ç›®å½•
            train: æ˜¯å¦ä¸ºè®­ç»ƒé›†
            test_split: è®­ç»ƒ/æµ‹è¯•åˆ’åˆ†æ¯”ä¾‹ (EuroSATæ²¡æœ‰å®˜æ–¹åˆ’åˆ†)
            seed: éšæœºç§å­
        """
        self.test_split = test_split
        self.seed = seed
        super().__init__(root, train)

    def _init_transforms(self):
        """EuroSAT æ•°æ®å¢žå¼º: é¥æ„Ÿå›¾åƒé€‚ç”¨æ›´æ¿€è¿›çš„ç­–ç•¥"""
        if self.train:
            self.transform = transforms.Compose(
                [
                    # transforms.RandomCrop(self.IMAGE_SIZE, padding=4),
                    # transforms.RandomHorizontalFlip(p=0.5),
                    # transforms.RandomVerticalFlip(p=0.5),  # é¥æ„Ÿå›¾åƒå¯åž‚ç›´ç¿»è½¬
                    # transforms.RandomRotation(degrees=90),  # é¥æ„Ÿå›¾åƒå¯æ›´å¤§è§’åº¦æ—‹è½¬
                ]
            )
        else:
            self.transform = None

    def _load_data(self):
        """ä¸»åŠ è½½æµç¨‹ (æ”¯æŒç¼“å­˜åŠ é€Ÿ)"""
        cache_path = Path(self.root) / f"eurosat_cache_seed{self.seed}.npz"

        if cache_path.exists():
            # å¿«é€ŸåŠ è½½ç¼“å­˜
            get_logger().info(f"âš¡ ä»Žç¼“å­˜åŠ è½½ {self.NAME}: {cache_path}")
            data = np.load(cache_path)
            full_imgs, full_lbls = data["images"], data["targets"]
        else:
            # é¦–æ¬¡åŠ è½½å¹¶åˆ›å»ºç¼“å­˜
            get_logger().info(f"ðŸ“¡ é¦–æ¬¡åŠ è½½ {self.NAME}ï¼Œå°†åˆ›å»ºç¼“å­˜...")
            source_ds = self._fetch_builtin_dataset()
            full_imgs, full_lbls = self._extract_samples(source_ds)
            np.savez(cache_path, images=full_imgs, targets=full_lbls)
            get_logger().info(f"ðŸ’¾ ç¼“å­˜å·²ä¿å­˜: {cache_path}")

        self._apply_train_test_split(full_imgs, full_lbls)
        self._log_loaded()

    def _fetch_builtin_dataset(self):
        """åŠ è½½ torchvision EuroSAT (å‡è®¾å·²ä¸‹è½½)"""
        return torchvision.datasets.EuroSAT(root=self.root, download=False)

    def _extract_samples(self, source_ds):
        """è§£æž PIL Image åºåˆ—ä¸º NumPy é˜µåˆ— (å¸¦è¿›åº¦æ¡)"""
        get_logger().info(f"ðŸ“¡ Parsing {self.NAME} samples...")
        imgs, lbls = [], []
        for img, target in tqdm(source_ds, desc=f"Loading {self.NAME}", unit="img"):
            imgs.append(np.array(img))
            lbls.append(target)
        return np.stack(imgs, axis=0), np.array(lbls)

    def _apply_train_test_split(self, all_images, all_targets):
        """å¯¹å…¨é‡æ•°æ®è¿›è¡Œç¡®å®šæ€§éšæœºåˆ’åˆ†"""
        total = len(all_images)
        rng = np.random.default_rng(self.seed)
        shuffled_indices = rng.permutation(total)

        test_n = int(total * self.test_split)
        train_n = total - test_n

        indices = (
            shuffled_indices[:train_n] if self.train else shuffled_indices[train_n:]
        )

        # è½¬ä¸º Tensor å¹¶äº¤æ¢é€šé“ (H,W,C) -> (C,H,W)
        self.images = torch.from_numpy(all_images[indices]).permute(0, 3, 1, 2)
        self.targets = torch.tensor(all_targets[indices], dtype=torch.long)
