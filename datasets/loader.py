"""
================================================================================
æ•°æ®é›†åŠ è½½å‡½æ•°æ¨¡å—
================================================================================

åŒ…å«: load_dataset
"""

import torch
from torch.utils.data import DataLoader, Subset

from ..utils import get_logger
from .preloaded import DATASET_REGISTRY
from .robustness import CorruptionDataset, DomainShiftDataset, OODDataset

# â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
# â•‘ æ•°æ®é›†åŠ è½½å‡½æ•°                                                               â•‘
# â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•


def load_dataset(cfg):
    """åŠ è½½å¹¶é¢„å¤„ç†æ•°æ®é›† (ä¸»æµç¨‹å¤§çº²)"""
    dataset_name = cfg.dataset_name.lower()
    DatasetClass = _get_dataset_class(dataset_name)

    # 1. å‡†å¤‡æ ‡å‡†è®­ç»ƒ/éªŒè¯/æµ‹è¯• Loader
    loaders = _prepare_standard_loaders(cfg, DatasetClass)
    
    # 2. å‡†å¤‡é²æ£’æ€§è¯„ä¼°æ•°æ®é›† (åŸºäº Cache)
    robustness_suite = _init_robustness_group(cfg, dataset_name)

    get_logger().info(f"ğŸ“Š æ•°æ®é›†åˆå§‹åŒ–å®Œæˆ: {dataset_name.upper()}")
    return (*loaders, *robustness_suite)


def _get_dataset_class(name):
    """ä»æ³¨å†Œè¡¨è·å–ç±»ï¼Œå¤„ç†é”™è¯¯"""
    if name not in DATASET_REGISTRY:
        raise ValueError(f"ä¸æ”¯æŒçš„æ•°æ®é›†: {name}. å¯ç”¨: {list(DATASET_REGISTRY.keys())}")
    return DATASET_REGISTRY[name]


def _prepare_standard_loaders(cfg, DatasetClass):
    """æ‰§è¡Œæ•°æ®é›†åˆ’åˆ†å¹¶åˆ›å»ºæ ‡å‡† DataLoaders"""
    # 1. å®ä¾‹åŒ–æ•°æ®é›† (å¤„ç† EuroSAT ç­‰éå®˜æ–¹åˆ’åˆ†æƒ…å†µ)
    extra = {}
    if not getattr(DatasetClass, "HAS_OFFICIAL_SPLIT", True):
        extra = {"test_split": cfg.test_split, "seed": cfg.seed}
    train_full = DatasetClass(root=cfg.data_root, train=True, **extra)
    test_ds = DatasetClass(root=cfg.data_root, train=False, **extra)

    # 2. è®­ç»ƒ/éªŒè¯é›†åˆ’åˆ†
    v_size = int(len(train_full) * cfg.val_split)
    t_size = len(train_full) - v_size
    idx = torch.randperm(len(train_full), generator=torch.Generator().manual_seed(cfg.seed))
    
    train_sub = Subset(train_full, idx[:t_size].tolist())
    val_sub = Subset(train_full, idx[t_size:].tolist())

    # 3. æ„é€  Loader
    kwargs = {
        "num_workers": cfg.num_workers,
        "pin_memory": cfg.pin_memory,
        "persistent_workers": cfg.persistent_workers and cfg.num_workers > 0,
    }
    
    return (
        DataLoader(train_sub, batch_size=cfg.batch_size, shuffle=True, **kwargs),
        DataLoader(val_sub, batch_size=cfg.batch_size * 2, shuffle=False, **kwargs),
        DataLoader(test_ds, batch_size=cfg.batch_size * 2, shuffle=False, **kwargs)
    )


def _init_robustness_group(cfg, name):
    """æŒ‰éœ€æ¢ç´¢å¹¶åŠ è½½é²æ£’æ€§æ•°æ®é›†"""
    results = []
    
    # Corruption
    c_ds = None
    if cfg.corruption_dataset:
        try:
            c_ds = CorruptionDataset(name, cfg.data_root)
        except Exception as e:
            get_logger().warning(f"   âš ï¸ Corruption æ•°æ®é›†ä¸å¯ç”¨: {e}")
    results.append(c_ds)

    # OOD
    o_ds = None
    if cfg.ood_dataset:
        try:
            o_ds = OODDataset(id_dataset=name, root=cfg.data_root)
        except Exception as e:
            get_logger().warning(f"   âš ï¸ OOD æ•°æ®é›†ä¸å¯ç”¨: {e}")
    results.append(o_ds)

    # Domain
    d_ds = None
    if cfg.domain_dataset:
        try:
            d_ds = DomainShiftDataset(id_dataset=name, root=cfg.data_root)
        except Exception as e:
            get_logger().warning(f"   âš ï¸ Domain Shift æ•°æ®é›†ä¸å¯ç”¨: {e}")
    results.append(d_ds)

    return tuple(results)
