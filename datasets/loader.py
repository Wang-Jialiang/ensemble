"""
================================================================================
æ•°æ®é›†åŠ è½½å‡½æ•°æ¨¡å—
================================================================================

åŒ…å«: load_dataset
"""

import torch
from torch.utils.data import DataLoader, Subset

from ..utils import get_logger
from .corruption import CorruptionDataset
from .preloaded import DATASET_REGISTRY

# â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
# â•‘ æ•°æ®é›†åŠ è½½å‡½æ•°                                                               â•‘
# â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•


def load_dataset(cfg):
    """
    åŠ è½½å¹¶é¢„å¤„ç†æ•°æ®é›†

    å‚æ•°:
        cfg: é…ç½®å¯¹è±¡

    è¿”å›:
        train_loader, val_loader, test_loader, corruption_dataset
    """
    dataset_name = cfg.dataset_name.lower()

    if dataset_name not in DATASET_REGISTRY:
        raise ValueError(
            f"ä¸æ”¯æŒçš„æ•°æ®é›†: {dataset_name}. æ”¯æŒ: {list(DATASET_REGISTRY.keys())}"
        )

    DatasetClass = DATASET_REGISTRY[dataset_name]

    # ä¸ºæ²¡æœ‰å®˜æ–¹åˆ’åˆ†çš„æ•°æ®é›†ä¼ é€’é¢å¤–å‚æ•°
    extra_kwargs = {}
    if not getattr(DatasetClass, "HAS_OFFICIAL_SPLIT", True):
        extra_kwargs["test_split"] = cfg.test_split

    # åˆ›å»ºå®Œæ•´è®­ç»ƒé›† (ç”¨äºåˆ’åˆ†)
    train_full = DatasetClass(root=cfg.data_root, train=True, **extra_kwargs)
    test_dataset = DatasetClass(root=cfg.data_root, train=False, **extra_kwargs)

    # åˆ’åˆ†è®­ç»ƒé›†å’ŒéªŒè¯é›†
    total_train = len(train_full)
    val_size = int(total_train * cfg.val_split)
    train_size = total_train - val_size

    generator = torch.Generator().manual_seed(cfg.seed)
    indices = torch.randperm(total_train, generator=generator)
    train_indices = indices[:train_size].tolist()
    val_indices = indices[train_size:].tolist()

    # ä½¿ç”¨ PyTorch å†…ç½® Subset
    train_subset = Subset(train_full, train_indices)
    val_subset = Subset(train_full, val_indices)

    # åˆ›å»ºDataLoader
    common_loader_kwargs = {
        "num_workers": cfg.num_workers,
        "pin_memory": cfg.pin_memory,
        "persistent_workers": cfg.persistent_workers and cfg.num_workers > 0,
        "prefetch_factor": cfg.prefetch_factor if cfg.num_workers > 0 else None,
    }

    train_loader = DataLoader(
        train_subset, batch_size=cfg.batch_size, shuffle=True, **common_loader_kwargs
    )
    val_loader = DataLoader(
        val_subset, batch_size=cfg.batch_size * 2, shuffle=False, **common_loader_kwargs
    )
    test_loader = DataLoader(
        test_dataset,
        batch_size=cfg.batch_size * 2,
        shuffle=False,
        **common_loader_kwargs,
    )

    get_logger().info(f"ğŸ“Š æ•°æ®é›†: {dataset_name.upper()}")
    get_logger().info(
        f"   è®­ç»ƒé›†: {len(train_subset)} | éªŒè¯é›†: {len(val_subset)} | æµ‹è¯•é›†: {len(test_dataset)}"
    )

    # åŠ è½½Corruptionæ•°æ®é›† (ä»»ä½•åœ¨ DATASET_REGISTRY ä¸­çš„æ•°æ®é›†éƒ½æ”¯æŒ)
    corruption_dataset = None
    try:
        corruption_dataset = CorruptionDataset.from_name(dataset_name, cfg.data_root)
        get_logger().info(f"   Corruptionæ•°æ®é›†: {corruption_dataset.name}")
    except FileNotFoundError as e:
        get_logger().warning(f"   âš ï¸ Corruptionæ•°æ®é›†æœªæ‰¾åˆ°: {e}")

    return train_loader, val_loader, test_loader, corruption_dataset
