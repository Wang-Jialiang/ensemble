# ==============================================================================
# 配置文件
# ==============================================================================

# ==============================================================================
# 业界标准常量 - 通常无需修改
# ==============================================================================
constants:
  # 数据集划分 (机器学习惯例)
  val_split: 0.1                    # 验证集划分比例 (10%)
  test_split: 0.2                   # 测试集划分比例 (20%)

  # 优化器标准参数
  weight_decay: 0.0001              # AdamW 推荐值 (Loshchilov & Hutter, 2019)
  max_grad_norm: 1.0                # 梯度裁剪标准阈值
  sgd_momentum: 0.9                 # SGD 动量标准值
  label_smoothing: 0.1              # 标签平滑 (Szegedy et al., 2016)

  # DataLoader 标准配置
  pin_memory: true                  # GPU 训练必开
  persistent_workers: true          # PyTorch 1.7+ 推荐

  # 硬件加速 (现代 GPU 标配)
  use_amp: true                     # 自动混合精度
  use_tf32: true                    # TF32 加速 (Ampere+)
  compile_model: true               # PyTorch 2.0+ 编译优化

  # 对抗鲁棒性评估 (Madry et al., 2018; RobustBench)
  adv_eps: 0.03137                  # ε = 8/255
  adv_alpha: 0.00784                # α = 2/255
  adv_pgd_steps: 10                 # PGD 标准迭代数

  # 校准度评估 (Guo et al., 2017)
  ece_n_bins: 15                    # ECE 分箱数

  # 数据增强标准值
  cutout_fill_value: 0.5            # 归一化后中性灰
  perlin_persistence: 0.5           # Perlin 噪声标准持久度

  # 可视化
  plot_dpi: 300                     # 图表保存 DPI

# ==============================================================================
# 可调参数
# ==============================================================================
base:
  # ==========================================================================
  # [全局] 数据配置 - 被 BaseTrainer 及所有子类使用
  # ==========================================================================
  data_root: "./data"               # 数据集根目录路径
  save_root: "./outputs"             # 检查点/输出保存根目录
  dataset_name: "cifar10"           # 数据集名称: "cifar10", "cifar100", "eurosat" 等

  # ==========================================================================
  # [全局] 模型配置 - 被 BaseTrainer 及所有子类使用
  # ==========================================================================
  model_name: "resnet18"            # 模型名称: "resnet18", "resnet50", "vgg16" 等
  num_models_per_gpu: 3             # 每个 GPU 上的模型数量

  # ==========================================================================
  # [全局] 训练超参数 - 被 BaseTrainer 及所有子类使用
  # ==========================================================================
  batch_size: 512                   # 批次大小
  lr: 0.0015                        # 基础学习率
  seed: 42                          # 随机种子
  optimizer: "adamw"                # 优化器: "adamw", "sgd", "adam", "rmsprop"
  scheduler: "cosine"               # 调度器: "cosine", "step", "plateau", "none"
  early_stopping_patience: 20       # 早停耐心值 (验证集无改善的轮数)

  # ==========================================================================
  # [阶段训练专用] 三阶段与 Mask - 仅 StagedEnsembleTrainer 使用
  # ==========================================================================
  warmup_epochs: 20                 # Warmup 阶段轮数
  progressive_epochs: 40            # Progressive 阶段轮数
  finetune_epochs: 20               # Finetune 阶段轮数
  mask_pool_size: 100               # 预生成的 Mask 池大小
  mask_start_ratio: 0.15            # Progressive 阶段起始遮罩比例
  mask_end_ratio: 0.35              # Progressive 阶段结束遮罩比例
  mask_prob_start: 0.30             # Progressive 阶段起始应用概率
  mask_prob_end: 0.70               # Progressive 阶段结束应用概率
  finetune_mask_ratio: 0.25         # Finetune 阶段固定遮罩比例
  finetune_mask_prob: 0.50          # Finetune 阶段固定应用概率

  # ==========================================================================
  # [阶段训练专用] 阶段学习率缩放 - 仅 StagedEnsembleTrainer 使用
  # ==========================================================================
  warmup_lr_scale: 0.5              # Warmup 阶段学习率缩放因子 (lr * scale)
  progressive_lr_scale: 1.0         # Progressive 阶段学习率缩放因子
  finetune_lr_scale: 0.5            # Finetune 阶段学习率缩放因子

  # ==========================================================================
  # [全局] 数据加载配置 - 被 BaseTrainer 及所有子类使用
  # ==========================================================================
  num_workers: 16                   # DataLoader 工作进程数
  prefetch_factor: 4                # 每个 worker 预取的批次数

  # ==========================================================================
  # [全局] 保存与日志配置 - 被 BaseTrainer 及所有子类使用
  # ==========================================================================
  save_every_n_epochs: 20           # 每 N 轮保存一次检查点
  keep_last_n_checkpoints: 3        # 保留最近 N 个检查点
  use_tensorboard: true             # 是否启用 TensorBoard 日志
  log_level: "INFO"                 # 日志级别: "DEBUG", "INFO", "WARNING", "ERROR"

  # ==========================================================================
  # [评估专用] 评估配置 - 仅评估模块使用
  # ==========================================================================
  ensemble_strategy: "mean"         # 集成策略: "mean" (等权平均), "voting" (多数投票)
  corruption_dataset: true          # 是否加载 Corruption 数据集进行评估
  ood_dataset: false                # 是否加载 OOD 数据集进行评估
  domain_dataset: false             # 是否加载 Domain Shift 数据集进行评估

  # ==========================================================================
  # [全局] 模型初始化 - 被 BaseTrainer 及所有子类使用
  # ==========================================================================
  init_method: "kaiming"            # 初始化方法: "kaiming", "xavier", "orthogonal", "default"

  # ==========================================================================
  # [全局] 运行控制 - 被 BaseTrainer 及所有子类使用
  # ==========================================================================
  quick_test: false                 # 快速测试模式 (减少轮数/模型数)

  # ==========================================================================
  # [实验级别] 增强与课程学习参数 - 每个实验可覆盖
  # ==========================================================================
  augmentation_method: "perlin"     # 增强方法: "perlin", "cutout", "none" 等
  use_curriculum: true              # 是否使用课程学习
  fixed_ratio: 0.25                 # 固定遮挡比例 (仅 use_curriculum=false 时生效)
  fixed_prob: 0.5                   # 固定遮挡概率 (仅 use_curriculum=false 时生效)
  share_warmup_backbone: false      # 是否在 warmup 后共享 backbone (仅 use_curriculum=true 时生效)

# ==============================================================================
# 实验列表
# ==============================================================================
experiments:
  - name: "ExpD_Perlin_Curriculum"
    desc: "Perlin + Dual Curriculum (PROPOSED)"
    augmentation_method: "perlin"
    use_curriculum: true

  - name: "ExpA_Baseline"
    desc: "Baseline (No Augmentation)"
    augmentation_method: "none"
    use_curriculum: false

  - name: "ExpB_Cutout_Fixed"
    desc: "Cutout Fixed (ratio=25%, prob=50%)"
    augmentation_method: "cutout"
    use_curriculum: false
    fixed_ratio: 0.25
    fixed_prob: 0.5

  - name: "ExpC_Perlin_Fixed"
    desc: "Perlin Fixed (ratio=25%, prob=50%)"
    augmentation_method: "perlin"
    use_curriculum: false
    fixed_ratio: 0.25
    fixed_prob: 0.5

  - name: "ExpE_Cutout_Curriculum"
    desc: "Cutout + Dual Curriculum"
    augmentation_method: "cutout"
    use_curriculum: true

# ==============================================================================
# 评估配置 (仅 --eval 模式)
# ==============================================================================
eval_checkpoints:
  - name: "ExpA_Baseline"
    path: "./outputs/exp_latest/checkpoints/ExpA_Baseline/best"

  - name: "ExpB_Cutout_Fixed"
    path: "./outputs/exp_latest/checkpoints/ExpB_Cutout_Fixed/best"

  - name: "ExpC_Perlin_Fixed"
    path: "./outputs/exp_latest/checkpoints/ExpC_Perlin_Fixed/best"

  - name: "ExpD_Perlin_Curriculum"
    path: "./outputs/exp_latest/checkpoints/ExpD_Perlin_Curriculum/best"

  - name: "ExpE_Cutout_Curriculum"
    path: "./outputs/exp_latest/checkpoints/ExpE_Cutout_Curriculum/best"
