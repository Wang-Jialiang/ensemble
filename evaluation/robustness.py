"""
================================================================================
é²æ£’æ€§è¯„ä¼°æ¨¡å—
================================================================================

åŒ…å«: Corruption è¯„ä¼°ã€åŸŸåç§»è¯„ä¼°
"""

from typing import Any, Dict, Optional

import numpy as np
from torch.utils.data import DataLoader

from ..utils import get_logger
from .core import (
    ENSEMBLE_STRATEGIES,
    MetricsCalculator,
    extract_models,
    get_all_models_logits,
)

# â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
# â•‘ Corruption é²æ£’æ€§è¯„ä¼°                                                         â•‘
# â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•


def evaluate_corruption(
    trainer_or_models: Any,
    corruption_dataset: "CorruptionDataset",
    batch_size: int = 128,
    num_workers: int = 4,
    logger: Optional[Any] = None,
) -> Dict[str, Any]:
    """
    é€šç”¨ Corruption é²æ£’æ€§è¯„ä¼°
    """
    from tqdm import tqdm

    logger = logger or get_logger()
    dataset_name = corruption_dataset.name
    n_corruptions = len(corruption_dataset.CORRUPTIONS)
    total_evals = 5 * n_corruptions  # 5 severity Ã— N corruptions

    logger.info(f"\nğŸ§ª Running Corruption Evaluation on {dataset_name}")
    logger.info(
        f"   ğŸ“Š {n_corruptions} corruptions Ã— 5 severities = {total_evals} æ¬¡è¯„ä¼°"
    )

    models, device = extract_models(trainer_or_models)
    results = {}
    overall_avg = 0.0

    # åˆ›å»ºæ€»è¿›åº¦æ¡
    pbar = tqdm(total=total_evals, desc="Corruption Eval", leave=False)

    for severity in range(1, 6):
        results[severity] = {}
        severity_accs = []

        for corruption in corruption_dataset.CORRUPTIONS:
            pbar.set_postfix({"severity": severity, "type": corruption[:10]})

            loader = corruption_dataset.get_loader(
                corruption,
                severity=severity,
                batch_size=batch_size,
                num_workers=num_workers,
            )

            # åªéœ€é¢„æµ‹ï¼Œä¸éœ€è¦è¯¦ç»†çš„ Calculator (åªç®— Acc)
            all_logits, targets = get_all_models_logits(models, loader, device)

            ensemble_logits = all_logits.mean(dim=0)
            ensemble_preds = ensemble_logits.argmax(dim=1)
            acc = 100.0 * (ensemble_preds == targets).float().mean().item()

            results[severity][corruption] = acc
            severity_accs.append(acc)
            pbar.update(1)

        avg_acc_sev = np.mean(severity_accs)
        results[severity]["avg"] = avg_acc_sev
        overall_avg += avg_acc_sev

    pbar.close()

    overall_avg /= 5.0
    logger.info(f"   âœ… å®Œæˆ! Overall Avg: {overall_avg:.2f}%")

    results["severity_5_raw"] = results[5]
    results["overall_avg"] = overall_avg
    return results


# â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
# â•‘ Domain Shift (åŸŸåç§») è¯„ä¼°                                                    â•‘
# â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•


def evaluate_domain_shift(
    trainer_or_models: Any,
    domain_loader: DataLoader,
    domain_name: str = "Domain",
    num_classes: int = 10,
    logger: Optional[Any] = None,
) -> Dict[str, Any]:
    """
    Domain Shift (åŸŸåç§») è¯„ä¼°

    è¯„ä¼°æ¨¡å‹åœ¨ä¸åŒè§†è§‰åŸŸ/é£æ ¼ä¸Šçš„åˆ†ç±»å‡†ç¡®ç‡ã€‚

    Args:
        trainer_or_models: StagedEnsembleTrainer å®ä¾‹æˆ– List[nn.Module]
        domain_loader: Domain Shift æ•°æ®åŠ è½½å™¨ï¼ˆéœ€åŒ…å«æ­£ç¡®çš„æ ‡ç­¾ï¼‰
        domain_name: åŸŸåç§°ï¼ˆç”¨äºæ—¥å¿—ï¼‰
        num_classes: ç±»åˆ«æ•°é‡
        logger: æ—¥å¿—è®°å½•å™¨

    Returns:
        åŒ…å«åŸŸåç§»è¯„ä¼°æŒ‡æ ‡çš„å­—å…¸
    """
    logger = logger or get_logger()
    logger.info(f"\nğŸŒ Running Domain Shift Evaluation ({domain_name})")

    models, device = extract_models(trainer_or_models)
    calculator = MetricsCalculator(num_classes=num_classes)
    ensemble_fn = ENSEMBLE_STRATEGIES["mean"]

    # è·å–æ‰€æœ‰æ¨¡å‹çš„ logits
    all_logits, targets = get_all_models_logits(models, domain_loader, device)

    if len(all_logits) == 0:
        logger.warning("   âš ï¸ æ— æ•°æ®å¯è¯„ä¼°")
        return {"domain_name": domain_name, "error": "No data"}

    # è®¡ç®—æŒ‡æ ‡
    metrics = calculator.calculate_all_metrics(all_logits, targets, ensemble_fn)

    results = {
        "domain_name": domain_name,
        "num_samples": len(targets),
        "domain_acc": metrics["ensemble_acc"],
        "domain_balanced_acc": metrics["balanced_acc"],
        "domain_worst_class_acc": metrics["worst_class_acc"],
        "domain_avg_individual_acc": metrics["avg_individual_acc"],
        # é›†æˆ vs å•æ¨¡å‹çš„æå‡
        "domain_ensemble_gain": metrics["ensemble_acc"] - metrics["avg_individual_acc"],
    }

    logger.info(f"   âœ… Domain Shift Results ({domain_name}):")
    logger.info(f"      Ensemble Acc: {results['domain_acc']:.2f}%")
    logger.info(f"      Balanced Acc: {results['domain_balanced_acc']:.2f}%")
    logger.info(f"      Ensemble Gain: {results['domain_ensemble_gain']:+.2f}%")

    return results
