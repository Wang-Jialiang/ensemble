"""
================================================================================
Grad-CAM åˆ†æ + Loss Landscape å¯è§†åŒ–æ¨¡å—
================================================================================
"""

from pathlib import Path
from typing import Any, Dict, List, Optional

import numpy as np
import torch
import torch.nn as nn
from torch.utils.data import DataLoader

from ..utils import ensure_dir, get_logger

# â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
# â•‘ Grad-CAM ç›®æ ‡å±‚è¾…åŠ©å‡½æ•°                                                      â•‘
# â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•


def get_target_layer(model: nn.Module, model_name: str) -> nn.Module:
    """è·å–æ¨¡å‹çš„ç›®æ ‡å±‚ç”¨äºGrad-CAM

    æ ¹æ®æ¨¡å‹æ¶æ„è‡ªåŠ¨ç¡®å®šé€‚åˆç”¨äºGrad-CAMå¯è§†åŒ–çš„ç›®æ ‡å±‚ã€‚

    Args:
        model: PyTorchæ¨¡å‹
        model_name: æ¨¡å‹åç§° (resnet18, vgg16, efficientnet_b0ç­‰)

    Returns:
        ç›®æ ‡å±‚æ¨¡å—

    Raises:
        ValueError: æ— æ³•è‡ªåŠ¨ç¡®å®šç›®æ ‡å±‚æ—¶æŠ›å‡º
    """
    model_name = model_name.lower()
    if "resnet" in model_name:
        return model.layer4[-1]
    elif "vgg" in model_name:
        return model.features[-1]
    elif "efficientnet" in model_name:
        return model.features[-1]
    else:
        # é»˜è®¤å°è¯•layer4
        if hasattr(model, "layer4"):
            return model.layer4[-1]
        raise ValueError(f"æ— æ³•è‡ªåŠ¨ç¡®å®š {model_name} çš„ç›®æ ‡å±‚ï¼Œè¯·æ‰‹åŠ¨æŒ‡å®š")


# â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
# â•‘ Grad-CAM çƒ­åŠ›å›¾ç”Ÿæˆå™¨                                                        â•‘
# â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•


class GradCAM:
    """
    Grad-CAM (Gradient-weighted Class Activation Mapping) - åŸºäº pytorch-grad-cam åº“

    ç”¨äºç”Ÿæˆæ¨¡å‹æ³¨æ„åŠ›çƒ­åŠ›å›¾ï¼Œå¯è§†åŒ–æ¨¡å‹å…³æ³¨çš„å›¾åƒåŒºåŸŸã€‚

    ä¾èµ–: pip install grad-cam
    """

    def __init__(self, model: nn.Module, target_layer: nn.Module):
        """åˆå§‹åŒ–Grad-CAM

        Args:
            model: PyTorchæ¨¡å‹
            target_layer: ç”¨äºç”ŸæˆCAMçš„ç›®æ ‡å±‚ (ä½¿ç”¨get_target_layerè·å–)
        """
        self.model = model
        self.target_layer = target_layer
        self._cam = None  # å»¶è¿Ÿåˆå§‹åŒ–

    def _get_cam(self):
        """å»¶è¿Ÿåˆå§‹åŒ– CAM å¯¹è±¡"""
        if self._cam is None:
            try:
                from pytorch_grad_cam import GradCAM as LibGradCAM

                self._cam = LibGradCAM(
                    model=self.model, target_layers=[self.target_layer]
                )
            except ImportError:
                raise ImportError("éœ€è¦å®‰è£… grad-cam: pip install grad-cam")
        return self._cam

    def generate_cam(self, input_tensor: torch.Tensor, target_class: int) -> np.ndarray:
        """ç”ŸæˆGrad-CAMçƒ­åŠ›å›¾ (å•å¼ å›¾åƒ)

        Args:
            input_tensor: è¾“å…¥å¼ é‡ï¼Œshape (1, C, H, W)
            target_class: ç›®æ ‡ç±»åˆ«ç´¢å¼•

        Returns:
            CAM çƒ­åŠ›å›¾ï¼Œshape (H, W)ï¼Œå€¼åœ¨ [0, 1]
        """
        cams = self.generate_cam_batch(input_tensor, [target_class])
        return cams[0]

    def generate_cam_batch(
        self, input_tensor: torch.Tensor, target_classes: List[int]
    ) -> np.ndarray:
        """æ‰¹é‡ç”ŸæˆGrad-CAMçƒ­åŠ›å›¾ (æ€§èƒ½ä¼˜åŒ–ç‰ˆ)

        Args:
            input_tensor: è¾“å…¥å¼ é‡ï¼Œshape (N, C, H, W)
            target_classes: ç›®æ ‡ç±»åˆ«åˆ—è¡¨ï¼Œé•¿åº¦ä¸º N

        Returns:
            CAM çƒ­åŠ›å›¾æ•°ç»„ï¼Œshape (N, H, W)ï¼Œå€¼åœ¨ [0, 1]
        """
        try:
            from pytorch_grad_cam.utils.model_targets import ClassifierOutputTarget
        except ImportError:
            raise ImportError("éœ€è¦å®‰è£… grad-cam: pip install grad-cam")

        cam_obj = self._get_cam()

        # æ‰¹é‡ç”Ÿæˆ CAM - ä¸€æ¬¡å¤„ç†æ•´ä¸ª batch
        targets = [ClassifierOutputTarget(cls) for cls in target_classes]
        grayscale_cams = cam_obj(input_tensor=input_tensor, targets=targets)

        # è¿”å› shape (N, H, W)
        return grayscale_cams

    def remove_hooks(self):
        """ç§»é™¤hooksï¼Œé‡Šæ”¾èµ„æº"""
        if self._cam is not None:
            del self._cam
            self._cam = None


# â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
# â•‘ Grad-CAMå¤šæ ·æ€§åˆ†æå™¨                                                         â•‘
# â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•


class GradCAMAnalyzer:
    """
    Grad-CAMå¤šæ ·æ€§è´¨é‡åˆ†æå™¨

    ç”¨äºåˆ†æé›†æˆæ¨¡å‹ä¸­å„æˆå‘˜çš„æ³¨æ„åŠ›åˆ†å¸ƒå¤šæ ·æ€§ã€‚

    åˆ†ææŒ‡æ ‡:
        - avg_cam_entropy: CAMçƒ­åŠ›å›¾çš„ç†µ (è¶Šé«˜è¡¨ç¤ºæ³¨æ„åŠ›è¶Šåˆ†æ•£)
        - avg_cam_similarity: æ¨¡å‹é—´CAMç›¸ä¼¼åº¦ (è¶Šä½è¡¨ç¤ºè¶Šå¤šæ ·)
        - avg_cam_overlap: CAMçƒ­ç‚¹åŒºåŸŸé‡å åº¦ (è¶Šä½è¡¨ç¤ºè¶Šå¤šæ ·)
        - pred_cam_correlation: é¢„æµ‹ä¸CAMçš„ç›¸å…³æ€§
    """

    def __init__(self, cfg: "Config"):
        self.cfg = cfg
        self.model_name = cfg.model_name

    def analyze_ensemble_quality(
        self, workers: List, test_loader, num_samples: int = 50, image_size: int = 32
    ) -> Dict[str, Any]:
        """åˆ†æé›†æˆæ¨¡å‹çš„Grad-CAMå¤šæ ·æ€§

        Returns:
            metrics: åŒ…å«per_modelå’ŒoverallæŒ‡æ ‡çš„å­—å…¸
        """
        # æ”¶é›†æ ·æœ¬
        samples = []
        labels = []
        for inputs, targets in test_loader:
            for i in range(min(len(inputs), num_samples - len(samples))):
                samples.append(inputs[i : i + 1])
                labels.append(targets[i].item())
            if len(samples) >= num_samples:
                break

        if len(samples) == 0:
            get_logger().warning("âš ï¸ No samples for Grad-CAM analysis")
            return {}

        samples = torch.cat(samples, dim=0)

        # æ”¶é›†æ‰€æœ‰æ¨¡å‹çš„CAM
        all_cams = []
        all_preds = []

        for worker in workers:
            for model_idx, model in enumerate(worker.models):
                model.eval()
                device = next(model.parameters()).device
                target_layer = get_target_layer(model, self.model_name)
                gradcam = GradCAM(model, target_layer)

                model_cams = []
                model_preds = []

                samples_device = samples.to(device)
                with torch.no_grad():
                    logits = model(samples_device)
                    preds = logits.argmax(dim=1).cpu().tolist()

                # æ‰¹é‡ç”ŸæˆCAM
                cams = gradcam.generate_cam_batch(samples_device, preds)
                model_cams = list(cams)
                model_preds = preds

                gradcam.remove_hooks()

                all_cams.append(model_cams)
                all_preds.append(model_preds)

        # è®¡ç®—æŒ‡æ ‡
        metrics = self._compute_diversity_metrics(all_cams, all_preds, labels)

        return metrics

    def _compute_diversity_metrics(
        self,
        all_cams: List[List[np.ndarray]],
        all_preds: List[List[int]],
        labels: List[int],
    ) -> Dict[str, Any]:
        """è®¡ç®—å¤šæ ·æ€§æŒ‡æ ‡"""
        num_models = len(all_cams)
        num_samples = len(all_cams[0]) if all_cams else 0

        if num_samples == 0:
            return {}

        per_model_metrics = []

        for model_idx in range(num_models):
            model_cams = all_cams[model_idx]
            model_preds = all_preds[model_idx]

            # è®¡ç®—CAMç†µ
            entropies = []
            for cam in model_cams:
                cam_flat = cam.flatten()
                cam_flat = cam_flat / (cam_flat.sum() + 1e-8)
                entropy = -np.sum(cam_flat * np.log(cam_flat + 1e-8))
                entropies.append(entropy)

            # é¢„æµ‹å‡†ç¡®ç‡
            correct = sum(
                1 for pred, label in zip(model_preds, labels) if pred == label
            )
            accuracy = correct / len(labels)

            per_model_metrics.append(
                {
                    "avg_cam_entropy": np.mean(entropies),
                    "accuracy": accuracy * 100,
                }
            )

        # è®¡ç®—æ¨¡å‹é—´ç›¸ä¼¼åº¦
        similarities = []
        overlaps = []

        for i in range(num_models):
            for j in range(i + 1, num_models):
                for s in range(num_samples):
                    cam_i = all_cams[i][s].flatten()
                    cam_j = all_cams[j][s].flatten()

                    # ä½™å¼¦ç›¸ä¼¼åº¦
                    sim = np.dot(cam_i, cam_j) / (
                        np.linalg.norm(cam_i) * np.linalg.norm(cam_j) + 1e-8
                    )
                    similarities.append(sim)

                    # é‡å åº¦ (IoU)
                    threshold = 0.5
                    mask_i = cam_i > threshold * cam_i.max()
                    mask_j = cam_j > threshold * cam_j.max()
                    intersection = np.logical_and(mask_i, mask_j).sum()
                    union = np.logical_or(mask_i, mask_j).sum()
                    iou = intersection / (union + 1e-8)
                    overlaps.append(iou)

        overall_metrics = {
            "avg_cam_entropy": np.mean(
                [m["avg_cam_entropy"] for m in per_model_metrics]
            ),
            "avg_cam_similarity": np.mean(similarities) if similarities else 0,
            "avg_cam_overlap": np.mean(overlaps) if overlaps else 0,
            "std_cam_entropy": np.std(
                [m["avg_cam_entropy"] for m in per_model_metrics]
            ),
        }

        return {
            "per_model": per_model_metrics,
            "overall": overall_metrics,
        }


class ModelListWrapper:
    """æ¨¡å‹åˆ—è¡¨çš„ç®€æ˜“åŒ…è£…å™¨ï¼Œç”¨äºå…¼å®¹ GradCAMAnalyzer çš„ workers æ¥å£"""

    def __init__(self, models: List[nn.Module]):
        self.models = models


# â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
# â•‘ Loss Landscape å¯è§†åŒ–å™¨                                                       â•‘
# â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•


class LossLandscapeVisualizer:
    """Loss Landscape å¯è§†åŒ–å™¨

    ç”¨äºå¯è§†åŒ–é›†æˆæ¨¡å‹ä¸­å„æˆå‘˜åœ¨æŸå¤±åœ°å½¢ä¸Šçš„ä½ç½®åˆ†å¸ƒã€‚

    åŠŸèƒ½:
        - 1D æ’å€¼: åœ¨ä¸¤ä¸ªæ¨¡å‹ä¹‹é—´çº¿æ€§æ’å€¼ï¼Œè§‚å¯ŸæŸå¤±å˜åŒ–
        - 2D å¹³é¢: å›´ç»•å•ä¸ªæ¨¡å‹åœ¨éšæœºæ–¹å‘ä¸Šé‡‡æ ·ï¼Œç”Ÿæˆç­‰é«˜çº¿å›¾
        - æ¨¡å‹é—´è·ç¦»: è®¡ç®—æ¨¡å‹åœ¨å‚æ•°ç©ºé—´ä¸­çš„æ¬§æ°è·ç¦»

    ä¾èµ–: pip install loss-landscapes
    """

    def __init__(self, save_dir: str):
        self.save_dir = Path(save_dir)
        ensure_dir(self.save_dir)
        self.logger = get_logger()

    def _check_dependency(self):
        """æ£€æŸ¥ loss-landscapes ä¾èµ–"""
        import importlib.util

        if importlib.util.find_spec("loss_landscapes") is None:
            self.logger.warning(
                "âš ï¸ loss-landscapes æœªå®‰è£…ï¼Œè¯·è¿è¡Œ: pip install loss-landscapes"
            )
            return False
        return True

    def _create_metric(
        self, model: nn.Module, dataloader: DataLoader, device: torch.device
    ):
        """åˆ›å»ºæŸå¤±è¯„ä¼°å™¨"""
        import loss_landscapes.metrics as metrics

        criterion = nn.CrossEntropyLoss()

        class LossMetric(metrics.Metric):
            """è‡ªå®šä¹‰æŸå¤±è¯„ä¼°å™¨"""

            def __init__(self, criterion, dataloader, device):
                super().__init__()
                self.criterion = criterion
                self.dataloader = dataloader
                self.device = device

            def __call__(self, model):
                model.eval()
                total_loss = 0.0
                total_samples = 0
                with torch.no_grad():
                    for inputs, targets in self.dataloader:
                        inputs = inputs.to(self.device)
                        targets = targets.to(self.device)
                        outputs = model(inputs)
                        loss = self.criterion(outputs, targets)
                        total_loss += loss.item() * inputs.size(0)
                        total_samples += inputs.size(0)
                return total_loss / total_samples if total_samples > 0 else 0.0

        return LossMetric(criterion, dataloader, device)

    def plot_1d_interpolation(
        self,
        model1: nn.Module,
        model2: nn.Module,
        dataloader: DataLoader,
        device: torch.device,
        steps: int = 50,
        filename: str = "loss_landscape_1d.png",
        label1: str = "Model 1",
        label2: str = "Model 2",
    ) -> Optional[np.ndarray]:
        """ç»˜åˆ¶ä¸¤ä¸ªæ¨¡å‹ä¹‹é—´çš„1DæŸå¤±æ’å€¼æ›²çº¿"""
        if not self._check_dependency():
            return None

        import loss_landscapes
        import matplotlib.pyplot as plt

        self.logger.info(f"ğŸ“ˆ æ­£åœ¨è®¡ç®— 1D Loss Landscape ({label1} â†’ {label2})...")

        model1 = model1.to(device)
        model2 = model2.to(device)
        metric = self._create_metric(model1, dataloader, device)

        # çº¿æ€§æ’å€¼
        loss_data = loss_landscapes.linear_interpolation(
            model1, model2, metric, steps=steps
        )

        # ç»˜å›¾
        fig, ax = plt.subplots(figsize=(10, 6))
        x = np.linspace(0, 1, steps)
        ax.plot(x, loss_data, "b-", linewidth=2)
        ax.scatter([0, 1], [loss_data[0], loss_data[-1]], c="red", s=100, zorder=5)
        ax.annotate(
            label1,
            (0, loss_data[0]),
            textcoords="offset points",
            xytext=(10, 10),
            fontsize=10,
        )
        ax.annotate(
            label2,
            (1, loss_data[-1]),
            textcoords="offset points",
            xytext=(10, 10),
            fontsize=10,
        )

        ax.set_xlabel("Interpolation (Î±)")
        ax.set_ylabel("Loss")
        ax.set_title(f"Loss Landscape: {label1} â†’ {label2}")
        ax.grid(True, alpha=0.3)

        plt.tight_layout()
        plt.savefig(self.save_dir / filename, dpi=150)
        plt.close()

        self.logger.info(f"ğŸ“Š Saved: {filename}")
        return loss_data

    def plot_2d_plane(
        self,
        model: nn.Module,
        dataloader: DataLoader,
        device: torch.device,
        distance: float = 1.0,
        steps: int = 40,
        filename: str = "loss_landscape_2d.png",
        model_name: str = "Model",
    ) -> Optional[np.ndarray]:
        """ç»˜åˆ¶æ¨¡å‹å‘¨å›´çš„2DæŸå¤±åœ°å½¢ç­‰é«˜çº¿å›¾"""
        if not self._check_dependency():
            return None

        import loss_landscapes
        import matplotlib.pyplot as plt

        self.logger.info(f"ğŸ“ˆ æ­£åœ¨è®¡ç®— 2D Loss Landscape ({model_name})...")
        self.logger.info(
            f"   â³ é¢„è®¡ {steps}Ã—{steps}={steps * steps} æ¬¡å‰å‘ä¼ æ’­ï¼Œè¯·è€å¿ƒç­‰å¾…..."
        )

        model = model.to(device)
        metric = self._create_metric(model, dataloader, device)

        # éšæœºæ–¹å‘å¹³é¢é‡‡æ ·
        loss_data = loss_landscapes.random_plane(
            model, metric, distance=distance, steps=steps, normalization="filter"
        )
        self.logger.info("   âœ… 2D é‡‡æ ·å®Œæˆ")

        # åˆ›å»ºåæ ‡ç½‘æ ¼
        x = np.linspace(-distance, distance, steps)
        y = np.linspace(-distance, distance, steps)
        X, Y = np.meshgrid(x, y)

        # ç»˜åˆ¶ç­‰é«˜çº¿å›¾
        fig, ax = plt.subplots(figsize=(10, 8))
        contour = ax.contourf(X, Y, loss_data, levels=50, cmap="viridis")
        plt.colorbar(contour, ax=ax, label="Loss")
        ax.scatter([0], [0], c="red", s=100, marker="*", label=model_name, zorder=5)
        ax.legend()
        ax.set_xlabel("Direction 1")
        ax.set_ylabel("Direction 2")
        ax.set_title(f"2D Loss Landscape around {model_name}")
        plt.tight_layout()
        plt.savefig(self.save_dir / filename, dpi=150)
        plt.close()
        self.logger.info(f"ğŸ“Š Saved: {filename}")

        # ç»˜åˆ¶ 3D è¡¨é¢å›¾
        fig_3d = plt.figure(figsize=(12, 9))
        ax_3d = fig_3d.add_subplot(111, projection="3d")

        surf = ax_3d.plot_surface(
            X, Y, loss_data, cmap="viridis", edgecolor="none", alpha=0.9
        )
        fig_3d.colorbar(surf, ax=ax_3d, shrink=0.5, aspect=10, label="Loss")

        center_loss = loss_data[steps // 2, steps // 2]
        ax_3d.scatter(
            [0], [0], [center_loss], c="red", s=200, marker="*", label=model_name
        )

        ax_3d.set_xlabel("Direction 1")
        ax_3d.set_ylabel("Direction 2")
        ax_3d.set_zlabel("Loss")
        ax_3d.set_title(f"3D Loss Landscape around {model_name}")
        ax_3d.view_init(elev=30, azim=45)
        ax_3d.legend()

        filename_3d = filename.replace(".png", "_3d.png")
        plt.tight_layout()
        plt.savefig(self.save_dir / filename_3d, dpi=150)
        plt.close()
        self.logger.info(f"ğŸ“Š Saved: {filename_3d}")

        return loss_data

    def plot_ensemble_interpolations(
        self,
        models: List[nn.Module],
        dataloader: DataLoader,
        device: torch.device,
        steps: int = 50,
        filename: str = "ensemble_loss_landscape.png",
    ) -> Dict[str, np.ndarray]:
        """ç»˜åˆ¶é›†æˆä¸­æ‰€æœ‰æ¨¡å‹å¯¹ä¹‹é—´çš„1DæŸå¤±æ’å€¼æ›²çº¿"""
        if not self._check_dependency():
            return {}

        import loss_landscapes
        import matplotlib.pyplot as plt
        from tqdm import tqdm

        n_models = len(models)
        if n_models < 2:
            self.logger.warning("âš ï¸ éœ€è¦è‡³å°‘ 2 ä¸ªæ¨¡å‹æ¥è®¡ç®—æ’å€¼")
            return {}

        self.logger.info(
            f"ğŸ“ˆ æ­£åœ¨è®¡ç®—é›†æˆæ¨¡å‹é—´çš„ Loss Landscape ({n_models} ä¸ªæ¨¡å‹)..."
        )

        results = {}
        pairs = [(i, j) for i in range(n_models) for j in range(i + 1, n_models)]

        for idx, (i, j) in enumerate(
            tqdm(pairs, desc="Computing Loss Landscape", leave=False)
        ):
            model_i = models[i].to(device)
            model_j = models[j].to(device)
            metric = self._create_metric(model_i, dataloader, device)

            loss_data = loss_landscapes.linear_interpolation(
                model_i, model_j, metric, steps=steps
            )
            results[f"M{i + 1}-M{j + 1}"] = loss_data

        # ç»˜å›¾
        fig, ax = plt.subplots(figsize=(12, 6))
        x = np.linspace(0, 1, steps)
        colors = plt.cm.tab10(np.linspace(0, 1, len(results)))

        for (pair_name, loss_data), color in zip(results.items(), colors):
            ax.plot(x, loss_data, label=pair_name, linewidth=1.5, color=color)

        ax.set_xlabel("Interpolation (Î±)")
        ax.set_ylabel("Loss")
        ax.set_title("Loss Landscape: Pairwise Model Interpolations")
        ax.legend(bbox_to_anchor=(1.05, 1), loc="upper left")
        ax.grid(True, alpha=0.3)

        plt.tight_layout()
        plt.savefig(self.save_dir / filename, dpi=150, bbox_inches="tight")
        plt.close()

        self.logger.info(f"ğŸ“Š Saved: {filename}")
        return results

    def compute_model_distances(self, models: List[nn.Module]) -> np.ndarray:
        """è®¡ç®—æ¨¡å‹é—´çš„å‚æ•°ç©ºé—´æ¬§æ°è·ç¦»"""
        n_models = len(models)
        distance_matrix = np.zeros((n_models, n_models))

        # å°†æ‰€æœ‰æ¨¡å‹å‚æ•°å±•å¹³
        flat_params = []
        for model in models:
            params = torch.cat(
                [p.data.view(-1).cpu() for p in model.parameters()]
            ).numpy()
            flat_params.append(params)

        # è®¡ç®—æˆå¯¹è·ç¦»
        for i in range(n_models):
            for j in range(i + 1, n_models):
                dist = np.linalg.norm(flat_params[i] - flat_params[j])
                distance_matrix[i, j] = dist
                distance_matrix[j, i] = dist

        return distance_matrix

    def plot_model_distance_heatmap(
        self,
        models: List[nn.Module],
        filename: str = "model_distances.png",
    ) -> np.ndarray:
        """ç»˜åˆ¶æ¨¡å‹é—´è·ç¦»çƒ­åŠ›å›¾"""
        import matplotlib.pyplot as plt

        self.logger.info("ğŸ“ˆ æ­£åœ¨è®¡ç®—æ¨¡å‹é—´å‚æ•°è·ç¦»...")

        distance_matrix = self.compute_model_distances(models)
        n_models = len(models)

        # ç»˜åˆ¶çƒ­åŠ›å›¾
        fig, ax = plt.subplots(figsize=(8, 6))
        im = ax.imshow(distance_matrix, cmap="YlOrRd")
        plt.colorbar(im, ax=ax, label="Euclidean Distance")

        # è®¾ç½®æ ‡ç­¾
        labels = [f"M{i + 1}" for i in range(n_models)]
        ax.set_xticks(range(n_models))
        ax.set_yticks(range(n_models))
        ax.set_xticklabels(labels)
        ax.set_yticklabels(labels)

        # åœ¨æ¯ä¸ªæ ¼å­ä¸­æ˜¾ç¤ºæ•°å€¼
        for i in range(n_models):
            for j in range(n_models):
                ax.text(
                    j,
                    i,
                    f"{distance_matrix[i, j]:.1f}",
                    ha="center",
                    va="center",
                    color="black"
                    if distance_matrix[i, j] < distance_matrix.max() / 2
                    else "white",
                    fontsize=8,
                )

        ax.set_title("Model Parameter Space Distances")
        plt.tight_layout()
        plt.savefig(self.save_dir / filename, dpi=150)
        plt.close()

        self.logger.info(f"ğŸ“Š Saved: {filename}")
        return distance_matrix
