"""
================================================================================
å¯¹æŠ—é²æ£’æ€§è¯„ä¼°æ¨¡å—
================================================================================

åŒ…å«: FGSM æ”»å‡»ã€PGD æ”»å‡»ã€å¯¹æŠ—é²æ£’æ€§è¯„ä¼°
"""

from typing import Dict

import torch
import torch.nn as nn
import torch.nn.functional as F

from ..utils import get_logger
from .inference import get_models_from_source

# â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
# â•‘ å¯¹æŠ—æ”»å‡»æ–¹æ³•                                                                 â•‘
# â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•


def _get_norm_params(eps, alpha, mean, std):
    """è®¡ç®—æ ‡å‡†åŒ–ç©ºé—´ä¸‹çš„æ‰°åŠ¨è¾¹ç•Œä¸è£å‰ªèŒƒå›´"""
    return (
        eps / std,
        alpha / std if alpha else None,
        (0 - mean) / std,
        (1 - mean) / std,
    )


def fgsm_attack(model, images, labels, eps, mean, std, targeted=False) -> torch.Tensor:
    """
    FGSM æ”»å‡»
    
    Args:
        targeted: è‹¥ä¸º Trueï¼Œlabels åº”ä¸ºç›®æ ‡æ ‡ç­¾ï¼Œæ‰§è¡Œé’ˆå¯¹æ€§æ”»å‡»
    """
    e_n, _, lower, upper = _get_norm_params(eps, None, mean, std)
    images = images.clone().detach().requires_grad_(True)

    loss = F.cross_entropy(model(images), labels)
    loss.backward()

    # targeted: æ¢¯åº¦ä¸‹é™é è¿‘ç›®æ ‡; untargeted: æ¢¯åº¦ä¸Šå‡è¿œç¦»çœŸå®æ ‡ç­¾
    sign = -1 if targeted else 1
    adv = images + sign * e_n * images.grad.sign()
    return torch.max(torch.min(adv, upper), lower).detach()



def pgd_attack(model, images, labels, eps, alpha, steps, mean, std, targeted=False) -> torch.Tensor:
    """
    PGD æ”»å‡»
    
    Args:
        targeted: è‹¥ä¸º Trueï¼Œlabels åº”ä¸ºç›®æ ‡æ ‡ç­¾ï¼Œæ‰§è¡Œé’ˆå¯¹æ€§æ”»å‡»
    """
    e_n, a_n, lower, upper = _get_norm_params(eps, alpha, mean, std)
    adv = (images + torch.empty_like(images).uniform_(-1, 1) * e_n).clamp(lower, upper)

    # targeted: æ¢¯åº¦ä¸‹é™é è¿‘ç›®æ ‡; untargeted: æ¢¯åº¦ä¸Šå‡è¿œç¦»çœŸå®æ ‡ç­¾
    sign = -1 if targeted else 1
    
    for _ in range(steps):
        adv.requires_grad_(True)
        loss = F.cross_entropy(model(adv), labels)
        model.zero_grad()
        loss.backward()

        # è¿­ä»£æ›´æ–°ä¸æŠ•å½±
        adv = images + (adv + sign * a_n * adv.grad.sign() - images).clamp(-e_n, e_n)
        adv = adv.clamp(lower, upper).detach()
    return adv



# â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
# â•‘ æ”»å‡»æ–¹å¼æ‰©å±• (TODO)                                                          â•‘
# â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•


def cw_attack(
    model, images, labels, c: float = 1.0, kappa: float = 0.0, 
    steps: int = 1000, lr: float = 0.01, mean=None, std=None
) -> torch.Tensor:
    """
    C&W (Carlini & Wagner) L2 æ”»å‡» - TODO
    
    åŸºäºä¼˜åŒ–çš„æ”»å‡»æ–¹æ³•ï¼Œæœ€å°åŒ– L2 æ‰°åŠ¨åŒæ—¶ä½¿æ¨¡å‹è¯¯åˆ†ç±»ã€‚
    
    å‚è€ƒè®ºæ–‡: "Towards Evaluating the Robustness of Neural Networks" (Carlini & Wagner, 2017)
    
    Args:
        model: ç›®æ ‡æ¨¡å‹
        images: è¾“å…¥å›¾åƒ [B, C, H, W]
        labels: çœŸå®æ ‡ç­¾ [B]
        c: ç½®ä¿¡åº¦æƒé‡
        kappa: ç½®ä¿¡åº¦è¾¹ç•Œ
        steps: ä¼˜åŒ–è¿­ä»£æ¬¡æ•°
        lr: å­¦ä¹ ç‡
        mean, std: æ•°æ®é›†æ ‡å‡†åŒ–å‚æ•°
    
    Returns:
        å¯¹æŠ—æ ·æœ¬ [B, C, H, W]
    """
    raise NotImplementedError("C&W æ”»å‡»å°šæœªå®ç°ï¼Œå¯ä½¿ç”¨ advertorch æˆ– foolbox åº“")


def auto_attack(
    model, images, labels, eps: float, norm: str = "Linf",
    version: str = "standard", mean=None, std=None
) -> torch.Tensor:
    """
    AutoAttack - å½“å‰æœ€å¼ºå¯¹æŠ—è¯„ä¼°åŸºå‡† - TODO
    
    ç»„åˆå¤šç§æ”»å‡»: APGD-CE, APGD-DLR, FAB, Square Attack
    
    å‚è€ƒè®ºæ–‡: "Reliable evaluation of adversarial robustness with an ensemble of diverse 
              parameter-free attacks" (Croce & Hein, 2020)
    
    Args:
        model: ç›®æ ‡æ¨¡å‹
        images: è¾“å…¥å›¾åƒ [B, C, H, W]
        labels: çœŸå®æ ‡ç­¾ [B]
        eps: æ‰°åŠ¨é¢„ç®—
        norm: èŒƒæ•°ç±»å‹ ("Linf" æˆ– "L2")
        version: ç‰ˆæœ¬ ("standard", "plus", "rand")
        mean, std: æ•°æ®é›†æ ‡å‡†åŒ–å‚æ•°
    
    Returns:
        å¯¹æŠ—æ ·æœ¬ [B, C, H, W]
    
    å®‰è£…: pip install autoattack
    """
    raise NotImplementedError("AutoAttack å°šæœªå®ç°ï¼Œè¯·å®‰è£… autoattack åº“")


# æ³¨æ„: é’ˆå¯¹æ€§æ”»å‡»å·²é€šè¿‡ fgsm_attack/pgd_attack çš„ targeted å‚æ•°æ”¯æŒ
# ç”¨æ³•: pgd_attack(model, x, target_labels, ..., targeted=True)


# â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
# â•‘ å¯¹æŠ—é²æ£’æ€§è¯„ä¼°                                                               â•‘
# â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•


def evaluate_adversarial(
    trainer_or_models, loader, 
    eps: Union[float, List[float]] = None, 
    alpha: float = None, 
    steps: int = None, 
    dataset: str = None, 
    cfg=None, 
    logger=None
) -> Dict:
    """
    é›†æˆå¯¹æŠ—é²æ£’æ€§è¯„ä¼°
    
    Args:
        trainer_or_models: Trainer å¯¹è±¡æˆ–æ¨¡å‹åˆ—è¡¨
        loader: æµ‹è¯•æ•°æ® DataLoader
        eps: æ‰°åŠ¨é¢„ç®— (å¯é€‰)ï¼Œæ”¯æŒ:
             - None: ä» cfg è‡ªåŠ¨è¯»å– (adv_eps_list æˆ– adv_eps)
             - float: å•å€¼è¯„ä¼°ï¼Œå¦‚ 8/255
             - list: å¤š Îµ è¯„ä¼°ï¼Œå¦‚ [2/255, 4/255, 8/255, 16/255]
        alpha: PGD æ­¥é•¿ (å¯é€‰ï¼ŒNone åˆ™ä» cfg è¯»å–)
        steps: PGD è¿­ä»£æ¬¡æ•° (å¯é€‰ï¼ŒNone åˆ™ä» cfg è¯»å–)
        dataset: æ•°æ®é›†åç§° (å¯é€‰ï¼ŒNone åˆ™ä» cfg è¯»å–)
        cfg: é…ç½®å¯¹è±¡
        logger: æ—¥å¿—è®°å½•å™¨
    
    Returns:
        - å• Îµ: {clean_acc, fgsm_acc, pgd_acc, ...}
        - å¤š Îµ: {eps_value: {clean_acc, fgsm_acc, pgd_acc, ...}, ...}
    """
    # 1. è‡ªåŠ¨è§£æå‚æ•° (ä¼˜å…ˆä½¿ç”¨æ˜¾å¼å‚æ•°ï¼Œå¦åˆ™ä½¿ç”¨ cfg)
    if cfg is not None:
        if eps is None:
            # ä¼˜å…ˆæ£€æŸ¥å¤š eps åˆ—è¡¨
            eps = getattr(cfg.constants, 'adv_eps_list', None)
            if eps is None:
                eps = getattr(cfg.constants, 'adv_eps', 0.03137)
        
        alpha = alpha if alpha is not None else getattr(cfg.constants, 'adv_alpha', 0.00784)
        steps = steps if steps is not None else getattr(cfg.constants, 'adv_pgd_steps', 10)
        dataset = dataset if dataset is not None else getattr(cfg.base, 'dataset_name', 'cifar10')
    else:
        # æ— é…ç½®æ—¶çš„é»˜è®¤å…œåº•
        eps = eps if eps is not None else 0.03137
        alpha = alpha if alpha is not None else 0.00784
        steps = steps if steps is not None else 10
        if dataset is None:
            raise ValueError("æœªæä¾› cfg æ—¶å¿…é¡»æ˜¾å¼æŒ‡å®š dataset åç§°")

    # 2. å¤š Îµ æ¨¡å¼: é€’å½’è°ƒç”¨è‡ªèº«
    if isinstance(eps, (list, tuple)):
        log = logger or get_logger()
        log.info(f"\nğŸ—¡ï¸ Multi-Îµ Adversarial Eval ({len(eps)} values)")
        return {
            e: evaluate_adversarial(
                trainer_or_models, loader, e, alpha, steps, dataset, cfg, logger
            ) for e in eps
        }
    
    # 3. å• Îµ æ¨¡å¼: æ ¸å¿ƒè¯„ä¼°é€»è¾‘
    return _evaluate_single_eps(
        trainer_or_models, loader, eps, alpha, steps, dataset, cfg, logger
    )


def _evaluate_single_eps(
    trainer_or_models, loader, eps: float, alpha, steps, dataset, cfg, logger
) -> Dict:
    """å• Îµ å¯¹æŠ—è¯„ä¼°æ ¸å¿ƒé€»è¾‘"""
    from tqdm import tqdm
    from .strategies import get_ensemble_fn

    log = logger or get_logger()
    log.info(f"\nğŸ—¡ï¸ Adversarial Eval (Îµ={eps * 255:.1f}/255, Steps={steps})")

    models, device = get_models_from_source(trainer_or_models)
    mean, std = _get_dataset_norm(dataset, device)

    # å»ºç«‹é›†æˆæ”»å‡»å¤–å£³ï¼ˆä½¿ç”¨é…ç½®çš„é›†æˆç­–ç•¥ï¼‰
    ensemble_fn = get_ensemble_fn(cfg) if cfg else None
    ens_model = _EnsembleProxy(models, ensemble_fn).to(device).eval()
    stats = {"total": 0, "clean": 0, "fgsm": 0, "pgd": 0}
    
    # ä»é…ç½®è¯»å–é’ˆå¯¹æ€§æ”»å‡»å¼€å…³
    targeted = getattr(cfg.constants, 'adv_targeted', False) if cfg else False

    pbar = tqdm(loader, desc=f"Adv Îµ={eps*255:.0f}", leave=False)
    for x, y in pbar:
        x, y = x.to(device), y.to(device)
        stats["total"] += x.size(0)

        # 1. å¹²å‡€ç²¾åº¦
        with torch.no_grad():
            stats["clean"] += (ens_model(x).argmax(1) == y).sum().item()

        # 2. é’ˆå¯¹æ€§æ”»å‡»: ç”Ÿæˆç›®æ ‡æ ‡ç­¾ (éšæœºé€‰æ‹©éçœŸå®ç±»åˆ«)
        if targeted:
            num_classes = ens_model(x[:1]).shape[-1]  # è·å–ç±»åˆ«æ•°
            attack_labels = _generate_target_labels(y, num_classes, device)
        else:
            attack_labels = y

        # 3. å¯¹æŠ—æ”»å‡» (FGSM/PGD)
        stats["fgsm"] += _run_and_eval_attack(
            ens_model, fgsm_attack, x, attack_labels, eps, mean, std, targeted
        )
        stats["pgd"] += _run_and_eval_attack(
            ens_model, pgd_attack, x, attack_labels, eps, alpha, steps, mean, std, targeted
        )

        pbar.set_postfix(
            {
                k: f"{100 * v / stats['total']:.1f}%"
                for k, v in stats.items()
                if k != "total"
            }
        )

    return _summarize_adv_results(stats, eps, alpha, steps, log)


class _EnsembleProxy(nn.Module):
    def __init__(self, models, ensemble_fn=None):
        super().__init__()
        self.models = nn.ModuleList(models)
        self._ensemble_fn = ensemble_fn or (lambda x: x.mean(0))

    def forward(self, x):
        stacked = torch.stack([m(x) for m in self.models])
        return self._ensemble_fn(stacked)


def _get_dataset_norm(name, device):
    from ..datasets import DATASET_REGISTRY

    cls = DATASET_REGISTRY.get(name.lower())
    if cls is None:
        raise ValueError(
            f"ä¸æ”¯æŒçš„æ•°æ®é›†: {name}. å¯ç”¨: {list(DATASET_REGISTRY.keys())}"
        )
    return torch.tensor(cls.MEAN).view(1, 3, 1, 1).to(device), torch.tensor(
        cls.STD
    ).view(1, 3, 1, 1).to(device)


def _generate_target_labels(true_labels: torch.Tensor, num_classes: int, device) -> torch.Tensor:
    """
    ç”Ÿæˆé’ˆå¯¹æ€§æ”»å‡»çš„ç›®æ ‡æ ‡ç­¾
    
    éšæœºé€‰æ‹©ä¸€ä¸ªä¸åŒäºçœŸå®æ ‡ç­¾çš„ç±»åˆ«ä½œä¸ºæ”»å‡»ç›®æ ‡ã€‚
    
    Args:
        true_labels: çœŸå®æ ‡ç­¾ [B]
        num_classes: ç±»åˆ«æ€»æ•°
        device: è®¾å¤‡
    
    Returns:
        ç›®æ ‡æ ‡ç­¾ [B]ï¼Œä¿è¯æ¯ä¸ªæ ·æœ¬çš„ç›®æ ‡ç±»åˆ« â‰  çœŸå®ç±»åˆ«
    """
    # ç”Ÿæˆ [1, num_classes-1] çš„éšæœºåç§»
    offsets = torch.randint(1, num_classes, true_labels.shape, device=device)
    # ç›®æ ‡ = (çœŸå® + åç§») % ç±»åˆ«æ•°ï¼Œä¿è¯ä¸ç­‰äºçœŸå®æ ‡ç­¾
    target_labels = (true_labels + offsets) % num_classes
    return target_labels


def _run_and_eval_attack(model, attack_fn, x, y, *args):
    """å°è£… æ”»å‡» -> æ¨ç† -> è®¡æ•° é€»è¾‘"""
    prev_training = model.training
    model.train()  # ç¡®ä¿å…è®¸æ¢¯åº¦è®¡ç®—
    for m in model.models:
        m.eval()  # BN ç»´æŒ eval

    adv_x = attack_fn(model, x, y, *args)

    model.train(prev_training)
    with torch.no_grad():
        return (model(adv_x).argmax(1) == y).sum().item()


def _summarize_adv_results(s, eps, alpha, steps, log):
    t = s["total"]
    res = {
        "clean_acc": 100 * s["clean"] / t,
        "fgsm_acc": 100 * s["fgsm"] / t,
        "pgd_acc": 100 * s["pgd"] / t,
        "eps": eps,
        "eps_255": eps * 255,
        "alpha": alpha,
        "pgd_steps": steps,
        "num_samples": t,
    }
    log.info(
        f"   âœ… Clean: {res['clean_acc']:.2f}% | FGSM: {res['fgsm_acc']:.2f}% | PGD-{steps}: {res['pgd_acc']:.2f}%"
    )
    return res
