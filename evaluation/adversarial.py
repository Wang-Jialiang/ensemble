"""
================================================================================
å¯¹æŠ—é²æ£’æ€§è¯„ä¼°æ¨¡å—
================================================================================

åŒ…å«: _fgsm_attack, _pgd_attack (å†…éƒ¨), evaluate_adversarial
"""

from typing import Dict, List, Union

import torch
import torch.nn as nn
import torch.nn.functional as F

from ..utils import get_logger
from .inference import get_models_from_source

# â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
# â•‘ å¯¹æŠ—æ”»å‡»æ–¹æ³•                                                                 â•‘
# â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•


def _get_norm_params(eps, alpha, mean, std):
    """è®¡ç®—æ ‡å‡†åŒ–ç©ºé—´ä¸‹çš„æ‰°åŠ¨è¾¹ç•Œä¸è£å‰ªèŒƒå›´"""
    return (
        eps / std,
        alpha / std if alpha else None,
        (0 - mean) / std,
        (1 - mean) / std,
    )


def _fgsm_attack(model, images, labels, eps, mean, std, targeted=False) -> torch.Tensor:
    """
    FGSM æ”»å‡»

    Args:
        targeted: è‹¥ä¸º Trueï¼Œlabels åº”ä¸ºç›®æ ‡æ ‡ç­¾ï¼Œæ‰§è¡Œé’ˆå¯¹æ€§æ”»å‡»
    """
    e_n, _, lower, upper = _get_norm_params(eps, None, mean, std)
    images = images.clone().detach().requires_grad_(True)

    loss = F.cross_entropy(model(images), labels)
    loss.backward()

    # targeted: æ¢¯åº¦ä¸‹é™é è¿‘ç›®æ ‡; untargeted: æ¢¯åº¦ä¸Šå‡è¿œç¦»çœŸå®æ ‡ç­¾
    sign = -1 if targeted else 1
    adv = images + sign * e_n * images.grad.sign()
    return torch.max(torch.min(adv, upper), lower).detach()


def _pgd_attack(
    model, images, labels, eps, alpha, steps, mean, std, targeted=False
) -> torch.Tensor:
    """
    PGD æ”»å‡»

    Args:
        targeted: è‹¥ä¸º Trueï¼Œlabels åº”ä¸ºç›®æ ‡æ ‡ç­¾ï¼Œæ‰§è¡Œé’ˆå¯¹æ€§æ”»å‡»
    """
    e_n, a_n, lower, upper = _get_norm_params(eps, alpha, mean, std)
    adv = (images + torch.empty_like(images).uniform_(-1, 1) * e_n).clamp(lower, upper)

    # targeted: æ¢¯åº¦ä¸‹é™é è¿‘ç›®æ ‡; untargeted: æ¢¯åº¦ä¸Šå‡è¿œç¦»çœŸå®æ ‡ç­¾
    sign = -1 if targeted else 1

    for _ in range(steps):
        adv.requires_grad_(True)
        loss = F.cross_entropy(model(adv), labels)
        model.zero_grad()
        loss.backward()

        # è¿­ä»£æ›´æ–°ä¸æŠ•å½±
        adv = images + (adv + sign * a_n * adv.grad.sign() - images).clamp(-e_n, e_n)
        adv = adv.clamp(lower, upper).detach()
    return adv


# â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
# â•‘ æ”»å‡»æ–¹å¼æ‰©å±• (TODO)                                                          â•‘
# â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•


def cw_attack(
    model,
    images,
    labels,
    c: float = 1.0,
    kappa: float = 0.0,
    steps: int = 1000,
    lr: float = 0.01,
    mean=None,
    std=None,
) -> torch.Tensor:
    """
    C&W (Carlini & Wagner) L2 æ”»å‡» - TODO

    åŸºäºä¼˜åŒ–çš„æ”»å‡»æ–¹æ³•ï¼Œæœ€å°åŒ– L2 æ‰°åŠ¨åŒæ—¶ä½¿æ¨¡å‹è¯¯åˆ†ç±»ã€‚

    å‚è€ƒè®ºæ–‡: "Towards Evaluating the Robustness of Neural Networks" (Carlini & Wagner, 2017)

    Args:
        model: ç›®æ ‡æ¨¡å‹
        images: è¾“å…¥å›¾åƒ [B, C, H, W]
        labels: çœŸå®æ ‡ç­¾ [B]
        c: ç½®ä¿¡åº¦æƒé‡
        kappa: ç½®ä¿¡åº¦è¾¹ç•Œ
        steps: ä¼˜åŒ–è¿­ä»£æ¬¡æ•°
        lr: å­¦ä¹ ç‡
        mean, std: æ•°æ®é›†æ ‡å‡†åŒ–å‚æ•°

    Returns:
        å¯¹æŠ—æ ·æœ¬ [B, C, H, W]
    """
    raise NotImplementedError("C&W æ”»å‡»å°šæœªå®ç°ï¼Œå¯ä½¿ç”¨ advertorch æˆ– foolbox åº“")


def auto_attack(
    model,
    images,
    labels,
    eps: float,
    norm: str = "Linf",
    version: str = "standard",
    mean=None,
    std=None,
) -> torch.Tensor:
    """
    AutoAttack - å½“å‰æœ€å¼ºå¯¹æŠ—è¯„ä¼°åŸºå‡† - TODO

    ç»„åˆå¤šç§æ”»å‡»: APGD-CE, APGD-DLR, FAB, Square Attack

    å‚è€ƒè®ºæ–‡: "Reliable evaluation of adversarial robustness with an ensemble of diverse
              parameter-free attacks" (Croce & Hein, 2020)

    Args:
        model: ç›®æ ‡æ¨¡å‹
        images: è¾“å…¥å›¾åƒ [B, C, H, W]
        labels: çœŸå®æ ‡ç­¾ [B]
        eps: æ‰°åŠ¨é¢„ç®—
        norm: èŒƒæ•°ç±»å‹ ("Linf" æˆ– "L2")
        version: ç‰ˆæœ¬ ("standard", "plus", "rand")
        mean, std: æ•°æ®é›†æ ‡å‡†åŒ–å‚æ•°

    Returns:
        å¯¹æŠ—æ ·æœ¬ [B, C, H, W]

    å®‰è£…: pip install autoattack
    """
    raise NotImplementedError("AutoAttack å°šæœªå®ç°ï¼Œè¯·å®‰è£… autoattack åº“")


# æ³¨æ„: é’ˆå¯¹æ€§æ”»å‡»å·²é€šè¿‡ fgsm_attack/pgd_attack çš„ targeted å‚æ•°æ”¯æŒ
# ç”¨æ³•: pgd_attack(model, x, target_labels, ..., targeted=True)


# â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
# â•‘ å¯¹æŠ—é²æ£’æ€§è¯„ä¼°                                                               â•‘
# â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•


def evaluate_adversarial(
    trainer_or_models,
    loader,
    eps: Union[float, List[float]] = None,
    alpha: float = None,
    steps: int = None,
    dataset: str = None,
    cfg=None,
    logger=None,
) -> Dict:
    """
    é›†æˆå¯¹æŠ—é²æ£’æ€§è¯„ä¼°

    Args:
        trainer_or_models: Trainer å¯¹è±¡æˆ–æ¨¡å‹åˆ—è¡¨
        loader: æµ‹è¯•æ•°æ® DataLoader
        eps: æ‰°åŠ¨é¢„ç®— (å¯é€‰)ï¼Œæ”¯æŒ:
             - None: ä» cfg è‡ªåŠ¨è¯»å– (adv_eps_list æˆ– adv_eps)
             - float: å•å€¼è¯„ä¼°ï¼Œå¦‚ 8/255
             - list: å¤š Îµ è¯„ä¼°ï¼Œå¦‚ [2/255, 4/255, 8/255, 16/255]
        alpha: PGD æ­¥é•¿ (å¯é€‰ï¼ŒNone åˆ™ä» cfg è¯»å–)
        steps: PGD è¿­ä»£æ¬¡æ•° (å¯é€‰ï¼ŒNone åˆ™ä» cfg è¯»å–)
        dataset: æ•°æ®é›†åç§° (å¯é€‰ï¼ŒNone åˆ™ä» cfg è¯»å–)
        cfg: é…ç½®å¯¹è±¡
        logger: æ—¥å¿—è®°å½•å™¨

    Returns:
        - å• Îµ: {clean_acc, fgsm_acc, pgd_acc, ...}
        - å¤š Îµ: {eps_value: {clean_acc, fgsm_acc, pgd_acc, ...}, ...}
    """
    # 1. è‡ªåŠ¨è§£æå‚æ•° (ä¼˜å…ˆä½¿ç”¨æ˜¾å¼å‚æ•°ï¼Œå¦åˆ™ä½¿ç”¨ cfg)
    if cfg is not None:
        if eps is None:
            # ä¼˜å…ˆæ£€æŸ¥å¤š eps åˆ—è¡¨
            eps = getattr(cfg, "adv_eps_list", None)
            if eps is None:
                eps = getattr(cfg, "adv_eps", 0.03137)

        alpha = alpha if alpha is not None else getattr(cfg, "adv_alpha", 0.00784)
        steps = steps if steps is not None else getattr(cfg, "adv_pgd_steps", 10)
        dataset = (
            dataset if dataset is not None else getattr(cfg, "dataset_name", "cifar10")
        )
    else:
        if dataset is None:
            raise ValueError("æœªæä¾› cfg æ—¶å¿…é¡»æ˜¾å¼æŒ‡å®š dataset åç§°")

    # 2. å¤š Îµ æ¨¡å¼: é€’å½’è°ƒç”¨è‡ªèº«
    if isinstance(eps, (list, tuple)):
        log = logger or get_logger()
        log.info(f"\nğŸ—¡ï¸ Multi-Îµ Adversarial Eval ({len(eps)} values)")
        return {
            e: evaluate_adversarial(
                trainer_or_models, loader, e, alpha, steps, dataset, cfg, logger
            )
            for e in eps
        }

    # 3. å• Îµ æ¨¡å¼: æ ¸å¿ƒè¯„ä¼°é€»è¾‘
    return _evaluate_single_eps(
        trainer_or_models, loader, eps, alpha, steps, dataset, cfg, logger
    )


def _evaluate_single_eps(
    trainer_or_models, loader, eps: float, alpha, steps, dataset, cfg, logger
) -> Dict:
    """å• Îµ å¯¹æŠ—è¯„ä¼°æ ¸å¿ƒé€»è¾‘"""
    from tqdm import tqdm

    from .strategies import get_ensemble_fn

    log = logger or get_logger()
    log.info("ğŸ—¡ï¸ Adversarial Eval")

    models, device = get_models_from_source(trainer_or_models)
    mean, std = _get_dataset_norm(dataset, device)

    # å»ºç«‹é›†æˆæ”»å‡»å¤–å£³ï¼ˆä½¿ç”¨é…ç½®çš„é›†æˆç­–ç•¥ï¼‰
    ensemble_fn = get_ensemble_fn(cfg) if cfg else None
    # æ³¨æ„: ä¸å†å¼ºåˆ¶ .to(device)ï¼Œå› ä¸º models å¯èƒ½åˆ†å¸ƒåœ¨ä¸åŒ GPU ä¸Š
    # _EnsembleProxy ä¼šè‡ªåŠ¨å¤„ç†è·¨è®¾å¤‡ forward
    ens_model = _EnsembleProxy(models, ensemble_fn).eval()
    stats = {"total": 0, "clean": 0, "fgsm": 0, "pgd": 0}

    # ä»é…ç½®è¯»å–é’ˆå¯¹æ€§æ”»å‡»å¼€å…³
    targeted = getattr(cfg, "adv_targeted", False) if cfg else False

    pbar = tqdm(loader, desc=f"Adv Îµ={eps * 255:.0f}", leave=False)
    for x, y in pbar:
        x, y = x.to(device), y.to(device)
        stats["total"] += x.size(0)

        # 1. å¹²å‡€ç²¾åº¦
        with torch.no_grad():
            stats["clean"] += (ens_model(x).argmax(1) == y).sum().item()

        # 2. é’ˆå¯¹æ€§æ”»å‡»: ç”Ÿæˆç›®æ ‡æ ‡ç­¾ (éšæœºé€‰æ‹©éçœŸå®ç±»åˆ«)
        if targeted:
            num_classes = ens_model(x[:1]).shape[-1]  # è·å–ç±»åˆ«æ•°
            attack_labels = _generate_target_labels(y, num_classes, device)
        else:
            attack_labels = y

        # 3. å¯¹æŠ—æ”»å‡» (FGSM/PGD)
        # æ³¨æ„: å§‹ç»ˆä¼ å…¥åŸå§‹çœŸå®æ ‡ç­¾ y ç”¨äºè¯„ä¼°æ˜¯å¦è¢«æ”»å‡»æˆåŠŸ
        stats["fgsm"] += _run_and_eval_attack(
            ens_model, _fgsm_attack, x, attack_labels, y, eps, mean, std, targeted
        )
        stats["pgd"] += _run_and_eval_attack(
            ens_model,
            _pgd_attack,
            x,
            attack_labels,
            y,
            eps,
            alpha,
            steps,
            mean,
            std,
            targeted,
        )

        pbar.set_postfix(
            {
                k: f"{100 * v / stats['total']:.1f}%"
                for k, v in stats.items()
                if k != "total"
            }
        )

    return _summarize_adv_results(stats, eps, alpha, steps, log)


class _EnsembleProxy(nn.Module):
    def __init__(self, models, ensemble_fn=None):
        super().__init__()
        self.models = nn.ModuleList(models)
        self._ensemble_fn = ensemble_fn or (lambda x: x.mean(0))

    def forward(self, x):
        outputs = []
        # è®°å½•è¾“å…¥è®¾å¤‡ï¼Œæœ€ç»ˆç»“æœéœ€è¦å›åˆ°è¿™é‡Œ
        input_device = x.device

        for m in self.models:
            # 1. ç¡®å®šæ¨¡å‹æ‰€åœ¨è®¾å¤‡
            try:
                model_device = next(m.parameters()).device
            except StopIteration:
                model_device = input_device  # å‡å®šåŒè®¾å¤‡

            # 2. å°†è¾“å…¥ç§»åˆ°æ¨¡å‹è®¾å¤‡ (å¦‚æœä¸åŒ)
            if model_device != input_device:
                x_in = x.to(model_device)
            else:
                x_in = x

            # 3. æ¨ç†
            out = m(x_in)

            # 4. å°†è¾“å‡ºç§»å›è¾“å…¥è®¾å¤‡
            if out.device != input_device:
                out = out.to(input_device)

            outputs.append(out)

        stacked = torch.stack(outputs)
        return self._ensemble_fn(stacked)


def _get_dataset_norm(name, device):
    from ..datasets import DATASET_REGISTRY

    cls = DATASET_REGISTRY.get(name.lower())
    if cls is None:
        raise ValueError(
            f"ä¸æ”¯æŒçš„æ•°æ®é›†: {name}. å¯ç”¨: {list(DATASET_REGISTRY.keys())}"
        )
    # åŠ¨æ€è·å–é€šé“æ•°ï¼Œæ”¯æŒç°åº¦å›¾åƒç­‰é RGB æ•°æ®é›†
    num_channels = len(cls.MEAN)
    return (
        torch.tensor(cls.MEAN).view(1, num_channels, 1, 1).to(device),
        torch.tensor(cls.STD).view(1, num_channels, 1, 1).to(device),
    )


def _generate_target_labels(
    true_labels: torch.Tensor, num_classes: int, device
) -> torch.Tensor:
    """
    ç”Ÿæˆé’ˆå¯¹æ€§æ”»å‡»çš„ç›®æ ‡æ ‡ç­¾

    éšæœºé€‰æ‹©ä¸€ä¸ªä¸åŒäºçœŸå®æ ‡ç­¾çš„ç±»åˆ«ä½œä¸ºæ”»å‡»ç›®æ ‡ã€‚

    Args:
        true_labels: çœŸå®æ ‡ç­¾ [B]
        num_classes: ç±»åˆ«æ€»æ•°
        device: è®¾å¤‡

    Returns:
        ç›®æ ‡æ ‡ç­¾ [B]ï¼Œä¿è¯æ¯ä¸ªæ ·æœ¬çš„ç›®æ ‡ç±»åˆ« â‰  çœŸå®ç±»åˆ«
    """
    # ç”Ÿæˆ [1, num_classes-1] çš„éšæœºåç§»
    offsets = torch.randint(1, num_classes, true_labels.shape, device=device)
    # ç›®æ ‡ = (çœŸå® + åç§») % ç±»åˆ«æ•°ï¼Œä¿è¯ä¸ç­‰äºçœŸå®æ ‡ç­¾
    target_labels = (true_labels + offsets) % num_classes
    return target_labels


def _run_and_eval_attack(model, attack_fn, x, attack_labels, true_y, *args):
    """å°è£… æ”»å‡» -> æ¨ç† -> è®¡æ•° é€»è¾‘

    Args:
        model: é›†æˆæ¨¡å‹
        attack_fn: æ”»å‡»å‡½æ•° (FGSM æˆ– PGD)
        x: è¾“å…¥å›¾åƒ
        attack_labels: ç”¨äºç”Ÿæˆå¯¹æŠ—æ ·æœ¬çš„æ ‡ç­¾ (éé’ˆå¯¹æ€§æ”»å‡»æ—¶=true_yï¼Œé’ˆå¯¹æ€§æ”»å‡»æ—¶=ç›®æ ‡æ ‡ç­¾)
        true_y: åŸå§‹çœŸå®æ ‡ç­¾ï¼Œç”¨äºè¯„ä¼°æ”»å‡»åçš„æ­£ç¡®ç‡
        *args: æ”»å‡»å‡½æ•°çš„å…¶ä»–å‚æ•°
    """
    adv_x = attack_fn(model, x, attack_labels, *args)
    with torch.no_grad():
        return (model(adv_x).argmax(1) == true_y).sum().item()


def _summarize_adv_results(s, eps, alpha, steps, log):
    t = s["total"]
    res = {
        "clean_acc": 100 * s["clean"] / t,
        "fgsm_acc": 100 * s["fgsm"] / t,
        "pgd_acc": 100 * s["pgd"] / t,
    }
    log.info(
        f"  Îµ={eps * 255:.0f}/255 | Clean: {res['clean_acc']:.2f}% | "
        f"FGSM: {res['fgsm_acc']:.2f}% | PGD: {res['pgd_acc']:.2f}%"
    )
    return res
