"""
================================================================================
å¯¹æŠ—é²æ£’æ€§è¯„ä¼°æ¨¡å—
================================================================================

åŒ…å«: FGSM æ”»å‡»ã€PGD æ”»å‡»ã€å¯¹æŠ—é²æ£’æ€§è¯„ä¼°
"""

from typing import Any, Dict, Optional

import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.utils.data import DataLoader

from ..utils import get_logger
from .core import extract_models

# â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
# â•‘ å¯¹æŠ—æ”»å‡»æ–¹æ³•                                                                 â•‘
# â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•


def fgsm_attack(
    model: nn.Module,
    images: torch.Tensor,
    labels: torch.Tensor,
    eps: float,
    mean: torch.Tensor,
    std: torch.Tensor,
) -> torch.Tensor:
    """FGSM (Fast Gradient Sign Method) å¯¹æŠ—æ”»å‡»

    å•æ­¥æ”»å‡»ï¼Œæ²¿æŸå¤±æ¢¯åº¦ç¬¦å·æ–¹å‘æ·»åŠ æ‰°åŠ¨ã€‚

    Args:
        model: ç›®æ ‡æ¨¡å‹
        images: è¾“å…¥å›¾åƒ (å·²æ ‡å‡†åŒ–)
        labels: çœŸå®æ ‡ç­¾
        eps: æ‰°åŠ¨å¼ºåº¦ Îµ (åœ¨åŸå§‹åƒç´ ç©ºé—´, å¦‚ 8/255)
        mean: æ ‡å‡†åŒ–å‡å€¼
        std: æ ‡å‡†åŒ–æ ‡å‡†å·®

    Returns:
        å¯¹æŠ—æ ·æœ¬ (å·²æ ‡å‡†åŒ–)
    """
    images = images.clone().detach().requires_grad_(True)
    outputs = model(images)
    loss = F.cross_entropy(outputs, labels)
    loss.backward()

    # åœ¨åŸå§‹åƒç´ ç©ºé—´è®¡ç®—æ‰°åŠ¨ï¼Œç„¶åè½¬æ¢å›æ ‡å‡†åŒ–ç©ºé—´
    eps_normalized = eps / std

    perturbation = eps_normalized * images.grad.sign()
    adv_images = images + perturbation

    # è£å‰ªåˆ°æœ‰æ•ˆèŒƒå›´
    lower_bound = (0 - mean) / std
    upper_bound = (1 - mean) / std
    adv_images = torch.max(torch.min(adv_images, upper_bound), lower_bound)

    return adv_images.detach()


def pgd_attack(
    model: nn.Module,
    images: torch.Tensor,
    labels: torch.Tensor,
    eps: float,
    alpha: float,
    steps: int,
    mean: torch.Tensor,
    std: torch.Tensor,
) -> torch.Tensor:
    """PGD (Projected Gradient Descent) å¯¹æŠ—æ”»å‡»

    å¤šæ­¥è¿­ä»£æ”»å‡»ï¼Œæ˜¯ FGSM çš„å¢å¼ºç‰ˆã€‚

    Args:
        model: ç›®æ ‡æ¨¡å‹
        images: è¾“å…¥å›¾åƒ (å·²æ ‡å‡†åŒ–)
        labels: çœŸå®æ ‡ç­¾
        eps: æœ€å¤§æ‰°åŠ¨å¼ºåº¦ Îµ (åœ¨åŸå§‹åƒç´ ç©ºé—´)
        alpha: æ¯æ­¥æ‰°åŠ¨å¤§å° Î± (åœ¨åŸå§‹åƒç´ ç©ºé—´)
        steps: è¿­ä»£æ­¥æ•°
        mean: æ ‡å‡†åŒ–å‡å€¼
        std: æ ‡å‡†åŒ–æ ‡å‡†å·®

    Returns:
        å¯¹æŠ—æ ·æœ¬ (å·²æ ‡å‡†åŒ–)
    """
    # è½¬æ¢åˆ°æ ‡å‡†åŒ–ç©ºé—´
    eps_normalized = eps / std
    alpha_normalized = alpha / std

    # æœ‰æ•ˆèŒƒå›´
    lower_bound = (0 - mean) / std
    upper_bound = (1 - mean) / std

    # éšæœºåˆå§‹åŒ–æ‰°åŠ¨
    adv_images = images.clone().detach()
    random_noise = torch.empty_like(adv_images).uniform_(-1, 1) * eps_normalized
    adv_images = adv_images + random_noise
    adv_images = torch.max(torch.min(adv_images, upper_bound), lower_bound)

    for _ in range(steps):
        adv_images.requires_grad_(True)
        outputs = model(adv_images)
        loss = F.cross_entropy(outputs, labels)

        model.zero_grad()
        loss.backward()

        # æ²¿æ¢¯åº¦æ–¹å‘æ›´æ–°
        grad_sign = adv_images.grad.sign()
        adv_images = adv_images.detach() + alpha_normalized * grad_sign

        # æŠ•å½±åˆ° Îµ-çƒå†…
        delta = adv_images - images
        delta = torch.max(torch.min(delta, eps_normalized), -eps_normalized)
        adv_images = images + delta

        # è£å‰ªåˆ°æœ‰æ•ˆèŒƒå›´
        adv_images = torch.max(torch.min(adv_images, upper_bound), lower_bound)

    return adv_images.detach()


# â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
# â•‘ å¯¹æŠ—é²æ£’æ€§è¯„ä¼°                                                               â•‘
# â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•


def evaluate_adversarial(
    trainer_or_models: Any,
    test_loader: DataLoader,
    eps: float = 8 / 255,
    alpha: float = 2 / 255,
    pgd_steps: int = 10,
    dataset_name: str = "cifar10",
    logger: Optional[Any] = None,
) -> Dict[str, Any]:
    """å¯¹æŠ—é²æ£’æ€§è¯„ä¼° (FGSM/PGD å®æ—¶æ”»å‡»)

    ä½¿ç”¨ FGSM å’Œ PGD æ”»å‡»è¯„ä¼°é›†æˆæ¨¡å‹çš„å¯¹æŠ—é²æ£’æ€§ã€‚
    æ”»å‡»é’ˆå¯¹é›†æˆæ¨¡å‹çš„å¹³å‡ logits è¿›è¡Œã€‚

    Args:
        trainer_or_models: StagedEnsembleTrainer å®ä¾‹æˆ– List[nn.Module]
        test_loader: æµ‹è¯•æ•°æ®åŠ è½½å™¨
        eps: æ‰°åŠ¨å¼ºåº¦ Îµ (é»˜è®¤ 8/255 â‰ˆ 0.031)
        alpha: PGD æ­¥é•¿ Î± (é»˜è®¤ 2/255 â‰ˆ 0.008)
        pgd_steps: PGD è¿­ä»£æ­¥æ•° (é»˜è®¤ 10)
        dataset_name: æ•°æ®é›†åç§° (ç”¨äºè·å–æ ‡å‡†åŒ–å‚æ•°)
        logger: æ—¥å¿—è®°å½•å™¨

    Returns:
        åŒ…å«å¯¹æŠ—é²æ£’æ€§æŒ‡æ ‡çš„å­—å…¸
    """
    from tqdm import tqdm

    from ..datasets import DATASET_REGISTRY

    logger = logger or get_logger()
    logger.info("\nğŸ—¡ï¸ Running Adversarial Robustness Evaluation")
    logger.info(f"   Îµ = {eps:.4f} ({eps * 255:.1f}/255)")
    logger.info(f"   PGD: Î± = {alpha:.4f}, steps = {pgd_steps}")

    models, device = extract_models(trainer_or_models)

    # è·å–æ•°æ®é›†çš„æ ‡å‡†åŒ–å‚æ•°
    if dataset_name.lower() in DATASET_REGISTRY:
        DatasetClass = DATASET_REGISTRY[dataset_name.lower()]
        mean = torch.tensor(DatasetClass.MEAN).view(1, 3, 1, 1).to(device)
        std = torch.tensor(DatasetClass.STD).view(1, 3, 1, 1).to(device)
    else:
        # é»˜è®¤ä½¿ç”¨ ImageNet æ ‡å‡†åŒ–å‚æ•°
        mean = torch.tensor([0.485, 0.456, 0.406]).view(1, 3, 1, 1).to(device)
        std = torch.tensor([0.229, 0.224, 0.225]).view(1, 3, 1, 1).to(device)

    # åˆ›å»ºä¸€ä¸ªåŒ…è£…æ¨¡å‹ï¼Œè¾“å‡ºé›†æˆçš„å¹³å‡ logits
    class EnsembleWrapper(nn.Module):
        def __init__(self, models_list):
            super().__init__()
            self.models = nn.ModuleList(models_list)

        def forward(self, x):
            logits_list = [m(x) for m in self.models]
            return torch.stack(logits_list).mean(dim=0)

    ensemble_model = EnsembleWrapper(models).to(device)
    ensemble_model.eval()

    # ç»Ÿè®¡å˜é‡
    clean_correct = 0
    fgsm_correct = 0
    pgd_correct = 0
    total = 0

    pbar = tqdm(test_loader, desc="Adversarial Eval", leave=False)

    for images, labels in pbar:
        images, labels = images.to(device), labels.to(device)
        batch_size = images.size(0)
        total += batch_size

        # å¹²å‡€æ ·æœ¬é¢„æµ‹
        with torch.no_grad():
            clean_outputs = ensemble_model(images)
            clean_preds = clean_outputs.argmax(dim=1)
            clean_correct += (clean_preds == labels).sum().item()

        # FGSM æ”»å‡»
        ensemble_model.train()  # éœ€è¦æ¢¯åº¦
        for m in ensemble_model.models:
            m.eval()  # ä½† BN ä¿æŒ eval æ¨¡å¼

        fgsm_images = fgsm_attack(ensemble_model, images, labels, eps, mean, std)

        with torch.no_grad():
            fgsm_outputs = ensemble_model(fgsm_images)
            fgsm_preds = fgsm_outputs.argmax(dim=1)
            fgsm_correct += (fgsm_preds == labels).sum().item()

        # PGD æ”»å‡»
        pgd_images = pgd_attack(
            ensemble_model, images, labels, eps, alpha, pgd_steps, mean, std
        )

        with torch.no_grad():
            pgd_outputs = ensemble_model(pgd_images)
            pgd_preds = pgd_outputs.argmax(dim=1)
            pgd_correct += (pgd_preds == labels).sum().item()

        # æ›´æ–°è¿›åº¦æ¡
        pbar.set_postfix(
            {
                "clean": f"{100 * clean_correct / total:.1f}%",
                "fgsm": f"{100 * fgsm_correct / total:.1f}%",
                "pgd": f"{100 * pgd_correct / total:.1f}%",
            }
        )

    # æ¢å¤ eval æ¨¡å¼
    ensemble_model.eval()

    # è®¡ç®—æŒ‡æ ‡
    clean_acc = 100.0 * clean_correct / total
    fgsm_acc = 100.0 * fgsm_correct / total
    pgd_acc = 100.0 * pgd_correct / total

    results = {
        "clean_acc": clean_acc,
        "fgsm_acc": fgsm_acc,
        "pgd_acc": pgd_acc,
        "fgsm_attack_success_rate": 100.0 - fgsm_acc,
        "pgd_attack_success_rate": 100.0 - pgd_acc,
        "fgsm_robustness_drop": clean_acc - fgsm_acc,
        "pgd_robustness_drop": clean_acc - pgd_acc,
        "eps": eps,
        "eps_255": eps * 255,
        "alpha": alpha,
        "pgd_steps": pgd_steps,
        "num_samples": total,
    }

    logger.info("   âœ… Adversarial Robustness Results:")
    logger.info(f"      Clean Accuracy: {clean_acc:.2f}%")
    logger.info(f"      FGSM Accuracy (Îµ={eps * 255:.0f}/255): {fgsm_acc:.2f}%")
    logger.info(
        f"      PGD-{pgd_steps} Accuracy (Îµ={eps * 255:.0f}/255): {pgd_acc:.2f}%"
    )
    logger.info(f"      FGSM Robustness Drop: {clean_acc - fgsm_acc:.2f}%")
    logger.info(f"      PGD Robustness Drop: {clean_acc - pgd_acc:.2f}%")

    return results
