"""
================================================================================
OOD (Out-of-Distribution) æ£€æµ‹è¯„ä¼°æ¨¡å—
================================================================================

æ”¯æŒçš„ OOD æ£€æµ‹æ–¹æ³•:
- MSP (Maximum Softmax Probability): åŸºçº¿æ–¹æ³•
- Energy Score: Liu et al., NeurIPS 2020
- Mahalanobis Distance: Lee et al., NeurIPS 2018 (æŽ¨èç”¨äºŽ Near-OOD)
"""

from typing import Dict, List, Tuple

import numpy as np
import torch
import torch.nn as nn
import torch.nn.functional as F
from sklearn.metrics import roc_auc_score

from ..utils import get_logger
from .inference import (
    _FeatureExtractor,
    get_all_models_logits,
    get_models_from_source,
)

# â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
# â•‘ OOD åˆ†æ•°è®¡ç®—æ–¹æ³•                                                              â•‘
# â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•


def _compute_msp_scores(logits: torch.Tensor) -> np.ndarray:
    """è®¡ç®— MSP (Maximum Softmax Probability) åˆ†æ•°

    Args:
        logits: [N, C] æˆ– [M, N, C] (ensemble å¹³å‡åŽä¸º [N, C])

    Returns:
        msp: [N] æ¯ä¸ªæ ·æœ¬çš„æœ€å¤§ softmax æ¦‚çŽ‡ (ID åˆ†æ•°é«˜)
    """
    probs = F.softmax(logits, dim=-1)
    return probs.max(dim=-1)[0].cpu().numpy()


def _compute_energy_scores(
    logits: torch.Tensor, temperature: float = 1.0
) -> np.ndarray:
    """è®¡ç®— Energy Score (Liu et al., NeurIPS 2020)

    E(x) = -T * log(sum_c exp(f_c(x) / T))

    Args:
        logits: [N, C] æ¨¡åž‹è¾“å‡º
        temperature: æ¸©åº¦å‚æ•° (é»˜è®¤ 1.0)

    Returns:
        energy: [N] èƒ½é‡åˆ†æ•° (ID åˆ†æ•°ä½Ž/è´Ÿå€¼æ›´å°, OOD åˆ†æ•°é«˜)
    """
    # æ³¨æ„: logsumexp å€¼è¶Šå¤§è¡¨ç¤ºèƒ½é‡è¶Šä½Ž (ID), æˆ‘ä»¬å–è´Ÿå€¼ä½¿ ID åˆ†æ•° > OOD åˆ†æ•°
    return -torch.logsumexp(logits / temperature, dim=-1).cpu().numpy()


def _compute_mahalanobis_scores(
    features: torch.Tensor,
    class_means: torch.Tensor,
    precision: torch.Tensor,
) -> np.ndarray:
    """è®¡ç®— Mahalanobis Distance (Lee et al., NeurIPS 2018)

    Args:
        features: [N, D] æ ·æœ¬ç‰¹å¾
        class_means: [C, D] ç±»æ¡ä»¶å‡å€¼
        precision: [D, D] å…±äº«ç²¾åº¦çŸ©é˜µ (åæ–¹å·®é€†)

    Returns:
        scores: [N] è´Ÿé©¬æ°è·ç¦» (ID åˆ†æ•°é«˜, OOD åˆ†æ•°ä½Ž)
    """
    num_classes = class_means.shape[0]
    scores = []

    for sample_feat in features:
        # è®¡ç®—åˆ°æ¯ä¸ªç±»ä¸­å¿ƒçš„é©¬æ°è·ç¦»
        dists = []
        for c in range(num_classes):
            diff = sample_feat - class_means[c]  # [D]
            dist = torch.dot(diff, torch.mv(precision, diff))  # æ ‡é‡
            dists.append(dist.item())
        # å–æœ€å°è·ç¦» (æœ€è¿‘çš„ç±»)
        scores.append(-min(dists))  # å–è´Ÿä½¿ ID åˆ†æ•°é«˜

    return np.array(scores)


def _fit_gaussian(
    features: torch.Tensor, labels: torch.Tensor, num_classes: int
) -> Tuple[torch.Tensor, torch.Tensor]:
    """æ‹Ÿåˆç±»æ¡ä»¶é«˜æ–¯åˆ†å¸ƒ

    Args:
        features: [N, D] ID æ•°æ®ç‰¹å¾
        labels: [N] æ ‡ç­¾
        num_classes: ç±»åˆ«æ•°

    Returns:
        class_means: [C, D] ç±»å‡å€¼
        precision: [D, D] å…±äº«ç²¾åº¦çŸ©é˜µ
    """
    device = features.device
    feat_dim = features.shape[1]

    # è®¡ç®—ç±»å‡å€¼
    class_means = torch.zeros(num_classes, feat_dim, device=device)
    for c in range(num_classes):
        mask = labels == c
        if mask.sum() > 0:
            class_means[c] = features[mask].mean(dim=0)

    # è®¡ç®—å…±äº«åæ–¹å·®
    centered = features - class_means[labels]  # [N, D]
    cov = (centered.T @ centered) / len(features)  # [D, D]

    # æ·»åŠ æ­£åˆ™åŒ–ä¿è¯æ•°å€¼ç¨³å®š
    cov += torch.eye(feat_dim, device=device) * 1e-6

    # è®¡ç®—ç²¾åº¦çŸ©é˜µ (åæ–¹å·®é€†)
    precision = torch.linalg.inv(cov)

    return class_means, precision


# â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
# â•‘ ç‰¹å¾æå–è¾…åŠ©å‡½æ•°                                                              â•‘
# â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•


def _extract_ensemble_features(
    models: List[nn.Module], loader, device: torch.device
) -> Tuple[torch.Tensor, torch.Tensor]:
    """æå– ensemble å¹³å‡ç‰¹å¾

    Args:
        models: æ¨¡åž‹åˆ—è¡¨
        loader: æ•°æ®åŠ è½½å™¨
        device: è®¡ç®—è®¾å¤‡

    Returns:
        features: [N, D] å¹³å‡ç‰¹å¾
        labels: [N] æ ‡ç­¾
    """
    from tqdm import tqdm

    extractors = [_FeatureExtractor(m) for m in models]
    all_feats, all_labels = [], []

    with torch.no_grad():
        for x, y in tqdm(loader, desc="Feature Extraction", leave=False):
            batch_feats = []
            for ext in extractors:
                ext.model.eval()
                model_device = next(ext.model.parameters()).device
                feats = ext.extract(x.to(model_device))
                batch_feats.append(feats.cpu())

            # Ensemble å¹³å‡
            avg_feat = torch.stack(batch_feats).mean(dim=0)  # [B, D]
            all_feats.append(avg_feat)
            all_labels.append(y)

    # æ¸…ç† hooks
    for ext in extractors:
        ext.remove_hook()

    return torch.cat(all_feats, dim=0), torch.cat(all_labels, dim=0)


# â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
# â•‘ OOD æ£€æµ‹è¯„ä¼°ä¸»å‡½æ•°                                                            â•‘
# â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•


def evaluate_ood(
    trainer_or_models,
    id_loader,
    ood_loader,
    ood_name="OOD",
    num_classes=None,
    logger=None,
) -> Dict:
    """OOD æ£€æµ‹è¯„ä¼°

    Args:
        trainer_or_models: Trainer å¯¹è±¡, Worker åˆ—è¡¨, æˆ–æ¨¡åž‹åˆ—è¡¨
        id_loader: ID (In-Distribution) æ•°æ®åŠ è½½å™¨
        ood_loader: OOD æ•°æ®åŠ è½½å™¨
        ood_name: OOD æ•°æ®é›†åç§° (ç”¨äºŽæ—¥å¿—)
        num_classes: ç±»åˆ«æ•° (ç”¨äºŽ Mahalanobis, è‹¥ä¸º None åˆ™ä»Ž ID æ ‡ç­¾æŽ¨æ–­)
        logger: æ—¥å¿—å™¨

    Returns:
        åŒ…å«ä»¥ä¸‹æŒ‡æ ‡çš„å­—å…¸:
        - ood_auroc_msp: MSP æ–¹æ³•çš„ AUROC
        - ood_fpr95_msp: MSP æ–¹æ³•åœ¨ 95% TPR æ—¶çš„ FPR
        - ood_auroc_energy: Energy æ–¹æ³•çš„ AUROC
        - ood_fpr95_energy: Energy æ–¹æ³•åœ¨ 95% TPR æ—¶çš„ FPR
        - ood_auroc_mahalanobis: Mahalanobis æ–¹æ³•çš„ AUROC
        - ood_fpr95_mahalanobis: Mahalanobis æ–¹æ³•åœ¨ 95% TPR æ—¶çš„ FPR
    """
    log = logger or get_logger()
    log.info(f"ðŸ” OOD Eval ({ood_name})")

    models, device = get_models_from_source(trainer_or_models)

    # ==================== 1. æå– Logits ====================
    log.info("  ðŸ“Š Extracting logits...")
    id_logits, id_labels = get_all_models_logits(models, id_loader, device)
    ood_logits, _ = get_all_models_logits(models, ood_loader, device)

    if id_logits.numel() == 0 or ood_logits.numel() == 0:
        return {"error": "Empty data"}

    # Ensemble å¹³å‡ logits
    id_logits_avg = id_logits.mean(dim=0)  # [N_id, C]
    ood_logits_avg = ood_logits.mean(dim=0)  # [N_ood, C]

    # ==================== 2. è®¡ç®— MSP å’Œ Energy åˆ†æ•° ====================
    id_msp = _compute_msp_scores(id_logits_avg)
    ood_msp = _compute_msp_scores(ood_logits_avg)

    id_energy = _compute_energy_scores(id_logits_avg)
    ood_energy = _compute_energy_scores(ood_logits_avg)

    # ==================== 3. è®¡ç®— Mahalanobis åˆ†æ•° ====================
    log.info("  ðŸ“Š Extracting features for Mahalanobis...")
    id_features, id_feat_labels = _extract_ensemble_features(models, id_loader, device)
    ood_features, _ = _extract_ensemble_features(models, ood_loader, device)

    # æŽ¨æ–­ç±»åˆ«æ•°
    if num_classes is None:
        num_classes = int(id_feat_labels.max().item()) + 1

    # åœ¨ ID æ•°æ®ä¸Šæ‹Ÿåˆé«˜æ–¯åˆ†å¸ƒ
    class_means, precision = _fit_gaussian(id_features, id_feat_labels, num_classes)

    id_mahal = _compute_mahalanobis_scores(id_features, class_means, precision)
    ood_mahal = _compute_mahalanobis_scores(ood_features, class_means, precision)

    # ==================== 4. è®¡ç®—è¯„ä¼°æŒ‡æ ‡ ====================
    y = np.concatenate([np.ones(len(id_msp)), np.zeros(len(ood_msp))])

    def _auroc(id_scores, ood_scores):
        scores = np.concatenate([id_scores, ood_scores])
        return roc_auc_score(y, scores) * 100

    res = {
        # MSP
        "ood_auroc_msp": _auroc(id_msp, ood_msp),
        "ood_fpr95_msp": _compute_fpr_at_95tpr(np.concatenate([id_msp, ood_msp]), y),
        # Energy
        "ood_auroc_energy": _auroc(id_energy, ood_energy),
        "ood_fpr95_energy": _compute_fpr_at_95tpr(
            np.concatenate([id_energy, ood_energy]), y
        ),
        # Mahalanobis
        "ood_auroc_mahalanobis": _auroc(id_mahal, ood_mahal),
        "ood_fpr95_mahalanobis": _compute_fpr_at_95tpr(
            np.concatenate([id_mahal, ood_mahal]), y
        ),
    }

    log.info(
        f"  âœ… MSP AUROC: {res['ood_auroc_msp']:.2f}%, Energy AUROC: {res['ood_auroc_energy']:.2f}%, Mahalanobis AUROC: {res['ood_auroc_mahalanobis']:.2f}%"
    )

    return res


def _compute_fpr_at_95tpr(scores, labels):
    """è®¡ç®— 95% TPR ä¸‹çš„ FPR"""
    id_scores, ood_scores = scores[labels == 1], scores[labels == 0]
    thresh = np.percentile(id_scores, 5)  # 5th percentile = 95% TPR
    return (ood_scores >= thresh).mean() * 100 if len(ood_scores) else 0.0
