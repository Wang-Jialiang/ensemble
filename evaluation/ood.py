"""
================================================================================
OOD (Out-of-Distribution) æ£€æµ‹è¯„ä¼°æ¨¡å—
================================================================================
"""

from typing import Any, Dict, Optional, Tuple

import numpy as np
import torch
import torch.nn.functional as F
from torch.utils.data import DataLoader

from ..utils import get_logger
from .core import extract_models

# â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
# â•‘ OOD æ£€æµ‹è¯„ä¼°                                                                  â•‘
# â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•


def evaluate_ood(
    trainer_or_models: Any,
    id_loader: DataLoader,
    ood_loader: DataLoader,
    ood_name: str = "OOD",
    logger: Optional[Any] = None,
) -> Dict[str, Any]:
    """
    OOD (Out-of-Distribution) æ£€æµ‹è¯„ä¼°

    ä½¿ç”¨é›†æˆæ¨¡åž‹çš„ç½®ä¿¡åº¦/ç†µæ¥åŒºåˆ† ID å’Œ OOD æ ·æœ¬ã€‚

    Args:
        trainer_or_models: StagedEnsembleTrainer å®žä¾‹æˆ– List[nn.Module]
        id_loader: ID (In-Distribution) æµ‹è¯•æ•°æ®åŠ è½½å™¨
        ood_loader: OOD æ•°æ®åŠ è½½å™¨
        ood_name: OOD æ•°æ®é›†åç§°ï¼ˆç”¨äºŽæ—¥å¿—ï¼‰
        logger: æ—¥å¿—è®°å½•å™¨

    Returns:
        åŒ…å« OOD æ£€æµ‹æŒ‡æ ‡çš„å­—å…¸:
        - ood_auroc_msp: åŸºäºŽ MSP çš„ AUROC
        - ood_auroc_entropy: åŸºäºŽç†µçš„ AUROC
        - ood_fpr95_msp: åŸºäºŽ MSP çš„ FPR@95%TPR
        - ood_fpr95_entropy: åŸºäºŽç†µçš„ FPR@95%TPR
    """
    from sklearn.metrics import roc_auc_score

    logger = logger or get_logger()
    logger.info(f"\nðŸ” Running OOD Detection Evaluation ({ood_name})")

    models, device = extract_models(trainer_or_models)

    def get_confidence_scores(loader: DataLoader) -> Tuple[np.ndarray, np.ndarray]:
        """èŽ·å–é›†æˆæ¨¡åž‹çš„ç½®ä¿¡åº¦åˆ†æ•°"""
        all_msp = []
        all_entropy = []

        with torch.no_grad():
            for inputs, _ in loader:
                inputs = inputs.to(device)

                # æ”¶é›†æ‰€æœ‰æ¨¡åž‹çš„ logits
                batch_logits = []
                for model in models:
                    model.eval()
                    logits = model(inputs)
                    batch_logits.append(logits.unsqueeze(0))

                # é›†æˆ logits: [num_models, batch_size, num_classes] -> [batch_size, num_classes]
                all_model_logits = torch.cat(batch_logits, dim=0)
                ensemble_logits = all_model_logits.mean(dim=0)

                # è®¡ç®—æ¦‚çŽ‡
                probs = F.softmax(ensemble_logits, dim=1)

                # MSP (Maximum Softmax Probability)
                msp = probs.max(dim=1)[0].cpu().numpy()
                all_msp.extend(msp)

                # ç†µ (Entropy): -sum(p * log(p))
                entropy = -(probs * torch.log(probs + 1e-10)).sum(dim=1).cpu().numpy()
                all_entropy.extend(entropy)

        return np.array(all_msp), np.array(all_entropy)

    # èŽ·å– ID å’Œ OOD çš„ç½®ä¿¡åº¦åˆ†æ•°
    logger.info("   ðŸ“Š è®¡ç®— ID æ ·æœ¬ç½®ä¿¡åº¦...")
    id_msp, id_entropy = get_confidence_scores(id_loader)

    logger.info("   ðŸ“Š è®¡ç®— OOD æ ·æœ¬ç½®ä¿¡åº¦...")
    ood_msp, ood_entropy = get_confidence_scores(ood_loader)

    # åˆ›å»ºæ ‡ç­¾: ID=1, OOD=0
    id_labels = np.ones(len(id_msp))
    ood_labels = np.zeros(len(ood_msp))

    all_labels = np.concatenate([id_labels, ood_labels])
    all_msp_combined = np.concatenate([id_msp, ood_msp])
    all_entropy_combined = np.concatenate([id_entropy, ood_entropy])

    # è¾¹ç•Œæ£€æŸ¥ï¼šç¡®ä¿æœ‰è¶³å¤Ÿçš„æ•°æ®è®¡ç®— AUROC
    if len(id_msp) == 0 or len(ood_msp) == 0:
        logger.warning("   âš ï¸ ID æˆ– OOD æ•°æ®ä¸ºç©ºï¼Œæ— æ³•è®¡ç®— AUROC")
        return {
            "ood_dataset": ood_name,
            "id_samples": len(id_msp),
            "ood_samples": len(ood_msp),
            "error": "Empty data",
        }

    # è®¡ç®— AUROC
    # MSP: é«˜å€¼è¡¨ç¤º IDï¼ˆæ‰€ä»¥ç›´æŽ¥ç”¨ï¼‰
    auroc_msp = roc_auc_score(all_labels, all_msp_combined) * 100.0

    # Entropy: ä½Žå€¼è¡¨ç¤º IDï¼ˆæ‰€ä»¥ç”¨è´Ÿå€¼ï¼‰
    auroc_entropy = roc_auc_score(all_labels, -all_entropy_combined) * 100.0

    # è®¡ç®— FPR@95%TPR
    def compute_fpr_at_tpr(
        scores: np.ndarray, labels: np.ndarray, tpr_target: float = 0.95
    ) -> float:
        """è®¡ç®—ç»™å®š TPR ä¸‹çš„ FPR"""
        # å¯¹äºŽ ID åˆ†æ•°é«˜çš„æƒ…å†µ
        pos_scores = scores[labels == 1]
        neg_scores = scores[labels == 0]

        # æ‰¾åˆ°ä½¿ TPR >= tpr_target çš„é˜ˆå€¼
        sorted_pos = np.sort(pos_scores)
        threshold_idx = int(len(sorted_pos) * (1 - tpr_target))
        threshold = (
            sorted_pos[threshold_idx]
            if threshold_idx < len(sorted_pos)
            else sorted_pos[0]
        )

        # è®¡ç®— FPR (é¿å…é™¤é›¶)
        if len(neg_scores) == 0:
            return 0.0
        fpr = (neg_scores >= threshold).sum() / len(neg_scores)
        return fpr * 100.0

    fpr95_msp = compute_fpr_at_tpr(all_msp_combined, all_labels, 0.95)
    fpr95_entropy = compute_fpr_at_tpr(-all_entropy_combined, all_labels, 0.95)

    results = {
        "ood_dataset": ood_name,
        "id_samples": len(id_msp),
        "ood_samples": len(ood_msp),
        "ood_auroc_msp": auroc_msp,
        "ood_auroc_entropy": auroc_entropy,
        "ood_fpr95_msp": fpr95_msp,
        "ood_fpr95_entropy": fpr95_entropy,
        # ç½®ä¿¡åº¦ç»Ÿè®¡
        "id_msp_mean": float(np.mean(id_msp)),
        "ood_msp_mean": float(np.mean(ood_msp)),
        "id_entropy_mean": float(np.mean(id_entropy)),
        "ood_entropy_mean": float(np.mean(ood_entropy)),
    }

    logger.info(f"   âœ… OOD Detection Results ({ood_name}):")
    logger.info(f"      AUROC (MSP): {auroc_msp:.2f}%")
    logger.info(f"      AUROC (Entropy): {auroc_entropy:.2f}%")
    logger.info(f"      FPR@95 (MSP): {fpr95_msp:.2f}%")
    logger.info(f"      FPR@95 (Entropy): {fpr95_entropy:.2f}%")

    return results
